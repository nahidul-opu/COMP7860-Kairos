{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding=utf-8\n",
    "import os.path as osp\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "from torch_geometric.data import TemporalData\n",
    "\n",
    "from torch_geometric.nn import TGNMemory, TransformerConv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn.models.tgn import (LastNeighborLoader, IdentityMessage, MeanAggregator,\n",
    "                                           LastAggregator)\n",
    "from torch_geometric import *\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "from tqdm import tqdm\n",
    "# from .autonotebook import tqdm as notebook_tqdm\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "from random import choice\n",
    "import gc\n",
    "from graphviz import Digraph\n",
    "import xxhash\n",
    "\n",
    "from datetime import datetime, timezone\n",
    "import time\n",
    "import pytz\n",
    "from time import mktime\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "from rich.progress import Progress\n",
    "from rich.progress import (\n",
    "    BarColumn,\n",
    "    DownloadColumn,\n",
    "    Progress,\n",
    "    SpinnerColumn,\n",
    "    TaskProgressColumn,\n",
    "    TimeElapsedColumn,\n",
    "    TimeRemainingColumn,\n",
    ")\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "def hashgen(l):\n",
    "    \"\"\"Generate a single hash value from a list. @l is a list of\n",
    "    string values, which can be properties of a node/edge. This\n",
    "    function returns a single hashed integer value.\"\"\"\n",
    "    hasher = xxhash.xxh64()\n",
    "    for e in l:\n",
    "        hasher.update(e)\n",
    "    return hasher.intdigest()\n",
    "\n",
    "\n",
    "def datetime_to_ns_time(date):\n",
    "    \"\"\"\n",
    "    :param date: str   format: %Y-%m-%d %H:%M:%S   e.g. 2013-10-10 23:40:00\n",
    "    :return: nano timestamp\n",
    "    \"\"\"\n",
    "    date,ns=date.split('.')\n",
    "\n",
    "    timeArray = time.strptime(date, '%Y-%m-%dT%H:%M:%S')\n",
    "    timeStamp = int(time.mktime(timeArray))\n",
    "    timeStamp = timeStamp * 1000000000\n",
    "    timeStamp += int(ns.split('Z')[0])\n",
    "    return timeStamp\n",
    "\n",
    "\n",
    "def datetime_to_timestamp_US(date):\n",
    "    \"\"\"\n",
    "    :param date: str   format: %Y-%m-%d %H:%M:%S   e.g. 2013-10-10 23:40:00\n",
    "    :return: nano timestamp\n",
    "    \"\"\"\n",
    "    date=date.replace('-04:00','')\n",
    "    if '.' in date:\n",
    "        date,ms=date.split('.')\n",
    "    else:\n",
    "        ms=0\n",
    "    tz = pytz.timezone('Etc/GMT+4')\n",
    "    timeArray = time.strptime(date, \"%Y-%m-%dT%H:%M:%S\")\n",
    "    dt = datetime.fromtimestamp(mktime(timeArray))\n",
    "    timestamp = tz.localize(dt)\n",
    "    timestamp=timestamp.timestamp()\n",
    "    timeStamp = timestamp*1000+int(ms)\n",
    "    return int(timeStamp)\n",
    "\n",
    "\n",
    "def timestamp_to_datetime_US(ns):\n",
    "    \"\"\"\n",
    "    :param date: str   format: %Y-%m-%d %H:%M:%S   e.g. 2013-10-10 23:40:00\n",
    "    :return: nano timestamp\n",
    "    \"\"\"\n",
    "    tz = pytz.timezone('US/Eastern')\n",
    "    ms=ns%1000\n",
    "    ns/=1000\n",
    "    dt = pytz.datetime.datetime.fromtimestamp(int(ns), tz)\n",
    "    s = dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    s+='.'+str(ms)\n",
    "#     s += '.' + str(int(int(ns) % 1000000000)).zfill(9)\n",
    "    return s\n",
    "\n",
    "pid_split_symble=\"#_\"\n",
    "\n",
    "host_split_symble=\"_@\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database setting (Make sure the database and tables are created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "from psycopg2 import extras as ex\n",
    "# Create a postgreSQL DB connection object for storing provenance graph edges into DB\n",
    "# Original '/var/run/postgresql/' has been replaced with 'localhost' since we are using docker and accessing as a service in port 5437\n",
    "connect = psycopg2.connect(database = 'optc_db',\n",
    "                           host = 'localhost',\n",
    "                           user = 'postgres',\n",
    "                           password = 'postgres',\n",
    "                           port = '5437'\n",
    "                          )\n",
    "\n",
    "cur = connect.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear all data in the database. Run it carefully!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Delete events/edges inserted in previous run\n",
    "tt=cur.execute(\"\"\"\n",
    "    delete from event_table where 1=1;\n",
    "\"\"\")\n",
    "print(tt)\n",
    "connect.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Delete messages inserted in previous run\n",
    "tt=cur.execute(\"\"\"\n",
    "    delete from nodeid2msg where 1=1;\n",
    "\"\"\")\n",
    "print(tt)\n",
    "connect.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_edge_type=[\n",
    "    \"READ\",\n",
    "]\n",
    "\n",
    "\n",
    "# 3 types of nodes used in kairos\n",
    "node_type_used=[\n",
    "    'FILE',\n",
    " 'FLOW',\n",
    " 'PROCESS',\n",
    "#  'SHELL',\n",
    "]\n",
    "# Parsing source node, destination node, edge, timestamp, hostname etc.\n",
    "def process_raw_dic(raw_dic):\n",
    "    ans_dic={}\n",
    "    \n",
    "    \n",
    "    ans_dic['hostname']=raw_dic['hostname'].split('.')[0]\n",
    "    \n",
    "    ans_dic['edge_type']=raw_dic['action']\n",
    "    ans_dic['src_id']=raw_dic['actorID']\n",
    "    ans_dic['dst_id']=raw_dic['objectID']\n",
    "    \n",
    "    ans_dic['src_type']='PROCESS'\n",
    "    ans_dic['timestamp']=datetime_to_timestamp_US(raw_dic['timestamp'])\n",
    "    ans_dic['dst_type']=raw_dic['object']\n",
    "    \n",
    "    try:\n",
    "        node_uuid2path[ans_dic['src_id']]=ans_dic['hostname']+host_split_symble+raw_dic['properties']['image_path']  \n",
    "        \n",
    "    \n",
    "        if raw_dic['object']=='FLOW':\n",
    "            temp_flow=f\"{raw_dic['properties']['direction']}#{raw_dic['properties']['src_ip']}:{raw_dic['properties']['src_port']}->{raw_dic['properties']['dest_ip']}:{raw_dic['properties']['dest_port']}\"\n",
    "            node_uuid2path[ans_dic['dst_id']]=ans_dic['hostname']+host_split_symble+temp_flow\n",
    "\n",
    "        if raw_dic['object']=='FILE':              \n",
    "            node_uuid2path[ans_dic['dst_id']]=ans_dic['hostname']+host_split_symble+raw_dic['properties']['file_path']\n",
    "\n",
    "\n",
    "    except:\n",
    "        ans_dic={}\n",
    "    \n",
    "    return ans_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_type={'FILE',\n",
    " 'FLOW',\n",
    " 'MODULE',\n",
    " 'PROCESS',\n",
    " 'REGISTRY',\n",
    " 'SHELL',\n",
    " 'TASK',\n",
    " 'THREAD',\n",
    " 'USER_SESSION'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unzip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    " \n",
    "# folder path\n",
    "dir_path = '/home/shahidul2k9/data/optc/plain/'\n",
    " \n",
    "# list to store files name\n",
    "res = []\n",
    "for (dir_path, dir_names, file_names) in walk(dir_path):\n",
    "    if dir_path[-1]!='/':\n",
    "        dir_path+='/'\n",
    "#     print(f\"{dir_path=}\")\n",
    "#     print(f\"{file_names=}\")\n",
    "    for f in file_names:\n",
    "        temp_file_path=dir_path+f\n",
    "#         print(f\"{temp_file_path=}\")\n",
    "     \n",
    "        res.append(temp_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4481/4481 [04:32<00:00, 16.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " /home/shahidul2k9/data/optc/plain/ecar/benign/17-18Sep19/AIA-51-75/AIA-51-75.ecar-last.json.gz Finished！\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Unzip compressed json files\n",
    "for r in tqdm(res):\n",
    "    if (\"201-225\" in r or \"401-425\" in r or \"651-675\" in r or \"501-525\" in r or \"51-75\" in r) and \".gz\" in r:\n",
    "        os.system(f\"gzip -d {r}\")\n",
    "        print(f\" {r} Finished！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the features of nodes and edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 types of edges\n",
    "edge_set=['OPEN',\n",
    "'READ',\n",
    "'CREATE',\n",
    "'MESSAGE',\n",
    "'MODIFY',\n",
    "'START',\n",
    "'RENAME',\n",
    "'DELETE',\n",
    "'TERMINATE',\n",
    "'WRITE',]\n",
    "\n",
    "# Generate edge type one-hot\n",
    "edgevec=torch.nn.functional.one_hot(torch.arange(0, len(edge_set)), num_classes=len(edge_set))\n",
    "\n",
    "\n",
    "# Allocating One-hot encoding for each edge type\n",
    "edge2vec={}\n",
    "for e in range(len(edge_set)):\n",
    "    edge2vec[edge_set[e]]=edgevec[e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OPEN': tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'READ': tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'CREATE': tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'MESSAGE': tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " 'MODIFY': tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " 'START': tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " 'RENAME': tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " 'DELETE': tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " 'TERMINATE': tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " 'WRITE': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge label to real number mapping for indexing operation\n",
    "rel2id={}\n",
    "index=1\n",
    "for i in edge_set:\n",
    "    rel2id[index]=i\n",
    "    rel2id[i]=index\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'OPEN',\n",
       " 'OPEN': 1,\n",
       " 2: 'READ',\n",
       " 'READ': 2,\n",
       " 3: 'CREATE',\n",
       " 'CREATE': 3,\n",
       " 4: 'MESSAGE',\n",
       " 'MESSAGE': 4,\n",
       " 5: 'MODIFY',\n",
       " 'MODIFY': 5,\n",
       " 6: 'START',\n",
       " 'START': 6,\n",
       " 7: 'RENAME',\n",
       " 'RENAME': 7,\n",
       " 8: 'DELETE',\n",
       " 'DELETE': 8,\n",
       " 9: 'TERMINATE',\n",
       " 'TERMINATE': 9,\n",
       " 10: 'WRITE',\n",
       " 'WRITE': 10}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "encode_len=16\n",
    "\n",
    "FH_string=FeatureHasher(n_features=encode_len,input_type=\"string\")\n",
    "FH_dict=FeatureHasher(n_features=encode_len,input_type=\"dict\")\n",
    "\n",
    "\n",
    "def path2higlist(p):\n",
    "    l=[]\n",
    "    spl=p.strip().split('/')\n",
    "    for i in spl:\n",
    "        if len(l)!=0:\n",
    "            l.append(l[-1]+'/'+i)\n",
    "        else:\n",
    "            l.append(i)\n",
    "#     print(l)\n",
    "    return l\n",
    "\n",
    "def ip2higlist(p):\n",
    "    l=[]\n",
    "    if \"::\" not in p:\n",
    "        spl=p.strip().split('.')\n",
    "        for i in spl:\n",
    "            if len(l)!=0:\n",
    "                l.append(l[-1]+'.'+i)\n",
    "            else:\n",
    "                l.append(i)\n",
    "    #     print(l)\n",
    "        return l\n",
    "    else:\n",
    "        spl=p.strip().split(':')\n",
    "        for i in spl:\n",
    "            if len(l)!=0:\n",
    "                l.append(l[-1]+':'+i)\n",
    "            else:\n",
    "                l.append(i)\n",
    "    #     print(l)\n",
    "        return l\n",
    "def list2str(l):\n",
    "    s=''\n",
    "    for i in l:\n",
    "        s+=i\n",
    "    return s\n",
    "\n",
    "def str2tensor(msg_type,msg):\n",
    "    if msg_type == 'FLOW':\n",
    "        h_msg=list2str(ip2higlist(msg))\n",
    "    else:\n",
    "        h_msg=list2str(path2higlist(msg))\n",
    "    vec=FH_string.transform([msg_type+h_msg]).toarray()\n",
    "    vec=torch.tensor(vec).reshape(encode_len).float()\n",
    "#     print(h_msg)\n",
    "    return vec\n",
    "\n",
    "\n",
    "class TimeEncoder(torch.nn.Module):\n",
    "    def __init__(self, out_channels):\n",
    "        super().__init__()\n",
    "        self.out_channels = out_channels\n",
    "        self.lin = Linear(1, out_channels)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "\n",
    "    def forward(self, t):\n",
    "        return self.lin(t.view(-1, 1)).cos()\n",
    "    \n",
    "time_enc=TimeEncoder(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store the benign data to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hashmap for storing unique nodes with associated metadata\n",
    "node_uuid2path={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    " \n",
    "# folder path\n",
    "dir_path = '/home/shahidul2k9/data/optc/plain/ecar/benign/'\n",
    "\n",
    "res = []\n",
    "for (dir_path, dir_names, file_names) in walk(dir_path):\n",
    "    if dir_path[-1]!='/':\n",
    "        dir_path+='/'\n",
    "#     print(f\"{dir_path=}\")\n",
    "#     print(f\"{file_names=}\")\n",
    "    for f in file_names:\n",
    "        temp_file_path=dir_path+f\n",
    "#         print(f\"{temp_file_path=}\")\n",
    "        if \"201-225\" in temp_file_path or (\"20-23Sep19\" in temp_file_path and (\"401-425\" in temp_file_path or \"651-675\" in temp_file_path or \"501-525\" in temp_file_path or \"51-75\" in temp_file_path)):\n",
    "            res.append(temp_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:00<00:00, 406994.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# Unzip ecar benign compressed data file\n",
    "for r in tqdm(res):\n",
    "    if  \".gz\" in r:\n",
    "        #os.system(f\"gzip -d {r}\")\n",
    "        print(f\" {r} Finished！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# White  listed hosts names\n",
    "def is_selected_hosts(line):\n",
    "    hosts=[\n",
    "        'SysClient0201',\n",
    "        'SysClient0402',\n",
    "        'SysClient0660',\n",
    "        'SysClient0501',\n",
    "        'SysClient0051',        \n",
    "        'SysClient0209',\n",
    "    ]\n",
    "    flag=False\n",
    "    for h in hosts:\n",
    "        if h in line:\n",
    "            flag=True\n",
    "            break\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6190907it [00:56, 110516.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=403686\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/19Sep19/AIA-201-225/AIA-201-225.ecar-2019-12-07T16-16-05.667.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23189497it [03:30, 110353.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=1744136\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/19Sep19/AIA-201-225/AIA-201-225.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76699983it [10:59, 116299.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=2957067\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-501-525/AIA-501-525.ecar-2019-11-15T09-43-35.856.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76706216it [10:47, 118536.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=2965137\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-501-525/AIA-501-525.ecar-2019-11-15T17-22-42.923.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20541672it [03:16, 104274.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=785228\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-501-525/AIA-501-525.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "78048775it [11:08, 116744.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=4039788\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-501-525/AIA-501-525.ecar-2019-11-15T05-59-37.208.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76719146it [10:39, 119990.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=2876893\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-501-525/AIA-501-525.ecar-2019-11-15T13-29-59.064.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36440311it [04:33, 133396.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=843401\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-501-525/AIA-501-525.ecar-2019-11-15T03-10-00.546.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36333460it [05:06, 118559.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=1022401\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-651-675/AIA-651-675.ecar-2019-11-15T03-09-38.187.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76458599it [10:36, 120164.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=2610952\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-651-675/AIA-651-675.ecar-2019-11-15T13-28-16.876.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32029474it [04:15, 125258.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=1099540\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-651-675/AIA-651-675.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "77786670it [10:47, 120131.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=3133116\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-651-675/AIA-651-675.ecar-2019-11-15T05-48-17.579.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76457220it [10:25, 122299.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=2644933\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-651-675/AIA-651-675.ecar-2019-11-15T09-37-46.741.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76425447it [10:30, 121194.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=2617847\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-651-675/AIA-651-675.ecar-2019-11-15T17-26-42.298.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76383303it [10:59, 115853.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=3024043\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-401-425/AIA-401-425.ecar-2019-12-07T20-18-48.097.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76389825it [10:41, 119053.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=2990117\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-401-425/AIA-401-425.ecar-2019-12-07T12-19-23.521.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76407480it [10:32, 120726.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=3002918\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-401-425/AIA-401-425.ecar-2019-12-07T16-09-39.085.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53285475it [07:04, 125617.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=2101814\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-401-425/AIA-401-425.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "77020972it [11:03, 116146.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=3421514\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-401-425/AIA-401-425.ecar-2019-12-07T08-33-35.028.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21076091it [02:49, 124576.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=480749\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-401-425/AIA-401-425.ecar-2019-12-07T06-28-53.370.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25224989it [03:08, 133931.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=432115\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-51-75/AIA-51-75.ecar-2019-12-07T16-15-43.163.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76427896it [10:44, 118605.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=2892230\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-51-75/AIA-51-75.ecar-2019-12-07T21-31-30.259.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76404717it [10:27, 121694.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=2919561\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-51-75/AIA-51-75.ecar-2019-12-08T00-56-58.175.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42840935it [06:13, 114785.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=1616861\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-51-75/AIA-51-75.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76421197it [10:28, 121583.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=2824549\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-51-75/AIA-51-75.ecar-2019-12-08T04-30-36.852.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76638913it [10:52, 117444.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=3417179\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-51-75/AIA-51-75.ecar-2019-12-07T18-18-31.331.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53321795it [08:47, 101079.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=4793249\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-201-225/AIA-201-225.ecar-2019-12-07T19-16-05.788.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76648515it [11:22, 112239.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=5027745\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-201-225/AIA-201-225.ecar-2019-12-07T22-06-33.589.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "74706481it [11:24, 109147.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=5727218\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-201-225/AIA-201-225.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76495083it [11:51, 107515.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=5879664\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-201-225/AIA-201-225.ecar-2019-12-08T01-57-30.012.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76469610it [11:33, 110258.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=5944960\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/20-23Sep19/AIA-201-225/AIA-201-225.ecar-2019-12-08T05-46-21.658.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32326513it [04:42, 114486.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=2449767\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/18-19Sep19/AIA-201-225/AIA-201-225.ecar-2019-12-07T10-37-17.942.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "69051137it [10:31, 109378.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=4978166\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/18-19Sep19/AIA-201-225/AIA-201-225.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "75743706it [11:38, 108369.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=5575885\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/17-18Sep19/AIA-201-225/AIA-201-225.ecar-2019-12-07T01-57-49.366.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43174191it [06:58, 103262.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=3393220\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/17-18Sep19/AIA-201-225/AIA-201-225.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "75798918it [11:53, 106214.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=6295186\n",
      "/home/shahidul2k9/data/optc/plain/ecar/benign/17-18Sep19/AIA-201-225/AIA-201-225.ecar-2019-12-07T06-00-00.251.json Finished! \n"
     ]
    }
   ],
   "source": [
    "# Iterate though all ecar benign logs, parse it and insert into DB\n",
    "for file_path in res:\n",
    "    \n",
    "    edge_list=[]\n",
    "\n",
    "    with open(file_path) as f:\n",
    "        for line in tqdm(f):\n",
    "            line=line.replace('\\\\\\\\','/')\n",
    "            temp_dic=json.loads(line.strip())\n",
    "            hostname=temp_dic['hostname'].split('.')[0]\n",
    "            if temp_dic['object'] in node_type_used and is_selected_hosts(hostname):\n",
    "                edge_list.append(process_raw_dic(temp_dic))\n",
    "    \n",
    "        print(f'{len(edge_list)=}')\n",
    "        data_list=[]\n",
    "        for e in edge_list:\n",
    "            try:\n",
    "                data_list.append([\n",
    "                    e['src_id'],\n",
    "                    e['src_type'],\n",
    "                    e['edge_type'],\n",
    "                    e['dst_id'],\n",
    "                    e['dst_type'],\n",
    "                    e['hostname'],\n",
    "                    e['timestamp'],\n",
    "                    \"benign\",\n",
    "                ])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # write to database\n",
    "        sql = '''insert into event_table\n",
    "                             values %s\n",
    "                '''\n",
    "        ex.execute_values(cur,sql, data_list,page_size=10000)\n",
    "        connect.commit()\n",
    "        \n",
    "        print(f\"{file_path} Finished! \")\n",
    "        # Clear the tmp variables to release the memory.\n",
    "        del edge_list\n",
    "        del data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store the evaluation data to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    " # Evaluation dataset subfolder listing\n",
    "# folder path\n",
    "dir_path = '/home/shahidul2k9/data/optc/plain/ecar/evaluation/'\n",
    "\n",
    "res = []\n",
    "for (dir_path, dir_names, file_names) in walk(dir_path):\n",
    "    if dir_path[-1]!='/':\n",
    "        dir_path+='/'\n",
    "    for f in file_names:\n",
    "        temp_file_path=dir_path+f\n",
    "#         print(f\"{temp_file_path=}\")\n",
    "        if (\"201-225\" in temp_file_path or \"401-425\" in temp_file_path or \"651-675\" in temp_file_path or \"501-525\" in temp_file_path or \"51-75\" in temp_file_path):\n",
    "            res.append(temp_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 304565.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# Decompress evaluation log files\n",
    "for r in tqdm(res):\n",
    "    if  \".gz\" in r:\n",
    "        os.system(f\"gzip -d {r}\")\n",
    "        print(f\" {r} Finished！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# White listed hostnames for evaluation\n",
    "def is_selected_hosts(line):\n",
    "    hosts=[\n",
    "        'SysClient0201',\n",
    "        'SysClient0402',\n",
    "        'SysClient0660',\n",
    "        'SysClient0501',\n",
    "        'SysClient0051',        \n",
    "        'SysClient0207',\n",
    "    ]\n",
    "    flag=False\n",
    "    for h in hosts:\n",
    "        if h in line:\n",
    "            flag=True\n",
    "            break\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32570231it [04:12, 129201.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=1194622\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/23Sep19-red/AIA-501-525/AIA-501-525.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32614330it [04:44, 114534.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=1131200\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/23Sep19-red/AIA-651-675/AIA-651-675.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23066470it [02:57, 129809.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=947751\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/23Sep19-red/AIA-401-425/AIA-401-425.ecar-2019-12-08T01-29-39.403.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9855840it [01:16, 129404.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=391973\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/23Sep19-red/AIA-401-425/AIA-401-425.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32602194it [04:35, 118389.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=1179498\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/23Sep19-red/AIA-51-75/AIA-51-75.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34146068it [04:50, 117508.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=2151310\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/23Sep19-red/AIA-201-225/AIA-201-225.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1759566it [00:15, 109979.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=139907\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/23Sep19-red/AIA-201-225/AIA-201-225.ecar-2019-12-08T11-05-10.046.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30125538it [04:28, 112385.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=1274143\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/24Sep19/AIA-501-525/AIA-501-525.ecar-2019-11-17T04-01-58.625.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65758362it [09:04, 120713.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=2554194\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/24Sep19/AIA-501-525/AIA-501-525.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18306997it [02:21, 128999.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=568693\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/24Sep19/AIA-651-675/AIA-651-675.ecar-2019-11-17T03-25-23.290.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76274003it [10:13, 124375.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=2829980\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/24Sep19/AIA-651-675/AIA-651-675.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "73190980it [10:05, 120953.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=2825428\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/24Sep19/AIA-401-425/AIA-401-425.ecar-2019-12-08T07-35-11.579.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23196562it [03:00, 128314.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=878620\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/24Sep19/AIA-401-425/AIA-401-425.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76327011it [10:17, 123697.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=2839067\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/24Sep19/AIA-51-75/AIA-51-75.ecar-2019-12-08T15-24-26.681.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7422309it [01:05, 113218.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=275431\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/24Sep19/AIA-51-75/AIA-51-75.ecar-2019-12-08T12-56-31.374.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12133760it [01:56, 104511.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=457651\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/24Sep19/AIA-51-75/AIA-51-75.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49333875it [07:05, 115981.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=3544607\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/24Sep19/AIA-201-225/AIA-201-225.ecar-2019-12-08T17-41-18.327.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46514809it [07:15, 106872.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=3497340\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/24Sep19/AIA-201-225/AIA-201-225.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13921814it [01:48, 128881.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=586663\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/25Sept/AIA-501-525/AIA-501-525.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10781277it [01:29, 120326.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=493144\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/25Sept/AIA-501-525/AIA-501-525.ecar-2019-11-17T15-04-02.073.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "333939it [00:07, 47156.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=11430\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/25Sept/AIA-651-675/AIA-651-675.ecar-2019-11-17T14-50-25.754.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24895771it [03:24, 121958.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=1035074\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/25Sept/AIA-651-675/AIA-651-675.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27461034it [03:33, 128625.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=1049439\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/25Sept/AIA-401-425/AIA-401-425.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25186287it [03:41, 113871.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=1053016\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/25Sept/AIA-51-75/AIA-51-75.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27031942it [03:51, 116579.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=1839580\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/25Sept/AIA-201-225/AIA-201-225.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46406787it [06:14, 123758.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=1768209\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/23Sep-night/AIA-501-525/AIA-501-525.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23561343it [03:06, 126386.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=897205\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/23Sep-night/AIA-501-525/AIA-501-525.ecar-2019-11-16T23-22-29.234.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58296574it [08:11, 118513.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=2195435\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/23Sep-night/AIA-651-675/AIA-651-675.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11713601it [01:32, 125974.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=441649\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/23Sep-night/AIA-651-675/AIA-651-675.ecar-2019-11-16T23-07-40.716.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "66585106it [09:06, 121837.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=2522019\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/23Sep-Night/AIA-401-425/AIA-401-425.ecar-2019-12-08T04-06-31.326.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3341987it [00:25, 128664.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=125517\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/23Sep-Night/AIA-401-425/AIA-401-425.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "69126143it [09:30, 121237.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=2654927\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/23Sep-Night/AIA-51-75/AIA-51-75.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "943962it [00:06, 138007.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=14520\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/23Sep-Night/AIA-51-75/AIA-51-75.ecar-2019-12-08T10-19-52.584.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27304413it [03:54, 116648.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=2064339\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/23Sep-Night/AIA-201-225/AIA-201-225.ecar-last.json Finished! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42593860it [06:27, 109872.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(edge_list)=3222906\n",
      "/home/shahidul2k9/data/optc/plain/ecar/evaluation/23Sep-Night/AIA-201-225/AIA-201-225.ecar-2019-12-08T14-19-51.427.json Finished! \n"
     ]
    }
   ],
   "source": [
    "# Iterating through uncompressed evaluation dataset files, extracting log and finally inserting into DB\n",
    "for file_path in res:\n",
    "    \n",
    "    edge_list=[]\n",
    "\n",
    "    with open(file_path) as f:\n",
    "        for line in tqdm(f):\n",
    "            line=line.replace('\\\\\\\\','/')\n",
    "            temp_dic=json.loads(line.strip())\n",
    "            hostname=temp_dic['hostname'].split('.')[0]\n",
    "            if temp_dic['object'] in node_type_used and is_selected_hosts(hostname):\n",
    "                edge_list.append(process_raw_dic(temp_dic))\n",
    "    \n",
    "        print(f'{len(edge_list)=}')\n",
    "        data_list=[]\n",
    "        for e in edge_list:\n",
    "            try:\n",
    "                data_list.append([\n",
    "                    e['src_id'],\n",
    "                    e['src_type'],\n",
    "                    e['edge_type'],\n",
    "                    e['dst_id'],\n",
    "                    e['dst_type'],\n",
    "                    e['hostname'],\n",
    "                    e['timestamp'],\n",
    "                    \"evaluation\",\n",
    "                ])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        sql = '''insert into event_table\n",
    "                             values %s\n",
    "                '''\n",
    "        ex.execute_values(cur,sql, data_list,page_size=10000)\n",
    "        connect.commit()\n",
    "        \n",
    "        print(f\"{file_path} Finished! \")\n",
    "        # Clear the tmp variables to release the memory.\n",
    "        del edge_list\n",
    "        del data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store the node data into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert temporarily stored nodes and associated metadata into DB\n",
    "data_list=[]\n",
    "for n in node_uuid2path:\n",
    "    try:\n",
    "        data_list.append([\n",
    "            n,\n",
    "             node_uuid2path[n]\n",
    "        ])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n",
    "sql = '''insert into nodeid2msg\n",
    "                     values %s\n",
    "        '''\n",
    "ex.execute_values(cur,sql, data_list,page_size=10000)\n",
    "connect.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18965643"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log total number of nodes ~19 millions\n",
    "len(node_uuid2path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load node data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18965643/18965643 [00:11<00:00, 1622800.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# Construct the map between nodeid and msg\n",
    "sql=\"select * from nodeid2msg;\"\n",
    "cur.execute(sql)\n",
    "rows = cur.fetchall()\n",
    "\n",
    "node_uuid2path={}  # nodeid => msg      node hash => nodeid\n",
    "for i in tqdm(rows):\n",
    "    # Map node UUID to metadata\n",
    "    node_uuid2path[i[0]]=i[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the benign datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h402  22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(events)=4410529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [25:57<00:00, 1557.68s/it]\n"
     ]
    }
   ],
   "source": [
    "# Read benign dataset generated by host SysClient0402 on 22nd September 2019 and create temporal graph\n",
    "for day in tqdm(range(22,23)):\n",
    "    start_timestamp=datetime_to_timestamp_US('2019-09-'+str(day)+'T00:00:00')\n",
    "    end_timestamp=datetime_to_timestamp_US('2019-09-'+str(day+1)+'T00:00:00')\n",
    "    hostname='SysClient0402'\n",
    "    datalabel='benign'\n",
    "\n",
    "    # Create SQL query command\n",
    "    sql=f\"\"\"\n",
    "    select * from event_table\n",
    "    where\n",
    "          timestamp>{start_timestamp} and timestamp<{end_timestamp}\n",
    "          and hostname='{hostname}' and data_label='{datalabel}' ORDER BY timestamp;\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute SQL query\n",
    "    cur.execute(sql)\n",
    "    # Fetch Edges\n",
    "    events = cur.fetchall()\n",
    "    print(f\"{len(events)=}\")\n",
    "    \n",
    "    \n",
    "    # Generate local temporal graph node indexes mapping\n",
    "    node_set=set()\n",
    "    node_uuid2index={}\n",
    "    temp_index=0\n",
    "    for e in events:\n",
    "        if e[3] not in node_uuid2path or e[0]  not in node_uuid2path:\n",
    "            continue\n",
    "\n",
    "        if e[0] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[0]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[0]]\n",
    "            temp_index+=1\n",
    "\n",
    "        if e[3] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[3]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[3]]\n",
    "            temp_index+=1 \n",
    "\n",
    "    torch.save(node_uuid2index,f'node_uuid2index_9_{day}_host={hostname}_datalabel={datalabel}')\n",
    "       \n",
    "\n",
    "    dataset = TemporalData()\n",
    "    src = []\n",
    "    dst = []\n",
    "    msg = []\n",
    "    t = []\n",
    "    \n",
    "    # Create temporal graph with nodes, edges, messages and times\n",
    "    for e in (events):\n",
    "        if e[3] in node_uuid2index and e[0] in node_uuid2index:\n",
    "            # If the image path of the node is not recorded, then skip this edge\n",
    "            src.append(node_uuid2index[e[0]])\n",
    "            dst.append(node_uuid2index[e[3]])\n",
    "        #     msg.append(torch.cat([torch.from_numpy(node2higvec_bn[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec_bn[i[1]])] ))\n",
    "\n",
    "            msg.append(torch.cat([str2tensor(e[1],node_uuid2path[e[0]]), \n",
    "                                  edge2vec[e[2]], \n",
    "                                  str2tensor(e[4],node_uuid2path[e[3]])\n",
    "                                 ]))\n",
    "            t.append(int(e[6]))\n",
    "\n",
    "    dataset.src = torch.tensor(src)\n",
    "    dataset.dst = torch.tensor(dst)\n",
    "    dataset.t = torch.tensor(t)\n",
    "    dataset.msg = torch.vstack(msg)\n",
    "    dataset.src = dataset.src.to(torch.long)\n",
    "    dataset.dst = dataset.dst.to(torch.long)\n",
    "    dataset.msg = dataset.msg.to(torch.float)\n",
    "    dataset.t = dataset.t.to(torch.long)\n",
    "    # Store temporal graph in disk\n",
    "    torch.save(dataset, f\"/home/shahidul2k9/data/optc/out/evaluation/9_{day}_host={hostname}_datalabel={datalabel}.TemporalData\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h660 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(events)=3889699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [22:04<00:00, 1324.87s/it]\n"
     ]
    }
   ],
   "source": [
    "# Read benign dataset generated by host SysClient0660 on 22nd September 2019 and create temporal graph\n",
    "for day in tqdm(range(22,23)):\n",
    "    start_timestamp=datetime_to_timestamp_US('2019-09-'+str(day)+'T00:00:00')\n",
    "    end_timestamp=datetime_to_timestamp_US('2019-09-'+str(day+1)+'T00:00:00')\n",
    "    hostname='SysClient0660'\n",
    "    datalabel='benign'\n",
    "    # Create SQL query command\n",
    "    sql=f\"\"\"\n",
    "    select * from event_table\n",
    "    where\n",
    "          timestamp>{start_timestamp} and timestamp<{end_timestamp}\n",
    "          and hostname='{hostname}' and data_label='{datalabel}' ORDER BY timestamp;\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute SQL query\n",
    "    cur.execute(sql)\n",
    "    events = cur.fetchall()\n",
    "    print(f\"{len(events)=}\")\n",
    "    \n",
    "    \n",
    "    # Generate local temporal graph node indexes mapping\n",
    "    node_set=set()\n",
    "    node_uuid2index={}\n",
    "    temp_index=0\n",
    "    for e in events:\n",
    "        if e[3] not in node_uuid2path or e[0]  not in node_uuid2path:\n",
    "            continue\n",
    "\n",
    "        if e[0] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[0]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[0]]\n",
    "            temp_index+=1\n",
    "\n",
    "        if e[3] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[3]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[3]]\n",
    "            temp_index+=1 \n",
    "\n",
    "    torch.save(node_uuid2index,f'node_uuid2index_9_{day}_host={hostname}_datalabel={datalabel}')\n",
    "       \n",
    "\n",
    "    dataset = TemporalData()\n",
    "    src = []\n",
    "    dst = []\n",
    "    msg = []\n",
    "    t = []\n",
    "    # Create temporal graph with nodes, edges, messages and times\n",
    "    for e in (events):\n",
    "        if e[3] in node_uuid2index and e[0] in node_uuid2index:\n",
    "            # If the image path of the node is not recorded, then skip this edge\n",
    "            src.append(node_uuid2index[e[0]])\n",
    "            dst.append(node_uuid2index[e[3]])\n",
    "        #     msg.append(torch.cat([torch.from_numpy(node2higvec_bn[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec_bn[i[1]])] ))\n",
    "\n",
    "            msg.append(torch.cat([str2tensor(e[1],node_uuid2path[e[0]]), \n",
    "                                  edge2vec[e[2]], \n",
    "                                  str2tensor(e[4],node_uuid2path[e[3]])\n",
    "                                 ]))\n",
    "            t.append(int(e[6]))\n",
    "\n",
    "    dataset.src = torch.tensor(src)\n",
    "    dataset.dst = torch.tensor(dst)\n",
    "    dataset.t = torch.tensor(t)\n",
    "    dataset.msg = torch.vstack(msg)\n",
    "    dataset.src = dataset.src.to(torch.long)\n",
    "    dataset.dst = dataset.dst.to(torch.long)\n",
    "    dataset.msg = dataset.msg.to(torch.float)\n",
    "    dataset.t = dataset.t.to(torch.long)\n",
    "    # Store temporal graph in disk\n",
    "    torch.save(dataset, f\"/home/shahidul2k9/data/optc/out/evaluation/9_{day}_host={hostname}_datalabel={datalabel}.TemporalData\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h501 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(events)=4337416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [23:52<00:00, 1432.56s/it]\n"
     ]
    }
   ],
   "source": [
    "# Read benign dataset generated by host SysClient0501 on 21st September 2019 and create temporal graph\n",
    "for day in tqdm(range(21,22)):\n",
    "    start_timestamp=datetime_to_timestamp_US('2019-09-'+str(day)+'T00:00:00')\n",
    "    end_timestamp=datetime_to_timestamp_US('2019-09-'+str(day+1)+'T00:00:00')\n",
    "    hostname='SysClient0501'\n",
    "    datalabel='benign'\n",
    "    # Create SQL query command\n",
    "    sql=f\"\"\"\n",
    "    select * from event_table\n",
    "    where\n",
    "          timestamp>{start_timestamp} and timestamp<{end_timestamp}\n",
    "          and hostname='{hostname}' and data_label='{datalabel}' ORDER BY timestamp;\n",
    "    \"\"\"\n",
    "    # Execute SQL query\n",
    "    cur.execute(sql)\n",
    "    events = cur.fetchall()\n",
    "    print(f\"{len(events)=}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    node_set=set()\n",
    "    node_uuid2index={}\n",
    "    temp_index=0\n",
    "    for e in events:\n",
    "        if e[3] not in node_uuid2path or e[0]  not in node_uuid2path:\n",
    "            continue\n",
    "\n",
    "        if e[0] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[0]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[0]]\n",
    "            temp_index+=1\n",
    "\n",
    "        if e[3] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[3]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[3]]\n",
    "            temp_index+=1 \n",
    "\n",
    "    torch.save(node_uuid2index,f'node_uuid2index_9_{day}_host={hostname}_datalabel={datalabel}')\n",
    "       \n",
    "\n",
    "    dataset = TemporalData()\n",
    "    src = []\n",
    "    dst = []\n",
    "    msg = []\n",
    "    t = []\n",
    "    # Create temporal graph with nodes, edges, messages and times\n",
    "    for e in (events):\n",
    "        if e[3] in node_uuid2index and e[0] in node_uuid2index:\n",
    "            # If the image path of the node is not recorded, then skip this edge\n",
    "            src.append(node_uuid2index[e[0]])\n",
    "            dst.append(node_uuid2index[e[3]])\n",
    "        #     msg.append(torch.cat([torch.from_numpy(node2higvec_bn[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec_bn[i[1]])] ))\n",
    "\n",
    "            msg.append(torch.cat([str2tensor(e[1],node_uuid2path[e[0]]), \n",
    "                                  edge2vec[e[2]], \n",
    "                                  str2tensor(e[4],node_uuid2path[e[3]])\n",
    "                                 ]))\n",
    "            t.append(int(e[6]))\n",
    "\n",
    "    dataset.src = torch.tensor(src)\n",
    "    dataset.dst = torch.tensor(dst)\n",
    "    dataset.t = torch.tensor(t)\n",
    "    dataset.msg = torch.vstack(msg)\n",
    "    dataset.src = dataset.src.to(torch.long)\n",
    "    dataset.dst = dataset.dst.to(torch.long)\n",
    "    dataset.msg = dataset.msg.to(torch.float)\n",
    "    dataset.t = dataset.t.to(torch.long)\n",
    "    # Store temporal graph in disk\n",
    "    torch.save(dataset, f\"/home/shahidul2k9/data/optc/out/evaluation/9_{day}_host={hostname}_datalabel={datalabel}.TemporalData\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h501 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(events)=4263136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [24:09<00:00, 1449.94s/it]\n"
     ]
    }
   ],
   "source": [
    "# Read benign dataset generated by host SysClient0501 on 22nd September 2019 and create temporal graph\n",
    "for day in tqdm(range(22,23)):\n",
    "    start_timestamp=datetime_to_timestamp_US('2019-09-'+str(day)+'T00:00:00')\n",
    "    end_timestamp=datetime_to_timestamp_US('2019-09-'+str(day+1)+'T00:00:00')\n",
    "    hostname='SysClient0501'\n",
    "    datalabel='benign'\n",
    "    # Create SQL query command\n",
    "    sql=f\"\"\"\n",
    "    select * from event_table\n",
    "    where\n",
    "          timestamp>{start_timestamp} and timestamp<{end_timestamp}\n",
    "          and hostname='{hostname}' and data_label='{datalabel}' ORDER BY timestamp;\n",
    "    \"\"\"\n",
    "    # Execute SQL query\n",
    "    cur.execute(sql)\n",
    "    events = cur.fetchall()\n",
    "    print(f\"{len(events)=}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    node_set=set()\n",
    "    node_uuid2index={}\n",
    "    temp_index=0\n",
    "    # Generate local temporal graph node indexes mapping\n",
    "    for e in events:\n",
    "        if e[3] not in node_uuid2path or e[0]  not in node_uuid2path:\n",
    "            continue\n",
    "\n",
    "        if e[0] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[0]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[0]]\n",
    "            temp_index+=1\n",
    "\n",
    "        if e[3] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[3]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[3]]\n",
    "            temp_index+=1 \n",
    "\n",
    "    torch.save(node_uuid2index,f'node_uuid2index_9_{day}_host={hostname}_datalabel={datalabel}')\n",
    "\n",
    "    dataset = TemporalData()\n",
    "    src = []\n",
    "    dst = []\n",
    "    msg = []\n",
    "    t = []\n",
    "    # Create temporal graph with nodes, edges, messages and times\n",
    "    for e in (events):\n",
    "        if e[3] in node_uuid2index and e[0] in node_uuid2index:\n",
    "            # If the image path of the node is not recorded, then skip this edge\n",
    "            src.append(node_uuid2index[e[0]])\n",
    "            dst.append(node_uuid2index[e[3]])\n",
    "        #     msg.append(torch.cat([torch.from_numpy(node2higvec_bn[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec_bn[i[1]])] ))\n",
    "\n",
    "            msg.append(torch.cat([str2tensor(e[1],node_uuid2path[e[0]]), \n",
    "                                  edge2vec[e[2]], \n",
    "                                  str2tensor(e[4],node_uuid2path[e[3]])\n",
    "                                 ]))\n",
    "            t.append(int(e[6]))\n",
    "\n",
    "    dataset.src = torch.tensor(src)\n",
    "    dataset.dst = torch.tensor(dst)\n",
    "    dataset.t = torch.tensor(t)\n",
    "    dataset.msg = torch.vstack(msg)\n",
    "    dataset.src = dataset.src.to(torch.long)\n",
    "    dataset.dst = dataset.dst.to(torch.long)\n",
    "    dataset.msg = dataset.msg.to(torch.float)\n",
    "    dataset.t = dataset.t.to(torch.long)\n",
    "    # Store temporal graph in disk\n",
    "    torch.save(dataset, f\"/home/shahidul2k9/data/optc/out/evaluation/9_{day}_host={hostname}_datalabel={datalabel}.TemporalData\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h051 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(events)=4074941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [22:32<00:00, 1352.34s/it]\n"
     ]
    }
   ],
   "source": [
    "# Read benign dataset generated by host SysClient0051 on 22nd September 2019 and create temporal graph\n",
    "for day in tqdm(range(22,23)):\n",
    "    start_timestamp=datetime_to_timestamp_US('2019-09-'+str(day)+'T00:00:00')\n",
    "    end_timestamp=datetime_to_timestamp_US('2019-09-'+str(day+1)+'T00:00:00')\n",
    "    hostname='SysClient0051'\n",
    "    datalabel='benign'\n",
    "    # Create SQL query command\n",
    "    sql=f\"\"\"\n",
    "    select * from event_table\n",
    "    where\n",
    "          timestamp>{start_timestamp} and timestamp<{end_timestamp}\n",
    "          and hostname='{hostname}' and data_label='{datalabel}' ORDER BY timestamp;\n",
    "    \"\"\"\n",
    "    # Execute SQL query\n",
    "    cur.execute(sql)\n",
    "    events = cur.fetchall()\n",
    "    print(f\"{len(events)=}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    node_set=set()\n",
    "    node_uuid2index={}\n",
    "    temp_index=0\n",
    "    # Generate local temporal graph node indexes mapping\n",
    "    for e in events:\n",
    "        if e[3] not in node_uuid2path or e[0]  not in node_uuid2path:\n",
    "            continue\n",
    "\n",
    "        if e[0] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[0]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[0]]\n",
    "            temp_index+=1\n",
    "\n",
    "        if e[3] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[3]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[3]]\n",
    "            temp_index+=1 \n",
    "\n",
    "    torch.save(node_uuid2index,f'node_uuid2index_9_{day}_host={hostname}_datalabel={datalabel}')\n",
    "       \n",
    "\n",
    "    dataset = TemporalData()\n",
    "    src = []\n",
    "    dst = []\n",
    "    msg = []\n",
    "    t = []\n",
    "    # Create temporal graph with nodes, edges, messages and times\n",
    "    for e in (events):\n",
    "        if e[3] in node_uuid2index and e[0] in node_uuid2index:\n",
    "            # If the image path of the node is not recorded, then skip this edge\n",
    "            src.append(node_uuid2index[e[0]])\n",
    "            dst.append(node_uuid2index[e[3]])\n",
    "        #     msg.append(torch.cat([torch.from_numpy(node2higvec_bn[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec_bn[i[1]])] ))\n",
    "\n",
    "            msg.append(torch.cat([str2tensor(e[1],node_uuid2path[e[0]]), \n",
    "                                  edge2vec[e[2]], \n",
    "                                  str2tensor(e[4],node_uuid2path[e[3]])\n",
    "                                 ]))\n",
    "            t.append(int(e[6]))\n",
    "\n",
    "    dataset.src = torch.tensor(src)\n",
    "    dataset.dst = torch.tensor(dst)\n",
    "    dataset.t = torch.tensor(t)\n",
    "    dataset.msg = torch.vstack(msg)\n",
    "    dataset.src = dataset.src.to(torch.long)\n",
    "    dataset.dst = dataset.dst.to(torch.long)\n",
    "    dataset.msg = dataset.msg.to(torch.float)\n",
    "    dataset.t = dataset.t.to(torch.long)\n",
    "    # Store temporal graph in disk\n",
    "    torch.save(dataset, f\"/home/shahidul2k9/data/optc/out/evaluation/9_{day}_host={hostname}_datalabel={datalabel}.TemporalData\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h209 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(events)=3853947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [21:45<00:00, 1305.96s/it]\n"
     ]
    }
   ],
   "source": [
    "# Read benign dataset generated by host SysClient0209 on 22nd September 2019 and create temporal graph\n",
    "for day in tqdm(range(22,23)):\n",
    "    start_timestamp=datetime_to_timestamp_US('2019-09-'+str(day)+'T00:00:00')\n",
    "    end_timestamp=datetime_to_timestamp_US('2019-09-'+str(day+1)+'T00:00:00')\n",
    "    hostname='SysClient0209'\n",
    "    datalabel='benign'\n",
    "    # Create SQL query command\n",
    "    sql=f\"\"\"\n",
    "    select * from event_table\n",
    "    where\n",
    "          timestamp>{start_timestamp} and timestamp<{end_timestamp}\n",
    "          and hostname='{hostname}' and data_label='{datalabel}' ORDER BY timestamp;\n",
    "    \"\"\"\n",
    "    cur.execute(sql)\n",
    "    events = cur.fetchall()\n",
    "    print(f\"{len(events)=}\")\n",
    "    \n",
    "    # Generate local temporal graph node indexes mapping\n",
    "    node_set=set()\n",
    "    node_uuid2index={}\n",
    "    temp_index=0\n",
    "    for e in events:\n",
    "        if e[3] not in node_uuid2path or e[0]  not in node_uuid2path:\n",
    "            continue\n",
    "\n",
    "        if e[0] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[0]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[0]]\n",
    "            temp_index+=1\n",
    "\n",
    "        if e[3] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[3]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[3]]\n",
    "            temp_index+=1 \n",
    "\n",
    "    torch.save(node_uuid2index,f'node_uuid2index_9_{day}_host={hostname}_datalabel={datalabel}')\n",
    "       \n",
    "\n",
    "    dataset = TemporalData()\n",
    "    src = []\n",
    "    dst = []\n",
    "    msg = []\n",
    "    t = []\n",
    "    # Create temporal graph with nodes, edges, messages and times\n",
    "    for e in (events):\n",
    "        if e[3] in node_uuid2index and e[0] in node_uuid2index:\n",
    "            # If the image path of the node is not recorded, then skip this edge\n",
    "            src.append(node_uuid2index[e[0]])\n",
    "            dst.append(node_uuid2index[e[3]])\n",
    "        #     msg.append(torch.cat([torch.from_numpy(node2higvec_bn[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec_bn[i[1]])] ))\n",
    "\n",
    "            msg.append(torch.cat([str2tensor(e[1],node_uuid2path[e[0]]), \n",
    "                                  edge2vec[e[2]], \n",
    "                                  str2tensor(e[4],node_uuid2path[e[3]])\n",
    "                                 ]))\n",
    "            t.append(int(e[6]))\n",
    "\n",
    "    dataset.src = torch.tensor(src)\n",
    "    dataset.dst = torch.tensor(dst)\n",
    "    dataset.t = torch.tensor(t)\n",
    "    dataset.msg = torch.vstack(msg)\n",
    "    dataset.src = dataset.src.to(torch.long)\n",
    "    dataset.dst = dataset.dst.to(torch.long)\n",
    "    dataset.msg = dataset.msg.to(torch.float)\n",
    "    dataset.t = dataset.t.to(torch.long)\n",
    "    # Store temporal graph in disk\n",
    "    torch.save(dataset, f\"/home/shahidul2k9/data/optc/out/evaluation/9_{day}_host={hostname}_datalabel={datalabel}.TemporalData\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h209 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(events)=1462775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [09:01<00:00, 541.35s/it]\n"
     ]
    }
   ],
   "source": [
    "# Read benign dataset generated by host SysClient0209 on 23rd September 2019 and create temporal graph\n",
    "for day in tqdm(range(23,24)):\n",
    "    start_timestamp=datetime_to_timestamp_US('2019-09-'+str(day)+'T00:00:00')\n",
    "    end_timestamp=datetime_to_timestamp_US('2019-09-'+str(day+1)+'T00:00:00')\n",
    "    hostname='SysClient0209'\n",
    "    datalabel='benign'\n",
    "    # Create SQL query command\n",
    "    sql=f\"\"\"\n",
    "    select * from event_table\n",
    "    where\n",
    "          timestamp>{start_timestamp} and timestamp<{end_timestamp}\n",
    "          and hostname='{hostname}' and data_label='{datalabel}' ORDER BY timestamp;\n",
    "    \"\"\"\n",
    "    # Execute SQL query\n",
    "    cur.execute(sql)\n",
    "    events = cur.fetchall()\n",
    "    print(f\"{len(events)=}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    node_set=set()\n",
    "    node_uuid2index={}\n",
    "    temp_index=0\n",
    "    # Generate local temporal graph node indexes mapping\n",
    "    for e in events:\n",
    "        if e[3] not in node_uuid2path or e[0]  not in node_uuid2path:\n",
    "            continue\n",
    "\n",
    "        if e[0] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[0]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[0]]\n",
    "            temp_index+=1\n",
    "\n",
    "        if e[3] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[3]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[3]]\n",
    "            temp_index+=1 \n",
    "\n",
    "    torch.save(node_uuid2index,f'node_uuid2index_9_{day}_host={hostname}_datalabel={datalabel}')\n",
    "       \n",
    "\n",
    "    dataset = TemporalData()\n",
    "    src = []\n",
    "    dst = []\n",
    "    msg = []\n",
    "    t = []\n",
    "    # Create temporal graph with nodes, edges, messages and times\n",
    "    for e in (events):\n",
    "        if e[3] in node_uuid2index and e[0] in node_uuid2index:\n",
    "            # If the image path of the node is not recorded, then skip this edge\n",
    "            src.append(node_uuid2index[e[0]])\n",
    "            dst.append(node_uuid2index[e[3]])\n",
    "        #     msg.append(torch.cat([torch.from_numpy(node2higvec_bn[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec_bn[i[1]])] ))\n",
    "\n",
    "            msg.append(torch.cat([str2tensor(e[1],node_uuid2path[e[0]]), \n",
    "                                  edge2vec[e[2]], \n",
    "                                  str2tensor(e[4],node_uuid2path[e[3]])\n",
    "                                 ]))\n",
    "            t.append(int(e[6]))\n",
    "\n",
    "    dataset.src = torch.tensor(src)\n",
    "    dataset.dst = torch.tensor(dst)\n",
    "    dataset.t = torch.tensor(t)\n",
    "    dataset.msg = torch.vstack(msg)\n",
    "    dataset.src = dataset.src.to(torch.long)\n",
    "    dataset.dst = dataset.dst.to(torch.long)\n",
    "    dataset.msg = dataset.msg.to(torch.float)\n",
    "    dataset.t = dataset.t.to(torch.long)\n",
    "    # Store temporal graph in disk\n",
    "    torch.save(dataset, f\"/home/shahidul2k9/data/optc/out/evaluation/9_{day}_host={hostname}_datalabel={datalabel}.TemporalData\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the evaluation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h201 23-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(events)=2354159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [13:12<26:25, 792.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(events)=3720913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [34:13<17:48, 1068.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(events)=2195398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [46:37<00:00, 932.51s/it] \n"
     ]
    }
   ],
   "source": [
    "# Read evaluation dataset generated by host SysClient0201 on 23rd-25th September 2019 and create temporal graph\n",
    "for day in tqdm(range(23,26)):\n",
    "    start_timestamp=datetime_to_timestamp_US('2019-09-'+str(day)+'T00:00:00')\n",
    "    end_timestamp=datetime_to_timestamp_US('2019-09-'+str(day+1)+'T00:00:00')\n",
    "    hostname='SysClient0201'\n",
    "    datalabel='evaluation'\n",
    "    # Create SQL query command\n",
    "    sql=f\"\"\"\n",
    "    select * from event_table\n",
    "    where\n",
    "          timestamp>{start_timestamp} and timestamp<{end_timestamp}\n",
    "          and hostname='{hostname}' and data_label='{datalabel}' ORDER BY timestamp;\n",
    "    \"\"\"\n",
    "    # Execute SQL query\n",
    "    cur.execute(sql)\n",
    "    events = cur.fetchall()\n",
    "    print(f\"{len(events)=}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    node_set=set()\n",
    "    node_uuid2index={}\n",
    "    temp_index=0\n",
    "    # Generate local temporal graph node indexes mapping\n",
    "    for e in events:\n",
    "        if e[3] not in node_uuid2path or e[0]  not in node_uuid2path:\n",
    "            continue\n",
    "\n",
    "        if e[0] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[0]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[0]]\n",
    "            temp_index+=1\n",
    "\n",
    "        if e[3] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[3]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[3]]\n",
    "            temp_index+=1 \n",
    "\n",
    "    torch.save(node_uuid2index,f'node_uuid2index_9_{day}_host={hostname}_datalabel={datalabel}')\n",
    "\n",
    "    dataset = TemporalData()\n",
    "    src = []\n",
    "    dst = []\n",
    "    msg = []\n",
    "    t = []\n",
    "    # Create temporal graph with nodes, edges, messages and times\n",
    "    for e in (events):\n",
    "        if e[3] in node_uuid2index and e[0] in node_uuid2index:\n",
    "            # If the image path of the node is not recorded, then skip this edge\n",
    "            src.append(node_uuid2index[e[0]])\n",
    "            dst.append(node_uuid2index[e[3]])\n",
    "        #     msg.append(torch.cat([torch.from_numpy(node2higvec_bn[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec_bn[i[1]])] ))\n",
    "\n",
    "            msg.append(torch.cat([str2tensor(e[1],node_uuid2path[e[0]]), \n",
    "                                  edge2vec[e[2]], \n",
    "                                  str2tensor(e[4],node_uuid2path[e[3]])\n",
    "                                 ]))\n",
    "            t.append(int(e[6]))\n",
    "\n",
    "    dataset.src = torch.tensor(src)\n",
    "    dataset.dst = torch.tensor(dst)\n",
    "    dataset.t = torch.tensor(t)\n",
    "    dataset.msg = torch.vstack(msg)\n",
    "    dataset.src = dataset.src.to(torch.long)\n",
    "    dataset.dst = dataset.dst.to(torch.long)\n",
    "    dataset.msg = dataset.msg.to(torch.float)\n",
    "    dataset.t = dataset.t.to(torch.long)\n",
    "    # Store temporal graph in disk\n",
    "    torch.save(dataset, f\"/home/shahidul2k9/data/optc/out/evaluation/9_{day}_host={hostname}_datalabel={datalabel}.TemporalData\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h402 23-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(events)=2513800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [14:04<28:08, 844.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(events)=3844461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [35:05<18:09, 1089.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(events)=2317807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [48:59<00:00, 979.86s/it] \n"
     ]
    }
   ],
   "source": [
    "# Read evaluation dataset generated by host SysClient0402 on 23rd-25th September 2019 and create temporal graph\n",
    "for day in tqdm(range(23,26)):\n",
    "    start_timestamp=datetime_to_timestamp_US('2019-09-'+str(day)+'T00:00:00')\n",
    "    end_timestamp=datetime_to_timestamp_US('2019-09-'+str(day+1)+'T00:00:00')\n",
    "    hostname='SysClient0402'\n",
    "    datalabel='evaluation'\n",
    "    # Create SQL query command\n",
    "    sql=f\"\"\"\n",
    "    select * from event_table\n",
    "    where\n",
    "          timestamp>{start_timestamp} and timestamp<{end_timestamp}\n",
    "          and hostname='{hostname}' and data_label='{datalabel}' ORDER BY timestamp;\n",
    "    \"\"\"\n",
    "    # Execute SQL query\n",
    "    cur.execute(sql)\n",
    "    events = cur.fetchall()\n",
    "    print(f\"{len(events)=}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    node_set=set()\n",
    "    node_uuid2index={}\n",
    "    temp_index=0\n",
    "    # Generate local temporal graph node indexes mapping\n",
    "    for e in events:\n",
    "        if e[3] not in node_uuid2path or e[0]  not in node_uuid2path:\n",
    "            continue\n",
    "\n",
    "        if e[0] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[0]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[0]]\n",
    "            temp_index+=1\n",
    "\n",
    "        if e[3] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[3]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[3]]\n",
    "            temp_index+=1 \n",
    "\n",
    "    torch.save(node_uuid2index,f'node_uuid2index_9_{day}_host={hostname}_datalabel={datalabel}')\n",
    "       \n",
    "\n",
    "    dataset = TemporalData()\n",
    "    src = []\n",
    "    dst = []\n",
    "    msg = []\n",
    "    t = []\n",
    "    # Create temporal graph with nodes, edges, messages and times\n",
    "    for e in (events):\n",
    "        if e[3] in node_uuid2index and e[0] in node_uuid2index:\n",
    "            # If the image path of the node is not recorded, then skip this edge\n",
    "            src.append(node_uuid2index[e[0]])\n",
    "            dst.append(node_uuid2index[e[3]])\n",
    "        #     msg.append(torch.cat([torch.from_numpy(node2higvec_bn[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec_bn[i[1]])] ))\n",
    "\n",
    "            msg.append(torch.cat([str2tensor(e[1],node_uuid2path[e[0]]), \n",
    "                                  edge2vec[e[2]], \n",
    "                                  str2tensor(e[4],node_uuid2path[e[3]])\n",
    "                                 ]))\n",
    "            t.append(int(e[6]))\n",
    "\n",
    "    dataset.src = torch.tensor(src)\n",
    "    dataset.dst = torch.tensor(dst)\n",
    "    dataset.t = torch.tensor(t)\n",
    "    dataset.msg = torch.vstack(msg)\n",
    "    dataset.src = dataset.src.to(torch.long)\n",
    "    dataset.dst = dataset.dst.to(torch.long)\n",
    "    dataset.msg = dataset.msg.to(torch.float)\n",
    "    dataset.t = dataset.t.to(torch.long)\n",
    "    # Store temporal graph in disk\n",
    "    torch.save(dataset, f\"/home/shahidul2k9/data/optc/out/evaluation/9_{day}_host={hostname}_datalabel={datalabel}.TemporalData\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h660 23-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(events)=2317440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [13:32<27:04, 812.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(events)=3558940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [34:00<17:37, 1057.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(events)=2314759\n"
     ]
    }
   ],
   "source": [
    "# Read evaluation dataset generated by host SysClient0660 on 23rd-25th September 2019 and create temporal graph\n",
    "for day in tqdm(range(23,26)):\n",
    "    start_timestamp=datetime_to_timestamp_US('2019-09-'+str(day)+'T00:00:00')\n",
    "    end_timestamp=datetime_to_timestamp_US('2019-09-'+str(day+1)+'T00:00:00')\n",
    "    hostname='SysClient0660'\n",
    "    datalabel='evaluation'\n",
    "    # Create SQL query command\n",
    "    sql=f\"\"\"\n",
    "    select * from event_table\n",
    "    where\n",
    "          timestamp>{start_timestamp} and timestamp<{end_timestamp}\n",
    "          and hostname='{hostname}' and data_label='{datalabel}' ORDER BY timestamp;\n",
    "    \"\"\"\n",
    "    # Execute SQL query\n",
    "    cur.execute(sql)\n",
    "    events = cur.fetchall()\n",
    "    print(f\"{len(events)=}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    node_set=set()\n",
    "    node_uuid2index={}\n",
    "    temp_index=0\n",
    "    # Generate local temporal graph node indexes mapping\n",
    "    for e in events:\n",
    "        if e[3] not in node_uuid2path or e[0]  not in node_uuid2path:\n",
    "            continue\n",
    "\n",
    "        if e[0] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[0]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[0]]\n",
    "            temp_index+=1\n",
    "\n",
    "        if e[3] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[3]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[3]]\n",
    "            temp_index+=1 \n",
    "\n",
    "    torch.save(node_uuid2index,f'node_uuid2index_9_{day}_host={hostname}_datalabel={datalabel}')\n",
    "       \n",
    "\n",
    "    dataset = TemporalData()\n",
    "    src = []\n",
    "    dst = []\n",
    "    msg = []\n",
    "    t = []\n",
    "    # Create temporal graph with nodes, edges, messages and times\n",
    "    for e in (events):\n",
    "        if e[3] in node_uuid2index and e[0] in node_uuid2index:\n",
    "            # If the image path of the node is not recorded, then skip this edge\n",
    "            src.append(node_uuid2index[e[0]])\n",
    "            dst.append(node_uuid2index[e[3]])\n",
    "        #     msg.append(torch.cat([torch.from_numpy(node2higvec_bn[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec_bn[i[1]])] ))\n",
    "\n",
    "            msg.append(torch.cat([str2tensor(e[1],node_uuid2path[e[0]]), \n",
    "                                  edge2vec[e[2]], \n",
    "                                  str2tensor(e[4],node_uuid2path[e[3]])\n",
    "                                 ]))\n",
    "            t.append(int(e[6]))\n",
    "\n",
    "    dataset.src = torch.tensor(src)\n",
    "    dataset.dst = torch.tensor(dst)\n",
    "    dataset.t = torch.tensor(t)\n",
    "    dataset.msg = torch.vstack(msg)\n",
    "    dataset.src = dataset.src.to(torch.long)\n",
    "    dataset.dst = dataset.dst.to(torch.long)\n",
    "    dataset.msg = dataset.msg.to(torch.float)\n",
    "    dataset.t = dataset.t.to(torch.long)\n",
    "    # Store temporal graph in disk\n",
    "    torch.save(dataset, f\"/home/shahidul2k9/data/optc/out/evaluation/9_{day}_host={hostname}_datalabel={datalabel}.TemporalData\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h501 23-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read evaluation dataset generated by host SysClient0501 on 23rd-25th September 2019 and create temporal graph\n",
    "for day in tqdm(range(23,26)):\n",
    "    start_timestamp=datetime_to_timestamp_US('2019-09-'+str(day)+'T00:00:00')\n",
    "    end_timestamp=datetime_to_timestamp_US('2019-09-'+str(day+1)+'T00:00:00')\n",
    "    hostname='SysClient0501'\n",
    "    datalabel='evaluation'\n",
    "    # Create SQL query command\n",
    "    sql=f\"\"\"\n",
    "    select * from event_table\n",
    "    where\n",
    "          timestamp>{start_timestamp} and timestamp<{end_timestamp}\n",
    "          and hostname='{hostname}' and data_label='{datalabel}' ORDER BY timestamp;\n",
    "    \"\"\"\n",
    "    # Execute SQL query\n",
    "    cur.execute(sql)\n",
    "    events = cur.fetchall()\n",
    "    print(f\"{len(events)=}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    node_set=set()\n",
    "    node_uuid2index={}\n",
    "    temp_index=0\n",
    "    for e in events:\n",
    "        if e[3] not in node_uuid2path or e[0]  not in node_uuid2path:\n",
    "            continue\n",
    "\n",
    "        if e[0] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[0]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[0]]\n",
    "            temp_index+=1\n",
    "\n",
    "        if e[3] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[3]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[3]]\n",
    "            temp_index+=1 \n",
    "\n",
    "    torch.save(node_uuid2index,f'node_uuid2index_9_{day}_host={hostname}_datalabel={datalabel}')\n",
    "       \n",
    "\n",
    "    dataset = TemporalData()\n",
    "    src = []\n",
    "    dst = []\n",
    "    msg = []\n",
    "    t = []\n",
    "    # Generate local temporal graph node indexes mapping\n",
    "    for e in (events):\n",
    "        if e[3] in node_uuid2index and e[0] in node_uuid2index:\n",
    "            # If the image path of the node is not recorded, then skip this edge\n",
    "            src.append(node_uuid2index[e[0]])\n",
    "            dst.append(node_uuid2index[e[3]])\n",
    "        #     msg.append(torch.cat([torch.from_numpy(node2higvec_bn[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec_bn[i[1]])] ))\n",
    "\n",
    "            msg.append(torch.cat([str2tensor(e[1],node_uuid2path[e[0]]), \n",
    "                                  edge2vec[e[2]], \n",
    "                                  str2tensor(e[4],node_uuid2path[e[3]])\n",
    "                                 ]))\n",
    "            t.append(int(e[6]))\n",
    "\n",
    "    dataset.src = torch.tensor(src)\n",
    "    dataset.dst = torch.tensor(dst)\n",
    "    dataset.t = torch.tensor(t)\n",
    "    dataset.msg = torch.vstack(msg)\n",
    "    dataset.src = dataset.src.to(torch.long)\n",
    "    dataset.dst = dataset.dst.to(torch.long)\n",
    "    dataset.msg = dataset.msg.to(torch.float)\n",
    "    dataset.t = dataset.t.to(torch.long)\n",
    "    # Store temporal graph in disk\n",
    "    torch.save(dataset, f\"/home/shahidul2k9/data/optc/out/evaluation/9_{day}_host={hostname}_datalabel={datalabel}.TemporalData\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h051 23-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read evaluation dataset generated by host SysClient0051 on 23rd-25th September 2019 and create temporal graph\n",
    "for day in tqdm(range(23,26)):\n",
    "    start_timestamp=datetime_to_timestamp_US('2019-09-'+str(day)+'T00:00:00')\n",
    "    end_timestamp=datetime_to_timestamp_US('2019-09-'+str(day+1)+'T00:00:00')\n",
    "    hostname='SysClient0051'\n",
    "    datalabel='evaluation'\n",
    "    # Create SQL query command\n",
    "    sql=f\"\"\"\n",
    "    select * from event_table\n",
    "    where\n",
    "          timestamp>{start_timestamp} and timestamp<{end_timestamp}\n",
    "          and hostname='{hostname}' and data_label='{datalabel}' ORDER BY timestamp;\n",
    "    \"\"\"\n",
    "    # Execute SQL query\n",
    "    cur.execute(sql)\n",
    "    events = cur.fetchall()\n",
    "    print(f\"{len(events)=}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    node_set=set()\n",
    "    node_uuid2index={}\n",
    "    temp_index=0\n",
    "    # Generate local temporal graph node indexes mapping\n",
    "    for e in events:\n",
    "        if e[3] not in node_uuid2path or e[0]  not in node_uuid2path:\n",
    "            continue\n",
    "\n",
    "        if e[0] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[0]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[0]]\n",
    "            temp_index+=1\n",
    "\n",
    "        if e[3] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[3]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[3]]\n",
    "            temp_index+=1 \n",
    "\n",
    "    torch.save(node_uuid2index,f'node_uuid2index_9_{day}_host={hostname}_datalabel={datalabel}')\n",
    "       \n",
    "\n",
    "    dataset = TemporalData()\n",
    "    src = []\n",
    "    dst = []\n",
    "    msg = []\n",
    "    t = []\n",
    "    # Create temporal graph with nodes, edges, messages and times\n",
    "    for e in (events):\n",
    "        if e[3] in node_uuid2index and e[0] in node_uuid2index:\n",
    "            # If the image path of the node is not recorded, then skip this edge\n",
    "            src.append(node_uuid2index[e[0]])\n",
    "            dst.append(node_uuid2index[e[3]])\n",
    "        #     msg.append(torch.cat([torch.from_numpy(node2higvec_bn[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec_bn[i[1]])] ))\n",
    "\n",
    "            msg.append(torch.cat([str2tensor(e[1],node_uuid2path[e[0]]), \n",
    "                                  edge2vec[e[2]], \n",
    "                                  str2tensor(e[4],node_uuid2path[e[3]])\n",
    "                                 ]))\n",
    "            t.append(int(e[6]))\n",
    "\n",
    "    dataset.src = torch.tensor(src)\n",
    "    dataset.dst = torch.tensor(dst)\n",
    "    dataset.t = torch.tensor(t)\n",
    "    dataset.msg = torch.vstack(msg)\n",
    "    dataset.src = dataset.src.to(torch.long)\n",
    "    dataset.dst = dataset.dst.to(torch.long)\n",
    "    dataset.msg = dataset.msg.to(torch.float)\n",
    "    dataset.t = dataset.t.to(torch.long)\n",
    "    # Store temporal graph in disk\n",
    "    torch.save(dataset, f\"/home/shahidul2k9/data/optc/out/evaluation/9_{day}_host={hostname}_datalabel={datalabel}.TemporalData\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h207 23-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read evaluation dataset generated by host SysClient0207 on 23rd-25th September 2019 and create temporal graph\n",
    "for day in tqdm(range(23,26)):\n",
    "    start_timestamp=datetime_to_timestamp_US('2019-09-'+str(day)+'T00:00:00')\n",
    "    end_timestamp=datetime_to_timestamp_US('2019-09-'+str(day+1)+'T00:00:00')\n",
    "    hostname='SysClient0207'\n",
    "    datalabel='evaluation'\n",
    "    # Create SQL query command\n",
    "    sql=f\"\"\"\n",
    "    select * from event_table\n",
    "    where\n",
    "          timestamp>{start_timestamp} and timestamp<{end_timestamp}\n",
    "          and hostname='{hostname}' and data_label='{datalabel}' ORDER BY timestamp;\n",
    "    \"\"\"\n",
    "    # Execute SQL query\n",
    "    cur.execute(sql)\n",
    "    events = cur.fetchall()\n",
    "    print(f\"{len(events)=}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    node_set=set()\n",
    "    node_uuid2index={}\n",
    "    temp_index=0\n",
    "    # Generate local temporal graph node indexes mapping\n",
    "    for e in events:\n",
    "        if e[3] not in node_uuid2path or e[0]  not in node_uuid2path:\n",
    "            continue\n",
    "\n",
    "        if e[0] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[0]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[0]]\n",
    "            temp_index+=1\n",
    "\n",
    "        if e[3] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[3]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[3]]\n",
    "            temp_index+=1 \n",
    "\n",
    "    torch.save(node_uuid2index,f'node_uuid2index_9_{day}_host={hostname}_datalabel={datalabel}')\n",
    "       \n",
    "\n",
    "    dataset = TemporalData()\n",
    "    src = []\n",
    "    dst = []\n",
    "    msg = []\n",
    "    t = []\n",
    "    # Create temporal graph with nodes, edges, messages and times\n",
    "    for e in (events):\n",
    "        if e[3] in node_uuid2index and e[0] in node_uuid2index:\n",
    "            # If the image path of the node is not recorded, then skip this edge\n",
    "            src.append(node_uuid2index[e[0]])\n",
    "            dst.append(node_uuid2index[e[3]])\n",
    "        #     msg.append(torch.cat([torch.from_numpy(node2higvec_bn[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec_bn[i[1]])] ))\n",
    "\n",
    "            msg.append(torch.cat([str2tensor(e[1],node_uuid2path[e[0]]), \n",
    "                                  edge2vec[e[2]], \n",
    "                                  str2tensor(e[4],node_uuid2path[e[3]])\n",
    "                                 ]))\n",
    "            t.append(int(e[6]))\n",
    "\n",
    "    dataset.src = torch.tensor(src)\n",
    "    dataset.dst = torch.tensor(dst)\n",
    "    dataset.t = torch.tensor(t)\n",
    "    dataset.msg = torch.vstack(msg)\n",
    "    dataset.src = dataset.src.to(torch.long)\n",
    "    dataset.dst = dataset.dst.to(torch.long)\n",
    "    dataset.msg = dataset.msg.to(torch.float)\n",
    "    dataset.t = dataset.t.to(torch.long)\n",
    "    # Store temporal graph in disk\n",
    "    torch.save(dataset, f\"/home/shahidul2k9/data/optc/out/evaluation/9_{day}_host={hostname}_datalabel={datalabel}.TemporalData\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A CSV file containing the ground truth nodes&edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load ground truth labels\n",
    "label_df=pd.read_csv(\"./labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log ground truth labels\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nodes_attack={}\n",
    "edges_attack_list=[]\n",
    "# Attack edge listing\n",
    "for idx,row in label_df.iterrows():\n",
    "    flag=False\n",
    "    if row['objectID'] in node_uuid2path:\n",
    "        nodes_attack[row['objectID']]=node_uuid2path[row['objectID']]\n",
    "        flag=True\n",
    "    if row['actorID'] in node_uuid2path:\n",
    "        nodes_attack[row['actorID']]=node_uuid2path[row['actorID']]\n",
    "        flag=True\n",
    "    if flag and row['action'] in edge2vec:    \n",
    "#         and row['action'] in edge2vec\n",
    "        temp_dic={}\n",
    "        temp_dic['src_uuid']=row['actorID']\n",
    "        temp_dic['dst_uuid']=row['objectID']\n",
    "        temp_dic['edge_type']=row['action']\n",
    "        temp_dic['timestamp']=datetime_to_timestamp_US(row['timestamp'])\n",
    "\n",
    "        edges_attack_list.append(temp_dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log number of attack edges\n",
    "len(edges_attack_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log number of attack nodes\n",
    "len(nodes_attack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics (Num of nodes and edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation temporal graph\n",
    "graph_9_22_h201=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_22_host=SysClient0201_datalabel=benign.TemporalData\")\n",
    "graph_9_22_h402=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_22_host=SysClient0402_datalabel=benign.TemporalData\")\n",
    "graph_9_22_h660=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_22_host=SysClient0660_datalabel=benign.TemporalData\")\n",
    "graph_9_22_h501=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_22_host=SysClient0501_datalabel=benign.TemporalData\")\n",
    "graph_9_22_h051=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_22_host=SysClient0051_datalabel=benign.TemporalData\")\n",
    "graph_9_22_h209=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_22_host=SysClient0209_datalabel=benign.TemporalData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation temporal graph\n",
    "graph_9_23_h201=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_23_host=SysClient0201_datalabel=evaluation.TemporalData\")\n",
    "graph_9_24_h201=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_24_host=SysClient0201_datalabel=evaluation.TemporalData\")\n",
    "graph_9_25_h201=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_25_host=SysClient0201_datalabel=evaluation.TemporalData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation temporal graph\n",
    "graph_9_23_h402=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_23_host=SysClient0402_datalabel=evaluation.TemporalData\")\n",
    "graph_9_24_h402=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_24_host=SysClient0402_datalabel=evaluation.TemporalData\")\n",
    "graph_9_25_h402=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_25_host=SysClient0402_datalabel=evaluation.TemporalData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation temporal graph\n",
    "graph_9_23_h660=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_23_host=SysClient0660_datalabel=evaluation.TemporalData\")\n",
    "graph_9_24_h660=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_24_host=SysClient0660_datalabel=evaluation.TemporalData\")\n",
    "graph_9_25_h660=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_25_host=SysClient0660_datalabel=evaluation.TemporalData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation temporal graph\n",
    "graph_9_23_h501=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_23_host=SysClient0501_datalabel=evaluation.TemporalData\")\n",
    "graph_9_24_h501=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_24_host=SysClient0501_datalabel=evaluation.TemporalData\")\n",
    "graph_9_25_h501=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_25_host=SysClient0501_datalabel=evaluation.TemporalData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation temporal graph\n",
    "graph_9_23_h051=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_23_host=SysClient0051_datalabel=evaluation.TemporalData\")\n",
    "graph_9_24_h051=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_24_host=SysClient0051_datalabel=evaluation.TemporalData\")\n",
    "graph_9_25_h051=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_25_host=SysClient0051_datalabel=evaluation.TemporalData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation temporal graph\n",
    "graph_9_23_h207=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_23_host=SysClient0207_datalabel=evaluation.TemporalData\")\n",
    "graph_9_24_h207=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_24_host=SysClient0207_datalabel=evaluation.TemporalData\")\n",
    "graph_9_25_h207=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_25_host=SysClient0207_datalabel=evaluation.TemporalData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of loaded temporal graphs\n",
    "graphs=[\n",
    "    graph_9_22_h201,\n",
    "    graph_9_22_h402,\n",
    "    graph_9_22_h660,\n",
    "    graph_9_22_h501,\n",
    "    graph_9_22_h051,\n",
    "    graph_9_22_h209,\n",
    "    \n",
    "    graph_9_23_h201,\n",
    "    graph_9_24_h201,\n",
    "    graph_9_25_h201,\n",
    "    \n",
    "    graph_9_23_h402,\n",
    "    graph_9_24_h402,\n",
    "    graph_9_25_h402,\n",
    "    \n",
    "    graph_9_23_h660,\n",
    "    graph_9_24_h660,\n",
    "    graph_9_25_h660,\n",
    "    \n",
    "    graph_9_23_h501,\n",
    "    graph_9_24_h501,\n",
    "    graph_9_25_h501,\n",
    "    \n",
    "    graph_9_23_h051,\n",
    "    graph_9_24_h051,\n",
    "    graph_9_25_h051,\n",
    "    \n",
    "    graph_9_23_h207,\n",
    "    graph_9_24_h207,\n",
    "    graph_9_25_h207,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total number of edges over all evaluation temporal graphs\n",
    "edges_count=0\n",
    "for g in graphs:\n",
    "     edges_count+=len(g.t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log temporal graphs edge count\n",
    "edges_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load unique node ID(UUID) to integer indexing\n",
    "node_uuid2index_9_22_h201=torch.load(\"node_uuid2index_9_22_host=SysClient0201_datalabel=benign\")\n",
    "node_uuid2index_9_22_h402=torch.load(\"node_uuid2index_9_22_host=SysClient0402_datalabel=benign\")\n",
    "node_uuid2index_9_22_h660=torch.load(\"node_uuid2index_9_22_host=SysClient0660_datalabel=benign\")\n",
    "node_uuid2index_9_22_h501=torch.load(\"node_uuid2index_9_22_host=SysClient0501_datalabel=benign\")\n",
    "node_uuid2index_9_22_h051=torch.load(\"node_uuid2index_9_22_host=SysClient0051_datalabel=benign\")\n",
    "node_uuid2index_9_22_h209=torch.load(\"node_uuid2index_9_22_host=SysClient0209_datalabel=benign\")\n",
    "\n",
    "\n",
    "node_uuid2index_9_23_h201=torch.load(\"node_uuid2index_9_23_host=SysClient0201_datalabel=evaluation\")\n",
    "node_uuid2index_9_24_h201=torch.load(\"node_uuid2index_9_24_host=SysClient0201_datalabel=evaluation\")\n",
    "node_uuid2index_9_25_h201=torch.load(\"node_uuid2index_9_25_host=SysClient0201_datalabel=evaluation\")\n",
    "\n",
    "node_uuid2index_9_23_h402=torch.load(\"node_uuid2index_9_23_host=SysClient0402_datalabel=evaluation\")\n",
    "node_uuid2index_9_24_h402=torch.load(\"node_uuid2index_9_24_host=SysClient0402_datalabel=evaluation\")\n",
    "node_uuid2index_9_25_h402=torch.load(\"node_uuid2index_9_25_host=SysClient0402_datalabel=evaluation\")\n",
    "\n",
    "node_uuid2index_9_23_h660=torch.load(\"node_uuid2index_9_23_host=SysClient0660_datalabel=evaluation\")\n",
    "node_uuid2index_9_24_h660=torch.load(\"node_uuid2index_9_24_host=SysClient0660_datalabel=evaluation\")\n",
    "node_uuid2index_9_25_h660=torch.load(\"node_uuid2index_9_25_host=SysClient0660_datalabel=evaluation\")\n",
    "\n",
    "node_uuid2index_9_23_h501=torch.load(\"node_uuid2index_9_23_host=SysClient0501_datalabel=evaluation\")\n",
    "node_uuid2index_9_24_h501=torch.load(\"node_uuid2index_9_24_host=SysClient0501_datalabel=evaluation\")\n",
    "node_uuid2index_9_25_h501=torch.load(\"node_uuid2index_9_25_host=SysClient0501_datalabel=evaluation\")\n",
    "\n",
    "node_uuid2index_9_23_h051=torch.load(\"node_uuid2index_9_23_host=SysClient0051_datalabel=evaluation\")\n",
    "node_uuid2index_9_24_h051=torch.load(\"node_uuid2index_9_24_host=SysClient0051_datalabel=evaluation\")\n",
    "node_uuid2index_9_25_h051=torch.load(\"node_uuid2index_9_25_host=SysClient0051_datalabel=evaluation\")\n",
    "\n",
    "node_uuid2index_9_23_h207=torch.load(\"node_uuid2index_9_23_host=SysClient0207_datalabel=evaluation\")\n",
    "node_uuid2index_9_24_h207=torch.load(\"node_uuid2index_9_24_host=SysClient0207_datalabel=evaluation\")\n",
    "node_uuid2index_9_25_h207=torch.load(\"node_uuid2index_9_25_host=SysClient0207_datalabel=evaluation\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of node indexing files\n",
    "node_dics=[\n",
    "    node_uuid2index_9_22_h201,\n",
    "    node_uuid2index_9_22_h402,\n",
    "    node_uuid2index_9_22_h660,\n",
    "    node_uuid2index_9_22_h501,\n",
    "    node_uuid2index_9_22_h051,\n",
    "    node_uuid2index_9_22_h209,\n",
    "    node_uuid2index_9_23_h201,\n",
    "    node_uuid2index_9_24_h201,\n",
    "    node_uuid2index_9_25_h201,\n",
    "    node_uuid2index_9_23_h402,\n",
    "    node_uuid2index_9_24_h402,\n",
    "    node_uuid2index_9_25_h402,\n",
    "    node_uuid2index_9_23_h660,\n",
    "    node_uuid2index_9_24_h660,\n",
    "    node_uuid2index_9_25_h660,\n",
    "    node_uuid2index_9_23_h501,\n",
    "    node_uuid2index_9_24_h501,\n",
    "    node_uuid2index_9_25_h501,\n",
    "    node_uuid2index_9_23_h051,\n",
    "    node_uuid2index_9_24_h051,\n",
    "    node_uuid2index_9_25_h051,\n",
    "    node_uuid2index_9_23_h207,\n",
    "    node_uuid2index_9_24_h207,\n",
    "    node_uuid2index_9_25_h207,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of unique nodes\n",
    "nodes=set()\n",
    "for dic in node_dics:\n",
    "    for n in dic:\n",
    "        if type(n)==str:\n",
    "            nodes.add(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log nodes\n",
    "len(nodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kairos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "47.7109px",
    "left": "21px",
    "top": "204.141px",
    "width": "199.344px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

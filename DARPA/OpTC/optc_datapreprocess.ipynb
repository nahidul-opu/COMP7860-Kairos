{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding=utf-8\n",
    "import os.path as osp\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "from torch_geometric.data import TemporalData\n",
    "\n",
    "from torch_geometric.nn import TGNMemory, TransformerConv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn.models.tgn import (LastNeighborLoader, IdentityMessage, MeanAggregator,\n",
    "                                           LastAggregator)\n",
    "from torch_geometric import *\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "from tqdm import tqdm\n",
    "# from .autonotebook import tqdm as notebook_tqdm\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "from random import choice\n",
    "import gc\n",
    "from graphviz import Digraph\n",
    "import xxhash\n",
    "\n",
    "from datetime import datetime, timezone\n",
    "import time\n",
    "import pytz\n",
    "from time import mktime\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "from rich.progress import Progress\n",
    "from rich.progress import (\n",
    "    BarColumn,\n",
    "    DownloadColumn,\n",
    "    Progress,\n",
    "    SpinnerColumn,\n",
    "    TaskProgressColumn,\n",
    "    TimeElapsedColumn,\n",
    "    TimeRemainingColumn,\n",
    ")\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "def hashgen(l):\n",
    "    \"\"\"Generate a single hash value from a list. @l is a list of\n",
    "    string values, which can be properties of a node/edge. This\n",
    "    function returns a single hashed integer value.\"\"\"\n",
    "    hasher = xxhash.xxh64()\n",
    "    for e in l:\n",
    "        hasher.update(e)\n",
    "    return hasher.intdigest()\n",
    "\n",
    "\n",
    "def datetime_to_ns_time(date):\n",
    "    \"\"\"\n",
    "    :param date: str   format: %Y-%m-%d %H:%M:%S   e.g. 2013-10-10 23:40:00\n",
    "    :return: nano timestamp\n",
    "    \"\"\"\n",
    "    date,ns=date.split('.')\n",
    "\n",
    "    timeArray = time.strptime(date, '%Y-%m-%dT%H:%M:%S')\n",
    "    timeStamp = int(time.mktime(timeArray))\n",
    "    timeStamp = timeStamp * 1000000000\n",
    "    timeStamp += int(ns.split('Z')[0])\n",
    "    return timeStamp\n",
    "\n",
    "\n",
    "def datetime_to_timestamp_US(date):\n",
    "    \"\"\"\n",
    "    :param date: str   format: %Y-%m-%d %H:%M:%S   e.g. 2013-10-10 23:40:00\n",
    "    :return: nano timestamp\n",
    "    \"\"\"\n",
    "    date=date.replace('-04:00','')\n",
    "    if '.' in date:\n",
    "        date,ms=date.split('.')\n",
    "    else:\n",
    "        ms=0\n",
    "    tz = pytz.timezone('Etc/GMT+4')\n",
    "    timeArray = time.strptime(date, \"%Y-%m-%dT%H:%M:%S\")\n",
    "    dt = datetime.fromtimestamp(mktime(timeArray))\n",
    "    timestamp = tz.localize(dt)\n",
    "    timestamp=timestamp.timestamp()\n",
    "    timeStamp = timestamp*1000+int(ms)\n",
    "    return int(timeStamp)\n",
    "\n",
    "\n",
    "def timestamp_to_datetime_US(ns):\n",
    "    \"\"\"\n",
    "    :param date: str   format: %Y-%m-%d %H:%M:%S   e.g. 2013-10-10 23:40:00\n",
    "    :return: nano timestamp\n",
    "    \"\"\"\n",
    "    tz = pytz.timezone('US/Eastern')\n",
    "    ms=ns%1000\n",
    "    ns/=1000\n",
    "    dt = pytz.datetime.datetime.fromtimestamp(int(ns), tz)\n",
    "    s = dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    s+='.'+str(ms)\n",
    "#     s += '.' + str(int(int(ns) % 1000000000)).zfill(9)\n",
    "    return s\n",
    "\n",
    "pid_split_symble=\"#_\"\n",
    "\n",
    "host_split_symble=\"_@\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database setting (Make sure the database and tables are created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "from psycopg2 import extras as ex\n",
    "connect = psycopg2.connect(database = 'optc_db',\n",
    "                           host = 'localhost',\n",
    "                           user = 'postgres',\n",
    "                           password = 'postgres',\n",
    "                           port = '5437'\n",
    "                          )\n",
    "\n",
    "cur = connect.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear all data in the database. Run it carefully!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt=cur.execute(\"\"\"\n",
    "    delete from event_table where 1=1;\n",
    "\"\"\")\n",
    "print(tt)\n",
    "connect.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt=cur.execute(\"\"\"\n",
    "    delete from nodeid2msg where 1=1;\n",
    "\"\"\")\n",
    "print(tt)\n",
    "connect.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_edge_type=[\n",
    "    \"READ\",\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "node_type_used=[\n",
    "    'FILE',\n",
    " 'FLOW',\n",
    " 'PROCESS',\n",
    "#  'SHELL',\n",
    "]\n",
    "\n",
    "def process_raw_dic(raw_dic):\n",
    "    ans_dic={}\n",
    "    \n",
    "    \n",
    "    ans_dic['hostname']=raw_dic['hostname'].split('.')[0]\n",
    "    \n",
    "    ans_dic['edge_type']=raw_dic['action']\n",
    "    ans_dic['src_id']=raw_dic['actorID']\n",
    "    ans_dic['dst_id']=raw_dic['objectID']\n",
    "    \n",
    "    ans_dic['src_type']='PROCESS'\n",
    "    ans_dic['timestamp']=datetime_to_timestamp_US(raw_dic['timestamp'])\n",
    "    ans_dic['dst_type']=raw_dic['object']\n",
    "    \n",
    "    try:\n",
    "        node_uuid2path[ans_dic['src_id']]=ans_dic['hostname']+host_split_symble+raw_dic['properties']['image_path']  \n",
    "        \n",
    "    \n",
    "        if raw_dic['object']=='FLOW':\n",
    "            temp_flow=f\"{raw_dic['properties']['direction']}#{raw_dic['properties']['src_ip']}:{raw_dic['properties']['src_port']}->{raw_dic['properties']['dest_ip']}:{raw_dic['properties']['dest_port']}\"\n",
    "            node_uuid2path[ans_dic['dst_id']]=ans_dic['hostname']+host_split_symble+temp_flow\n",
    "\n",
    "        if raw_dic['object']=='FILE':              \n",
    "            node_uuid2path[ans_dic['dst_id']]=ans_dic['hostname']+host_split_symble+raw_dic['properties']['file_path']\n",
    "\n",
    "\n",
    "    except:\n",
    "        ans_dic={}\n",
    "    \n",
    "    return ans_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_type={'FILE',\n",
    " 'FLOW',\n",
    " 'MODULE',\n",
    " 'PROCESS',\n",
    " 'REGISTRY',\n",
    " 'SHELL',\n",
    " 'TASK',\n",
    " 'THREAD',\n",
    " 'USER_SESSION'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unzip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    " \n",
    "# folder path\n",
    "dir_path = '/home/shahidul2k9/data/optc/plain/'\n",
    " \n",
    "# list to store files name\n",
    "res = []\n",
    "for (dir_path, dir_names, file_names) in walk(dir_path):\n",
    "    if dir_path[-1]!='/':\n",
    "        dir_path+='/'\n",
    "#     print(f\"{dir_path=}\")\n",
    "#     print(f\"{file_names=}\")\n",
    "    for f in file_names:\n",
    "        temp_file_path=dir_path+f\n",
    "#         print(f\"{temp_file_path=}\")\n",
    "     \n",
    "        res.append(temp_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in tqdm(res):\n",
    "    if (\"201-225\" in r or \"401-425\" in r or \"651-675\" in r or \"501-525\" in r or \"51-75\" in r) and \".gz\" in r:\n",
    "        os.system(f\"gzip -d {r}\")\n",
    "        print(f\" {r} FinishedÔºÅ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the features of nodes and edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge types\n",
    "edge_set=['OPEN',\n",
    "'READ',\n",
    "'CREATE',\n",
    "'MESSAGE',\n",
    "'MODIFY',\n",
    "'START',\n",
    "'RENAME',\n",
    "'DELETE',\n",
    "'TERMINATE',\n",
    "'WRITE',]\n",
    "\n",
    "# Generate edge type one-hot\n",
    "edgevec=torch.nn.functional.one_hot(torch.arange(0, len(edge_set)), num_classes=len(edge_set))\n",
    "\n",
    "\n",
    "edge2vec={}\n",
    "for e in range(len(edge_set)):\n",
    "    edge2vec[edge_set[e]]=edgevec[e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel2id={}\n",
    "index=1\n",
    "for i in edge_set:\n",
    "    rel2id[index]=i\n",
    "    rel2id[i]=index\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "encode_len=16\n",
    "\n",
    "FH_string=FeatureHasher(n_features=encode_len,input_type=\"string\")\n",
    "FH_dict=FeatureHasher(n_features=encode_len,input_type=\"dict\")\n",
    "\n",
    "\n",
    "def path2higlist(p):\n",
    "    l=[]\n",
    "    spl=p.strip().split('/')\n",
    "    for i in spl:\n",
    "        if len(l)!=0:\n",
    "            l.append(l[-1]+'/'+i)\n",
    "        else:\n",
    "            l.append(i)\n",
    "#     print(l)\n",
    "    return l\n",
    "\n",
    "def ip2higlist(p):\n",
    "    l=[]\n",
    "    if \"::\" not in p:\n",
    "        spl=p.strip().split('.')\n",
    "        for i in spl:\n",
    "            if len(l)!=0:\n",
    "                l.append(l[-1]+'.'+i)\n",
    "            else:\n",
    "                l.append(i)\n",
    "    #     print(l)\n",
    "        return l\n",
    "    else:\n",
    "        spl=p.strip().split(':')\n",
    "        for i in spl:\n",
    "            if len(l)!=0:\n",
    "                l.append(l[-1]+':'+i)\n",
    "            else:\n",
    "                l.append(i)\n",
    "    #     print(l)\n",
    "        return l\n",
    "def list2str(l):\n",
    "    s=''\n",
    "    for i in l:\n",
    "        s+=i\n",
    "    return s\n",
    "\n",
    "def str2tensor(msg_type,msg):\n",
    "    if msg_type == 'FLOW':\n",
    "        h_msg=list2str(ip2higlist(msg))\n",
    "    else:\n",
    "        h_msg=list2str(path2higlist(msg))\n",
    "    vec=FH_string.transform([msg_type+h_msg]).toarray()\n",
    "    vec=torch.tensor(vec).reshape(encode_len).float()\n",
    "#     print(h_msg)\n",
    "    return vec\n",
    "\n",
    "\n",
    "class TimeEncoder(torch.nn.Module):\n",
    "    def __init__(self, out_channels):\n",
    "        super().__init__()\n",
    "        self.out_channels = out_channels\n",
    "        self.lin = Linear(1, out_channels)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "\n",
    "    def forward(self, t):\n",
    "        return self.lin(t.view(-1, 1)).cos()\n",
    "    \n",
    "time_enc=TimeEncoder(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store the benign data to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_uuid2path={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    " \n",
    "# folder path\n",
    "dir_path = '/home/shahidul2k9/data/optc/plain/ecar/benign/'\n",
    "\n",
    "res = []\n",
    "for (dir_path, dir_names, file_names) in walk(dir_path):\n",
    "    if dir_path[-1]!='/':\n",
    "        dir_path+='/'\n",
    "#     print(f\"{dir_path=}\")\n",
    "#     print(f\"{file_names=}\")\n",
    "    for f in file_names:\n",
    "        temp_file_path=dir_path+f\n",
    "#         print(f\"{temp_file_path=}\")\n",
    "        if \"201-225\" in temp_file_path or (\"20-23Sep19\" in temp_file_path and (\"401-425\" in temp_file_path or \"651-675\" in temp_file_path or \"501-525\" in temp_file_path or \"51-75\" in temp_file_path)):\n",
    "            res.append(temp_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in tqdm(res):\n",
    "    if  \".gz\" in r:\n",
    "        os.system(f\"gzip -d {r}\")\n",
    "        print(f\" {r} FinishedÔºÅ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_selected_hosts(line):\n",
    "    hosts=[\n",
    "        'SysClient0201',\n",
    "        'SysClient0402',\n",
    "        'SysClient0660',\n",
    "        'SysClient0501',\n",
    "        'SysClient0051',        \n",
    "        'SysClient0209',\n",
    "    ]\n",
    "    flag=False\n",
    "    for h in hosts:\n",
    "        if h in line:\n",
    "            flag=True\n",
    "            break\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file_path in res:\n",
    "    \n",
    "    edge_list=[]\n",
    "\n",
    "    with open(file_path) as f:\n",
    "        for line in tqdm(f):\n",
    "            line=line.replace('\\\\\\\\','/')\n",
    "            temp_dic=json.loads(line.strip())\n",
    "            hostname=temp_dic['hostname'].split('.')[0]\n",
    "            if temp_dic['object'] in node_type_used and is_selected_hosts(hostname):\n",
    "                edge_list.append(process_raw_dic(temp_dic))\n",
    "    \n",
    "        print(f'{len(edge_list)=}')\n",
    "        data_list=[]\n",
    "        for e in edge_list:\n",
    "            try:\n",
    "                data_list.append([\n",
    "                    e['src_id'],\n",
    "                    e['src_type'],\n",
    "                    e['edge_type'],\n",
    "                    e['dst_id'],\n",
    "                    e['dst_type'],\n",
    "                    e['hostname'],\n",
    "                    e['timestamp'],\n",
    "                    \"benign\",\n",
    "                ])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # write to database\n",
    "        sql = '''insert into event_table\n",
    "                             values %s\n",
    "                '''\n",
    "        ex.execute_values(cur,sql, data_list,page_size=10000)\n",
    "        connect.commit()\n",
    "        \n",
    "        print(f\"{file_path} Finished! \")\n",
    "        # Clear the tmp variables to release the memory.\n",
    "        del edge_list\n",
    "        del data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store the evaluation data to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    " \n",
    "# folder path\n",
    "dir_path = '/home/shahidul2k9/data/optc/plain/ecar/evaluation/'\n",
    "\n",
    "res = []\n",
    "for (dir_path, dir_names, file_names) in walk(dir_path):\n",
    "    if dir_path[-1]!='/':\n",
    "        dir_path+='/'\n",
    "    for f in file_names:\n",
    "        temp_file_path=dir_path+f\n",
    "#         print(f\"{temp_file_path=}\")\n",
    "        if (\"201-225\" in temp_file_path or \"401-425\" in temp_file_path or \"651-675\" in temp_file_path or \"501-525\" in temp_file_path or \"51-75\" in temp_file_path):\n",
    "            res.append(temp_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for r in tqdm(res):\n",
    "    if  \".gz\" in r:\n",
    "        os.system(f\"gzip -d {r}\")\n",
    "        print(f\" {r} FinishedÔºÅ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_selected_hosts(line):\n",
    "    hosts=[\n",
    "        'SysClient0201',\n",
    "        'SysClient0402',\n",
    "        'SysClient0660',\n",
    "        'SysClient0501',\n",
    "        'SysClient0051',        \n",
    "        'SysClient0207',\n",
    "    ]\n",
    "    flag=False\n",
    "    for h in hosts:\n",
    "        if h in line:\n",
    "            flag=True\n",
    "            break\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file_path in res:\n",
    "    \n",
    "    edge_list=[]\n",
    "\n",
    "    with open(file_path) as f:\n",
    "        for line in tqdm(f):\n",
    "            line=line.replace('\\\\\\\\','/')\n",
    "            temp_dic=json.loads(line.strip())\n",
    "            hostname=temp_dic['hostname'].split('.')[0]\n",
    "            if temp_dic['object'] in node_type_used and is_selected_hosts(hostname):\n",
    "                edge_list.append(process_raw_dic(temp_dic))\n",
    "    \n",
    "        print(f'{len(edge_list)=}')\n",
    "        data_list=[]\n",
    "        for e in edge_list:\n",
    "            try:\n",
    "                data_list.append([\n",
    "                    e['src_id'],\n",
    "                    e['src_type'],\n",
    "                    e['edge_type'],\n",
    "                    e['dst_id'],\n",
    "                    e['dst_type'],\n",
    "                    e['hostname'],\n",
    "                    e['timestamp'],\n",
    "                    \"evaluation\",\n",
    "                ])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        sql = '''insert into event_table\n",
    "                             values %s\n",
    "                '''\n",
    "        ex.execute_values(cur,sql, data_list,page_size=10000)\n",
    "        connect.commit()\n",
    "        \n",
    "        print(f\"{file_path} Finished! \")\n",
    "        # Clear the tmp variables to release the memory.\n",
    "        del edge_list\n",
    "        del data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store the node data into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list=[]\n",
    "for n in node_uuid2path:\n",
    "    try:\n",
    "        data_list.append([\n",
    "            n,\n",
    "             node_uuid2path[n]\n",
    "        ])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n",
    "sql = '''insert into nodeid2msg\n",
    "                     values %s\n",
    "        '''\n",
    "ex.execute_values(cur,sql, data_list,page_size=10000)\n",
    "connect.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(node_uuid2path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load node data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the map between nodeid and msg\n",
    "sql=\"select * from nodeid2msg;\"\n",
    "cur.execute(sql)\n",
    "rows = cur.fetchall()\n",
    "\n",
    "node_uuid2path={}  # nodeid => msg      node hash => nodeid\n",
    "for i in tqdm(rows):\n",
    "    node_uuid2path[i[0]]=i[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the benign datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h402  22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in tqdm(range(22,23)):\n",
    "    start_timestamp=datetime_to_timestamp_US('2019-09-'+str(day)+'T00:00:00')\n",
    "    end_timestamp=datetime_to_timestamp_US('2019-09-'+str(day+1)+'T00:00:00')\n",
    "    hostname='SysClient0402'\n",
    "    datalabel='benign'\n",
    "    sql=f\"\"\"\n",
    "    select * from event_table\n",
    "    where\n",
    "          timestamp>{start_timestamp} and timestamp<{end_timestamp}\n",
    "          and hostname='{hostname}' and data_label='{datalabel}' ORDER BY timestamp;\n",
    "    \"\"\"\n",
    "    cur.execute(sql)\n",
    "    events = cur.fetchall()\n",
    "    print(f\"{len(events)=}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    node_set=set()\n",
    "    node_uuid2index={}\n",
    "    temp_index=0\n",
    "    for e in events:\n",
    "        if e[3] not in node_uuid2path or e[0]  not in node_uuid2path:\n",
    "            continue\n",
    "\n",
    "        if e[0] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[0]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[0]]\n",
    "            temp_index+=1\n",
    "\n",
    "        if e[3] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[3]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[3]]\n",
    "            temp_index+=1 \n",
    "\n",
    "    torch.save(node_uuid2index,f'node_uuid2index_9_{day}_host={hostname}_datalabel={datalabel}')\n",
    "       \n",
    "\n",
    "    dataset = TemporalData()\n",
    "    src = []\n",
    "    dst = []\n",
    "    msg = []\n",
    "    t = []\n",
    "    for e in (events):\n",
    "        if e[3] in node_uuid2index and e[0] in node_uuid2index:\n",
    "            # If the image path of the node is not recorded, then skip this edge\n",
    "            src.append(node_uuid2index[e[0]])\n",
    "            dst.append(node_uuid2index[e[3]])\n",
    "        #     msg.append(torch.cat([torch.from_numpy(node2higvec_bn[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec_bn[i[1]])] ))\n",
    "\n",
    "            msg.append(torch.cat([str2tensor(e[1],node_uuid2path[e[0]]), \n",
    "                                  edge2vec[e[2]], \n",
    "                                  str2tensor(e[4],node_uuid2path[e[3]])\n",
    "                                 ]))\n",
    "            t.append(int(e[6]))\n",
    "\n",
    "    dataset.src = torch.tensor(src)\n",
    "    dataset.dst = torch.tensor(dst)\n",
    "    dataset.t = torch.tensor(t)\n",
    "    dataset.msg = torch.vstack(msg)\n",
    "    dataset.src = dataset.src.to(torch.long)\n",
    "    dataset.dst = dataset.dst.to(torch.long)\n",
    "    dataset.msg = dataset.msg.to(torch.float)\n",
    "    dataset.t = dataset.t.to(torch.long)\n",
    "    torch.save(dataset, f\"/home/shahidul2k9/data/optc/out/evaluation/9_{day}_host={hostname}_datalabel={datalabel}.TemporalData\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h660 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in tqdm(range(22,23)):\n",
    "    start_timestamp=datetime_to_timestamp_US('2019-09-'+str(day)+'T00:00:00')\n",
    "    end_timestamp=datetime_to_timestamp_US('2019-09-'+str(day+1)+'T00:00:00')\n",
    "    hostname='SysClient0660'\n",
    "    datalabel='benign'\n",
    "    sql=f\"\"\"\n",
    "    select * from event_table\n",
    "    where\n",
    "          timestamp>{start_timestamp} and timestamp<{end_timestamp}\n",
    "          and hostname='{hostname}' and data_label='{datalabel}' ORDER BY timestamp;\n",
    "    \"\"\"\n",
    "    cur.execute(sql)\n",
    "    events = cur.fetchall()\n",
    "    print(f\"{len(events)=}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    node_set=set()\n",
    "    node_uuid2index={}\n",
    "    temp_index=0\n",
    "    for e in events:\n",
    "        if e[3] not in node_uuid2path or e[0]  not in node_uuid2path:\n",
    "            continue\n",
    "\n",
    "        if e[0] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[0]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[0]]\n",
    "            temp_index+=1\n",
    "\n",
    "        if e[3] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[3]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[3]]\n",
    "            temp_index+=1 \n",
    "\n",
    "    torch.save(node_uuid2index,f'node_uuid2index_9_{day}_host={hostname}_datalabel={datalabel}')\n",
    "       \n",
    "\n",
    "    dataset = TemporalData()\n",
    "    src = []\n",
    "    dst = []\n",
    "    msg = []\n",
    "    t = []\n",
    "    for e in (events):\n",
    "        if e[3] in node_uuid2index and e[0] in node_uuid2index:\n",
    "            # If the image path of the node is not recorded, then skip this edge\n",
    "            src.append(node_uuid2index[e[0]])\n",
    "            dst.append(node_uuid2index[e[3]])\n",
    "        #     msg.append(torch.cat([torch.from_numpy(node2higvec_bn[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec_bn[i[1]])] ))\n",
    "\n",
    "            msg.append(torch.cat([str2tensor(e[1],node_uuid2path[e[0]]), \n",
    "                                  edge2vec[e[2]], \n",
    "                                  str2tensor(e[4],node_uuid2path[e[3]])\n",
    "                                 ]))\n",
    "            t.append(int(e[6]))\n",
    "\n",
    "    dataset.src = torch.tensor(src)\n",
    "    dataset.dst = torch.tensor(dst)\n",
    "    dataset.t = torch.tensor(t)\n",
    "    dataset.msg = torch.vstack(msg)\n",
    "    dataset.src = dataset.src.to(torch.long)\n",
    "    dataset.dst = dataset.dst.to(torch.long)\n",
    "    dataset.msg = dataset.msg.to(torch.float)\n",
    "    dataset.t = dataset.t.to(torch.long)\n",
    "    torch.save(dataset, f\"/home/shahidul2k9/data/optc/out/evaluation/9_{day}_host={hostname}_datalabel={datalabel}.TemporalData\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h501 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in tqdm(range(21,22)):\n",
    "    start_timestamp=datetime_to_timestamp_US('2019-09-'+str(day)+'T00:00:00')\n",
    "    end_timestamp=datetime_to_timestamp_US('2019-09-'+str(day+1)+'T00:00:00')\n",
    "    hostname='SysClient0501'\n",
    "    datalabel='benign'\n",
    "    sql=f\"\"\"\n",
    "    select * from event_table\n",
    "    where\n",
    "          timestamp>{start_timestamp} and timestamp<{end_timestamp}\n",
    "          and hostname='{hostname}' and data_label='{datalabel}' ORDER BY timestamp;\n",
    "    \"\"\"\n",
    "    cur.execute(sql)\n",
    "    events = cur.fetchall()\n",
    "    print(f\"{len(events)=}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    node_set=set()\n",
    "    node_uuid2index={}\n",
    "    temp_index=0\n",
    "    for e in events:\n",
    "        if e[3] not in node_uuid2path or e[0]  not in node_uuid2path:\n",
    "            continue\n",
    "\n",
    "        if e[0] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[0]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[0]]\n",
    "            temp_index+=1\n",
    "\n",
    "        if e[3] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[3]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[3]]\n",
    "            temp_index+=1 \n",
    "\n",
    "    torch.save(node_uuid2index,f'node_uuid2index_9_{day}_host={hostname}_datalabel={datalabel}')\n",
    "       \n",
    "\n",
    "    dataset = TemporalData()\n",
    "    src = []\n",
    "    dst = []\n",
    "    msg = []\n",
    "    t = []\n",
    "    for e in (events):\n",
    "        if e[3] in node_uuid2index and e[0] in node_uuid2index:\n",
    "            # If the image path of the node is not recorded, then skip this edge\n",
    "            src.append(node_uuid2index[e[0]])\n",
    "            dst.append(node_uuid2index[e[3]])\n",
    "        #     msg.append(torch.cat([torch.from_numpy(node2higvec_bn[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec_bn[i[1]])] ))\n",
    "\n",
    "            msg.append(torch.cat([str2tensor(e[1],node_uuid2path[e[0]]), \n",
    "                                  edge2vec[e[2]], \n",
    "                                  str2tensor(e[4],node_uuid2path[e[3]])\n",
    "                                 ]))\n",
    "            t.append(int(e[6]))\n",
    "\n",
    "    dataset.src = torch.tensor(src)\n",
    "    dataset.dst = torch.tensor(dst)\n",
    "    dataset.t = torch.tensor(t)\n",
    "    dataset.msg = torch.vstack(msg)\n",
    "    dataset.src = dataset.src.to(torch.long)\n",
    "    dataset.dst = dataset.dst.to(torch.long)\n",
    "    dataset.msg = dataset.msg.to(torch.float)\n",
    "    dataset.t = dataset.t.to(torch.long)\n",
    "    torch.save(dataset, f\"/home/shahidul2k9/data/optc/out/evaluation/9_{day}_host={hostname}_datalabel={datalabel}.TemporalData\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h501 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in tqdm(range(22,23)):\n",
    "    start_timestamp=datetime_to_timestamp_US('2019-09-'+str(day)+'T00:00:00')\n",
    "    end_timestamp=datetime_to_timestamp_US('2019-09-'+str(day+1)+'T00:00:00')\n",
    "    hostname='SysClient0501'\n",
    "    datalabel='benign'\n",
    "    sql=f\"\"\"\n",
    "    select * from event_table\n",
    "    where\n",
    "          timestamp>{start_timestamp} and timestamp<{end_timestamp}\n",
    "          and hostname='{hostname}' and data_label='{datalabel}' ORDER BY timestamp;\n",
    "    \"\"\"\n",
    "    cur.execute(sql)\n",
    "    events = cur.fetchall()\n",
    "    print(f\"{len(events)=}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    node_set=set()\n",
    "    node_uuid2index={}\n",
    "    temp_index=0\n",
    "    for e in events:\n",
    "        if e[3] not in node_uuid2path or e[0]  not in node_uuid2path:\n",
    "            continue\n",
    "\n",
    "        if e[0] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[0]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[0]]\n",
    "            temp_index+=1\n",
    "\n",
    "        if e[3] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[3]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[3]]\n",
    "            temp_index+=1 \n",
    "\n",
    "    torch.save(node_uuid2index,f'node_uuid2index_9_{day}_host={hostname}_datalabel={datalabel}')\n",
    "\n",
    "    dataset = TemporalData()\n",
    "    src = []\n",
    "    dst = []\n",
    "    msg = []\n",
    "    t = []\n",
    "    for e in (events):\n",
    "        if e[3] in node_uuid2index and e[0] in node_uuid2index:\n",
    "            # If the image path of the node is not recorded, then skip this edge\n",
    "            src.append(node_uuid2index[e[0]])\n",
    "            dst.append(node_uuid2index[e[3]])\n",
    "        #     msg.append(torch.cat([torch.from_numpy(node2higvec_bn[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec_bn[i[1]])] ))\n",
    "\n",
    "            msg.append(torch.cat([str2tensor(e[1],node_uuid2path[e[0]]), \n",
    "                                  edge2vec[e[2]], \n",
    "                                  str2tensor(e[4],node_uuid2path[e[3]])\n",
    "                                 ]))\n",
    "            t.append(int(e[6]))\n",
    "\n",
    "    dataset.src = torch.tensor(src)\n",
    "    dataset.dst = torch.tensor(dst)\n",
    "    dataset.t = torch.tensor(t)\n",
    "    dataset.msg = torch.vstack(msg)\n",
    "    dataset.src = dataset.src.to(torch.long)\n",
    "    dataset.dst = dataset.dst.to(torch.long)\n",
    "    dataset.msg = dataset.msg.to(torch.float)\n",
    "    dataset.t = dataset.t.to(torch.long)\n",
    "    torch.save(dataset, f\"/home/shahidul2k9/data/optc/out/evaluation/9_{day}_host={hostname}_datalabel={datalabel}.TemporalData\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h051 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in tqdm(range(22,23)):\n",
    "    start_timestamp=datetime_to_timestamp_US('2019-09-'+str(day)+'T00:00:00')\n",
    "    end_timestamp=datetime_to_timestamp_US('2019-09-'+str(day+1)+'T00:00:00')\n",
    "    hostname='SysClient0051'\n",
    "    datalabel='benign'\n",
    "    sql=f\"\"\"\n",
    "    select * from event_table\n",
    "    where\n",
    "          timestamp>{start_timestamp} and timestamp<{end_timestamp}\n",
    "          and hostname='{hostname}' and data_label='{datalabel}' ORDER BY timestamp;\n",
    "    \"\"\"\n",
    "    cur.execute(sql)\n",
    "    events = cur.fetchall()\n",
    "    print(f\"{len(events)=}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    node_set=set()\n",
    "    node_uuid2index={}\n",
    "    temp_index=0\n",
    "    for e in events:\n",
    "        if e[3] not in node_uuid2path or e[0]  not in node_uuid2path:\n",
    "            continue\n",
    "\n",
    "        if e[0] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[0]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[0]]\n",
    "            temp_index+=1\n",
    "\n",
    "        if e[3] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[3]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[3]]\n",
    "            temp_index+=1 \n",
    "\n",
    "    torch.save(node_uuid2index,f'node_uuid2index_9_{day}_host={hostname}_datalabel={datalabel}')\n",
    "       \n",
    "\n",
    "    dataset = TemporalData()\n",
    "    src = []\n",
    "    dst = []\n",
    "    msg = []\n",
    "    t = []\n",
    "    for e in (events):\n",
    "        if e[3] in node_uuid2index and e[0] in node_uuid2index:\n",
    "            # If the image path of the node is not recorded, then skip this edge\n",
    "            src.append(node_uuid2index[e[0]])\n",
    "            dst.append(node_uuid2index[e[3]])\n",
    "        #     msg.append(torch.cat([torch.from_numpy(node2higvec_bn[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec_bn[i[1]])] ))\n",
    "\n",
    "            msg.append(torch.cat([str2tensor(e[1],node_uuid2path[e[0]]), \n",
    "                                  edge2vec[e[2]], \n",
    "                                  str2tensor(e[4],node_uuid2path[e[3]])\n",
    "                                 ]))\n",
    "            t.append(int(e[6]))\n",
    "\n",
    "    dataset.src = torch.tensor(src)\n",
    "    dataset.dst = torch.tensor(dst)\n",
    "    dataset.t = torch.tensor(t)\n",
    "    dataset.msg = torch.vstack(msg)\n",
    "    dataset.src = dataset.src.to(torch.long)\n",
    "    dataset.dst = dataset.dst.to(torch.long)\n",
    "    dataset.msg = dataset.msg.to(torch.float)\n",
    "    dataset.t = dataset.t.to(torch.long)\n",
    "    torch.save(dataset, f\"/home/shahidul2k9/data/optc/out/evaluation/9_{day}_host={hostname}_datalabel={datalabel}.TemporalData\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h209 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in tqdm(range(22,23)):\n",
    "    start_timestamp=datetime_to_timestamp_US('2019-09-'+str(day)+'T00:00:00')\n",
    "    end_timestamp=datetime_to_timestamp_US('2019-09-'+str(day+1)+'T00:00:00')\n",
    "    hostname='SysClient0209'\n",
    "    datalabel='benign'\n",
    "    sql=f\"\"\"\n",
    "    select * from event_table\n",
    "    where\n",
    "          timestamp>{start_timestamp} and timestamp<{end_timestamp}\n",
    "          and hostname='{hostname}' and data_label='{datalabel}' ORDER BY timestamp;\n",
    "    \"\"\"\n",
    "    cur.execute(sql)\n",
    "    events = cur.fetchall()\n",
    "    print(f\"{len(events)=}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    node_set=set()\n",
    "    node_uuid2index={}\n",
    "    temp_index=0\n",
    "    for e in events:\n",
    "        if e[3] not in node_uuid2path or e[0]  not in node_uuid2path:\n",
    "            continue\n",
    "\n",
    "        if e[0] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[0]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[0]]\n",
    "            temp_index+=1\n",
    "\n",
    "        if e[3] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[3]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[3]]\n",
    "            temp_index+=1 \n",
    "\n",
    "    torch.save(node_uuid2index,f'node_uuid2index_9_{day}_host={hostname}_datalabel={datalabel}')\n",
    "       \n",
    "\n",
    "    dataset = TemporalData()\n",
    "    src = []\n",
    "    dst = []\n",
    "    msg = []\n",
    "    t = []\n",
    "    for e in (events):\n",
    "        if e[3] in node_uuid2index and e[0] in node_uuid2index:\n",
    "            # If the image path of the node is not recorded, then skip this edge\n",
    "            src.append(node_uuid2index[e[0]])\n",
    "            dst.append(node_uuid2index[e[3]])\n",
    "        #     msg.append(torch.cat([torch.from_numpy(node2higvec_bn[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec_bn[i[1]])] ))\n",
    "\n",
    "            msg.append(torch.cat([str2tensor(e[1],node_uuid2path[e[0]]), \n",
    "                                  edge2vec[e[2]], \n",
    "                                  str2tensor(e[4],node_uuid2path[e[3]])\n",
    "                                 ]))\n",
    "            t.append(int(e[6]))\n",
    "\n",
    "    dataset.src = torch.tensor(src)\n",
    "    dataset.dst = torch.tensor(dst)\n",
    "    dataset.t = torch.tensor(t)\n",
    "    dataset.msg = torch.vstack(msg)\n",
    "    dataset.src = dataset.src.to(torch.long)\n",
    "    dataset.dst = dataset.dst.to(torch.long)\n",
    "    dataset.msg = dataset.msg.to(torch.float)\n",
    "    dataset.t = dataset.t.to(torch.long)\n",
    "    torch.save(dataset, f\"/home/shahidul2k9/data/optc/out/evaluation/9_{day}_host={hostname}_datalabel={datalabel}.TemporalData\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h209 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in tqdm(range(23,24)):\n",
    "    start_timestamp=datetime_to_timestamp_US('2019-09-'+str(day)+'T00:00:00')\n",
    "    end_timestamp=datetime_to_timestamp_US('2019-09-'+str(day+1)+'T00:00:00')\n",
    "    hostname='SysClient0209'\n",
    "    datalabel='benign'\n",
    "    sql=f\"\"\"\n",
    "    select * from event_table\n",
    "    where\n",
    "          timestamp>{start_timestamp} and timestamp<{end_timestamp}\n",
    "          and hostname='{hostname}' and data_label='{datalabel}' ORDER BY timestamp;\n",
    "    \"\"\"\n",
    "    cur.execute(sql)\n",
    "    events = cur.fetchall()\n",
    "    print(f\"{len(events)=}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    node_set=set()\n",
    "    node_uuid2index={}\n",
    "    temp_index=0\n",
    "    for e in events:\n",
    "        if e[3] not in node_uuid2path or e[0]  not in node_uuid2path:\n",
    "            continue\n",
    "\n",
    "        if e[0] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[0]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[0]]\n",
    "            temp_index+=1\n",
    "\n",
    "        if e[3] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[3]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[3]]\n",
    "            temp_index+=1 \n",
    "\n",
    "    torch.save(node_uuid2index,f'node_uuid2index_9_{day}_host={hostname}_datalabel={datalabel}')\n",
    "       \n",
    "\n",
    "    dataset = TemporalData()\n",
    "    src = []\n",
    "    dst = []\n",
    "    msg = []\n",
    "    t = []\n",
    "    for e in (events):\n",
    "        if e[3] in node_uuid2index and e[0] in node_uuid2index:\n",
    "            # If the image path of the node is not recorded, then skip this edge\n",
    "            src.append(node_uuid2index[e[0]])\n",
    "            dst.append(node_uuid2index[e[3]])\n",
    "        #     msg.append(torch.cat([torch.from_numpy(node2higvec_bn[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec_bn[i[1]])] ))\n",
    "\n",
    "            msg.append(torch.cat([str2tensor(e[1],node_uuid2path[e[0]]), \n",
    "                                  edge2vec[e[2]], \n",
    "                                  str2tensor(e[4],node_uuid2path[e[3]])\n",
    "                                 ]))\n",
    "            t.append(int(e[6]))\n",
    "\n",
    "    dataset.src = torch.tensor(src)\n",
    "    dataset.dst = torch.tensor(dst)\n",
    "    dataset.t = torch.tensor(t)\n",
    "    dataset.msg = torch.vstack(msg)\n",
    "    dataset.src = dataset.src.to(torch.long)\n",
    "    dataset.dst = dataset.dst.to(torch.long)\n",
    "    dataset.msg = dataset.msg.to(torch.float)\n",
    "    dataset.t = dataset.t.to(torch.long)\n",
    "    torch.save(dataset, f\"/home/shahidul2k9/data/optc/out/evaluation/9_{day}_host={hostname}_datalabel={datalabel}.TemporalData\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the evaluation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h201 23-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in tqdm(range(23,26)):\n",
    "    start_timestamp=datetime_to_timestamp_US('2019-09-'+str(day)+'T00:00:00')\n",
    "    end_timestamp=datetime_to_timestamp_US('2019-09-'+str(day+1)+'T00:00:00')\n",
    "    hostname='SysClient0201'\n",
    "    datalabel='evaluation'\n",
    "    sql=f\"\"\"\n",
    "    select * from event_table\n",
    "    where\n",
    "          timestamp>{start_timestamp} and timestamp<{end_timestamp}\n",
    "          and hostname='{hostname}' and data_label='{datalabel}' ORDER BY timestamp;\n",
    "    \"\"\"\n",
    "    cur.execute(sql)\n",
    "    events = cur.fetchall()\n",
    "    print(f\"{len(events)=}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    node_set=set()\n",
    "    node_uuid2index={}\n",
    "    temp_index=0\n",
    "    for e in events:\n",
    "        if e[3] not in node_uuid2path or e[0]  not in node_uuid2path:\n",
    "            continue\n",
    "\n",
    "        if e[0] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[0]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[0]]\n",
    "            temp_index+=1\n",
    "\n",
    "        if e[3] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[3]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[3]]\n",
    "            temp_index+=1 \n",
    "\n",
    "    torch.save(node_uuid2index,f'node_uuid2index_9_{day}_host={hostname}_datalabel={datalabel}')\n",
    "\n",
    "    dataset = TemporalData()\n",
    "    src = []\n",
    "    dst = []\n",
    "    msg = []\n",
    "    t = []\n",
    "    for e in (events):\n",
    "        if e[3] in node_uuid2index and e[0] in node_uuid2index:\n",
    "            # If the image path of the node is not recorded, then skip this edge\n",
    "            src.append(node_uuid2index[e[0]])\n",
    "            dst.append(node_uuid2index[e[3]])\n",
    "        #     msg.append(torch.cat([torch.from_numpy(node2higvec_bn[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec_bn[i[1]])] ))\n",
    "\n",
    "            msg.append(torch.cat([str2tensor(e[1],node_uuid2path[e[0]]), \n",
    "                                  edge2vec[e[2]], \n",
    "                                  str2tensor(e[4],node_uuid2path[e[3]])\n",
    "                                 ]))\n",
    "            t.append(int(e[6]))\n",
    "\n",
    "    dataset.src = torch.tensor(src)\n",
    "    dataset.dst = torch.tensor(dst)\n",
    "    dataset.t = torch.tensor(t)\n",
    "    dataset.msg = torch.vstack(msg)\n",
    "    dataset.src = dataset.src.to(torch.long)\n",
    "    dataset.dst = dataset.dst.to(torch.long)\n",
    "    dataset.msg = dataset.msg.to(torch.float)\n",
    "    dataset.t = dataset.t.to(torch.long)\n",
    "    torch.save(dataset, f\"/home/shahidul2k9/data/optc/out/evaluation/9_{day}_host={hostname}_datalabel={datalabel}.TemporalData\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h402 23-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in tqdm(range(23,26)):\n",
    "    start_timestamp=datetime_to_timestamp_US('2019-09-'+str(day)+'T00:00:00')\n",
    "    end_timestamp=datetime_to_timestamp_US('2019-09-'+str(day+1)+'T00:00:00')\n",
    "    hostname='SysClient0402'\n",
    "    datalabel='evaluation'\n",
    "    sql=f\"\"\"\n",
    "    select * from event_table\n",
    "    where\n",
    "          timestamp>{start_timestamp} and timestamp<{end_timestamp}\n",
    "          and hostname='{hostname}' and data_label='{datalabel}' ORDER BY timestamp;\n",
    "    \"\"\"\n",
    "    cur.execute(sql)\n",
    "    events = cur.fetchall()\n",
    "    print(f\"{len(events)=}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    node_set=set()\n",
    "    node_uuid2index={}\n",
    "    temp_index=0\n",
    "    for e in events:\n",
    "        if e[3] not in node_uuid2path or e[0]  not in node_uuid2path:\n",
    "            continue\n",
    "\n",
    "        if e[0] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[0]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[0]]\n",
    "            temp_index+=1\n",
    "\n",
    "        if e[3] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[3]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[3]]\n",
    "            temp_index+=1 \n",
    "\n",
    "    torch.save(node_uuid2index,f'node_uuid2index_9_{day}_host={hostname}_datalabel={datalabel}')\n",
    "       \n",
    "\n",
    "    dataset = TemporalData()\n",
    "    src = []\n",
    "    dst = []\n",
    "    msg = []\n",
    "    t = []\n",
    "    for e in (events):\n",
    "        if e[3] in node_uuid2index and e[0] in node_uuid2index:\n",
    "            # If the image path of the node is not recorded, then skip this edge\n",
    "            src.append(node_uuid2index[e[0]])\n",
    "            dst.append(node_uuid2index[e[3]])\n",
    "        #     msg.append(torch.cat([torch.from_numpy(node2higvec_bn[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec_bn[i[1]])] ))\n",
    "\n",
    "            msg.append(torch.cat([str2tensor(e[1],node_uuid2path[e[0]]), \n",
    "                                  edge2vec[e[2]], \n",
    "                                  str2tensor(e[4],node_uuid2path[e[3]])\n",
    "                                 ]))\n",
    "            t.append(int(e[6]))\n",
    "\n",
    "    dataset.src = torch.tensor(src)\n",
    "    dataset.dst = torch.tensor(dst)\n",
    "    dataset.t = torch.tensor(t)\n",
    "    dataset.msg = torch.vstack(msg)\n",
    "    dataset.src = dataset.src.to(torch.long)\n",
    "    dataset.dst = dataset.dst.to(torch.long)\n",
    "    dataset.msg = dataset.msg.to(torch.float)\n",
    "    dataset.t = dataset.t.to(torch.long)\n",
    "    torch.save(dataset, f\"/home/shahidul2k9/data/optc/out/evaluation/9_{day}_host={hostname}_datalabel={datalabel}.TemporalData\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h660 23-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in tqdm(range(23,26)):\n",
    "    start_timestamp=datetime_to_timestamp_US('2019-09-'+str(day)+'T00:00:00')\n",
    "    end_timestamp=datetime_to_timestamp_US('2019-09-'+str(day+1)+'T00:00:00')\n",
    "    hostname='SysClient0660'\n",
    "    datalabel='evaluation'\n",
    "    sql=f\"\"\"\n",
    "    select * from event_table\n",
    "    where\n",
    "          timestamp>{start_timestamp} and timestamp<{end_timestamp}\n",
    "          and hostname='{hostname}' and data_label='{datalabel}' ORDER BY timestamp;\n",
    "    \"\"\"\n",
    "    cur.execute(sql)\n",
    "    events = cur.fetchall()\n",
    "    print(f\"{len(events)=}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    node_set=set()\n",
    "    node_uuid2index={}\n",
    "    temp_index=0\n",
    "    for e in events:\n",
    "        if e[3] not in node_uuid2path or e[0]  not in node_uuid2path:\n",
    "            continue\n",
    "\n",
    "        if e[0] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[0]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[0]]\n",
    "            temp_index+=1\n",
    "\n",
    "        if e[3] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[3]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[3]]\n",
    "            temp_index+=1 \n",
    "\n",
    "    torch.save(node_uuid2index,f'node_uuid2index_9_{day}_host={hostname}_datalabel={datalabel}')\n",
    "       \n",
    "\n",
    "    dataset = TemporalData()\n",
    "    src = []\n",
    "    dst = []\n",
    "    msg = []\n",
    "    t = []\n",
    "    for e in (events):\n",
    "        if e[3] in node_uuid2index and e[0] in node_uuid2index:\n",
    "            # If the image path of the node is not recorded, then skip this edge\n",
    "            src.append(node_uuid2index[e[0]])\n",
    "            dst.append(node_uuid2index[e[3]])\n",
    "        #     msg.append(torch.cat([torch.from_numpy(node2higvec_bn[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec_bn[i[1]])] ))\n",
    "\n",
    "            msg.append(torch.cat([str2tensor(e[1],node_uuid2path[e[0]]), \n",
    "                                  edge2vec[e[2]], \n",
    "                                  str2tensor(e[4],node_uuid2path[e[3]])\n",
    "                                 ]))\n",
    "            t.append(int(e[6]))\n",
    "\n",
    "    dataset.src = torch.tensor(src)\n",
    "    dataset.dst = torch.tensor(dst)\n",
    "    dataset.t = torch.tensor(t)\n",
    "    dataset.msg = torch.vstack(msg)\n",
    "    dataset.src = dataset.src.to(torch.long)\n",
    "    dataset.dst = dataset.dst.to(torch.long)\n",
    "    dataset.msg = dataset.msg.to(torch.float)\n",
    "    dataset.t = dataset.t.to(torch.long)\n",
    "    torch.save(dataset, f\"/home/shahidul2k9/data/optc/out/evaluation/9_{day}_host={hostname}_datalabel={datalabel}.TemporalData\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h501 23-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in tqdm(range(23,26)):\n",
    "    start_timestamp=datetime_to_timestamp_US('2019-09-'+str(day)+'T00:00:00')\n",
    "    end_timestamp=datetime_to_timestamp_US('2019-09-'+str(day+1)+'T00:00:00')\n",
    "    hostname='SysClient0501'\n",
    "    datalabel='evaluation'\n",
    "    sql=f\"\"\"\n",
    "    select * from event_table\n",
    "    where\n",
    "          timestamp>{start_timestamp} and timestamp<{end_timestamp}\n",
    "          and hostname='{hostname}' and data_label='{datalabel}' ORDER BY timestamp;\n",
    "    \"\"\"\n",
    "    cur.execute(sql)\n",
    "    events = cur.fetchall()\n",
    "    print(f\"{len(events)=}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    node_set=set()\n",
    "    node_uuid2index={}\n",
    "    temp_index=0\n",
    "    for e in events:\n",
    "        if e[3] not in node_uuid2path or e[0]  not in node_uuid2path:\n",
    "            continue\n",
    "\n",
    "        if e[0] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[0]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[0]]\n",
    "            temp_index+=1\n",
    "\n",
    "        if e[3] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[3]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[3]]\n",
    "            temp_index+=1 \n",
    "\n",
    "    torch.save(node_uuid2index,f'node_uuid2index_9_{day}_host={hostname}_datalabel={datalabel}')\n",
    "       \n",
    "\n",
    "    dataset = TemporalData()\n",
    "    src = []\n",
    "    dst = []\n",
    "    msg = []\n",
    "    t = []\n",
    "    for e in (events):\n",
    "        if e[3] in node_uuid2index and e[0] in node_uuid2index:\n",
    "            # If the image path of the node is not recorded, then skip this edge\n",
    "            src.append(node_uuid2index[e[0]])\n",
    "            dst.append(node_uuid2index[e[3]])\n",
    "        #     msg.append(torch.cat([torch.from_numpy(node2higvec_bn[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec_bn[i[1]])] ))\n",
    "\n",
    "            msg.append(torch.cat([str2tensor(e[1],node_uuid2path[e[0]]), \n",
    "                                  edge2vec[e[2]], \n",
    "                                  str2tensor(e[4],node_uuid2path[e[3]])\n",
    "                                 ]))\n",
    "            t.append(int(e[6]))\n",
    "\n",
    "    dataset.src = torch.tensor(src)\n",
    "    dataset.dst = torch.tensor(dst)\n",
    "    dataset.t = torch.tensor(t)\n",
    "    dataset.msg = torch.vstack(msg)\n",
    "    dataset.src = dataset.src.to(torch.long)\n",
    "    dataset.dst = dataset.dst.to(torch.long)\n",
    "    dataset.msg = dataset.msg.to(torch.float)\n",
    "    dataset.t = dataset.t.to(torch.long)\n",
    "    torch.save(dataset, f\"/home/shahidul2k9/data/optc/out/evaluation/9_{day}_host={hostname}_datalabel={datalabel}.TemporalData\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h051 23-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in tqdm(range(23,26)):\n",
    "    start_timestamp=datetime_to_timestamp_US('2019-09-'+str(day)+'T00:00:00')\n",
    "    end_timestamp=datetime_to_timestamp_US('2019-09-'+str(day+1)+'T00:00:00')\n",
    "    hostname='SysClient0051'\n",
    "    datalabel='evaluation'\n",
    "    sql=f\"\"\"\n",
    "    select * from event_table\n",
    "    where\n",
    "          timestamp>{start_timestamp} and timestamp<{end_timestamp}\n",
    "          and hostname='{hostname}' and data_label='{datalabel}' ORDER BY timestamp;\n",
    "    \"\"\"\n",
    "    cur.execute(sql)\n",
    "    events = cur.fetchall()\n",
    "    print(f\"{len(events)=}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    node_set=set()\n",
    "    node_uuid2index={}\n",
    "    temp_index=0\n",
    "    for e in events:\n",
    "        if e[3] not in node_uuid2path or e[0]  not in node_uuid2path:\n",
    "            continue\n",
    "\n",
    "        if e[0] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[0]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[0]]\n",
    "            temp_index+=1\n",
    "\n",
    "        if e[3] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[3]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[3]]\n",
    "            temp_index+=1 \n",
    "\n",
    "    torch.save(node_uuid2index,f'node_uuid2index_9_{day}_host={hostname}_datalabel={datalabel}')\n",
    "       \n",
    "\n",
    "    dataset = TemporalData()\n",
    "    src = []\n",
    "    dst = []\n",
    "    msg = []\n",
    "    t = []\n",
    "    for e in (events):\n",
    "        if e[3] in node_uuid2index and e[0] in node_uuid2index:\n",
    "            # If the image path of the node is not recorded, then skip this edge\n",
    "            src.append(node_uuid2index[e[0]])\n",
    "            dst.append(node_uuid2index[e[3]])\n",
    "        #     msg.append(torch.cat([torch.from_numpy(node2higvec_bn[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec_bn[i[1]])] ))\n",
    "\n",
    "            msg.append(torch.cat([str2tensor(e[1],node_uuid2path[e[0]]), \n",
    "                                  edge2vec[e[2]], \n",
    "                                  str2tensor(e[4],node_uuid2path[e[3]])\n",
    "                                 ]))\n",
    "            t.append(int(e[6]))\n",
    "\n",
    "    dataset.src = torch.tensor(src)\n",
    "    dataset.dst = torch.tensor(dst)\n",
    "    dataset.t = torch.tensor(t)\n",
    "    dataset.msg = torch.vstack(msg)\n",
    "    dataset.src = dataset.src.to(torch.long)\n",
    "    dataset.dst = dataset.dst.to(torch.long)\n",
    "    dataset.msg = dataset.msg.to(torch.float)\n",
    "    dataset.t = dataset.t.to(torch.long)\n",
    "    torch.save(dataset, f\"/home/shahidul2k9/data/optc/out/evaluation/9_{day}_host={hostname}_datalabel={datalabel}.TemporalData\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h207 23-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in tqdm(range(23,26)):\n",
    "    start_timestamp=datetime_to_timestamp_US('2019-09-'+str(day)+'T00:00:00')\n",
    "    end_timestamp=datetime_to_timestamp_US('2019-09-'+str(day+1)+'T00:00:00')\n",
    "    hostname='SysClient0207'\n",
    "    datalabel='evaluation'\n",
    "    sql=f\"\"\"\n",
    "    select * from event_table\n",
    "    where\n",
    "          timestamp>{start_timestamp} and timestamp<{end_timestamp}\n",
    "          and hostname='{hostname}' and data_label='{datalabel}' ORDER BY timestamp;\n",
    "    \"\"\"\n",
    "    cur.execute(sql)\n",
    "    events = cur.fetchall()\n",
    "    print(f\"{len(events)=}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    node_set=set()\n",
    "    node_uuid2index={}\n",
    "    temp_index=0\n",
    "    for e in events:\n",
    "        if e[3] not in node_uuid2path or e[0]  not in node_uuid2path:\n",
    "            continue\n",
    "\n",
    "        if e[0] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[0]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[0]]\n",
    "            temp_index+=1\n",
    "\n",
    "        if e[3] in node_uuid2index:\n",
    "            pass\n",
    "        else:\n",
    "            node_uuid2index[e[3]]=temp_index\n",
    "            node_uuid2index[temp_index]=node_uuid2path[e[3]]\n",
    "            temp_index+=1 \n",
    "\n",
    "    torch.save(node_uuid2index,f'node_uuid2index_9_{day}_host={hostname}_datalabel={datalabel}')\n",
    "       \n",
    "\n",
    "    dataset = TemporalData()\n",
    "    src = []\n",
    "    dst = []\n",
    "    msg = []\n",
    "    t = []\n",
    "    for e in (events):\n",
    "        if e[3] in node_uuid2index and e[0] in node_uuid2index:\n",
    "            # If the image path of the node is not recorded, then skip this edge\n",
    "            src.append(node_uuid2index[e[0]])\n",
    "            dst.append(node_uuid2index[e[3]])\n",
    "        #     msg.append(torch.cat([torch.from_numpy(node2higvec_bn[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec_bn[i[1]])] ))\n",
    "\n",
    "            msg.append(torch.cat([str2tensor(e[1],node_uuid2path[e[0]]), \n",
    "                                  edge2vec[e[2]], \n",
    "                                  str2tensor(e[4],node_uuid2path[e[3]])\n",
    "                                 ]))\n",
    "            t.append(int(e[6]))\n",
    "\n",
    "    dataset.src = torch.tensor(src)\n",
    "    dataset.dst = torch.tensor(dst)\n",
    "    dataset.t = torch.tensor(t)\n",
    "    dataset.msg = torch.vstack(msg)\n",
    "    dataset.src = dataset.src.to(torch.long)\n",
    "    dataset.dst = dataset.dst.to(torch.long)\n",
    "    dataset.msg = dataset.msg.to(torch.float)\n",
    "    dataset.t = dataset.t.to(torch.long)\n",
    "    torch.save(dataset, f\"/home/shahidul2k9/data/optc/out/evaluation/9_{day}_host={hostname}_datalabel={datalabel}.TemporalData\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A CSV file containing the ground truth nodes&edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df=pd.read_csv(\"./labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nodes_attack={}\n",
    "edges_attack_list=[]\n",
    "\n",
    "for idx,row in label_df.iterrows():\n",
    "    flag=False\n",
    "    if row['objectID'] in node_uuid2path:\n",
    "        nodes_attack[row['objectID']]=node_uuid2path[row['objectID']]\n",
    "        flag=True\n",
    "    if row['actorID'] in node_uuid2path:\n",
    "        nodes_attack[row['actorID']]=node_uuid2path[row['actorID']]\n",
    "        flag=True\n",
    "    if flag and row['action'] in edge2vec:    \n",
    "#         and row['action'] in edge2vec\n",
    "        temp_dic={}\n",
    "        temp_dic['src_uuid']=row['actorID']\n",
    "        temp_dic['dst_uuid']=row['objectID']\n",
    "        temp_dic['edge_type']=row['action']\n",
    "        temp_dic['timestamp']=datetime_to_timestamp_US(row['timestamp'])\n",
    "\n",
    "        edges_attack_list.append(temp_dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(edges_attack_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nodes_attack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics (Num of nodes and edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_9_22_h201=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_22_host=SysClient0201_datalabel=benign.TemporalData\")\n",
    "graph_9_22_h402=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_22_host=SysClient0402_datalabel=benign.TemporalData\")\n",
    "graph_9_22_h660=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_22_host=SysClient0660_datalabel=benign.TemporalData\")\n",
    "graph_9_22_h501=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_22_host=SysClient0501_datalabel=benign.TemporalData\")\n",
    "graph_9_22_h051=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_22_host=SysClient0051_datalabel=benign.TemporalData\")\n",
    "graph_9_22_h209=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_22_host=SysClient0209_datalabel=benign.TemporalData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_9_23_h201=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_23_host=SysClient0201_datalabel=evaluation.TemporalData\")\n",
    "graph_9_24_h201=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_24_host=SysClient0201_datalabel=evaluation.TemporalData\")\n",
    "graph_9_25_h201=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_25_host=SysClient0201_datalabel=evaluation.TemporalData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_9_23_h402=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_23_host=SysClient0402_datalabel=evaluation.TemporalData\")\n",
    "graph_9_24_h402=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_24_host=SysClient0402_datalabel=evaluation.TemporalData\")\n",
    "graph_9_25_h402=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_25_host=SysClient0402_datalabel=evaluation.TemporalData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_9_23_h660=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_23_host=SysClient0660_datalabel=evaluation.TemporalData\")\n",
    "graph_9_24_h660=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_24_host=SysClient0660_datalabel=evaluation.TemporalData\")\n",
    "graph_9_25_h660=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_25_host=SysClient0660_datalabel=evaluation.TemporalData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_9_23_h501=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_23_host=SysClient0501_datalabel=evaluation.TemporalData\")\n",
    "graph_9_24_h501=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_24_host=SysClient0501_datalabel=evaluation.TemporalData\")\n",
    "graph_9_25_h501=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_25_host=SysClient0501_datalabel=evaluation.TemporalData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_9_23_h051=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_23_host=SysClient0051_datalabel=evaluation.TemporalData\")\n",
    "graph_9_24_h051=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_24_host=SysClient0051_datalabel=evaluation.TemporalData\")\n",
    "graph_9_25_h051=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_25_host=SysClient0051_datalabel=evaluation.TemporalData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_9_23_h207=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_23_host=SysClient0207_datalabel=evaluation.TemporalData\")\n",
    "graph_9_24_h207=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_24_host=SysClient0207_datalabel=evaluation.TemporalData\")\n",
    "graph_9_25_h207=torch.load(\"/home/shahidul2k9/data/optc/out/evaluation/9_25_host=SysClient0207_datalabel=evaluation.TemporalData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs=[\n",
    "    graph_9_22_h201,\n",
    "    graph_9_22_h402,\n",
    "    graph_9_22_h660,\n",
    "    graph_9_22_h501,\n",
    "    graph_9_22_h051,\n",
    "    graph_9_22_h209,\n",
    "    \n",
    "    graph_9_23_h201,\n",
    "    graph_9_24_h201,\n",
    "    graph_9_25_h201,\n",
    "    \n",
    "    graph_9_23_h402,\n",
    "    graph_9_24_h402,\n",
    "    graph_9_25_h402,\n",
    "    \n",
    "    graph_9_23_h660,\n",
    "    graph_9_24_h660,\n",
    "    graph_9_25_h660,\n",
    "    \n",
    "    graph_9_23_h501,\n",
    "    graph_9_24_h501,\n",
    "    graph_9_25_h501,\n",
    "    \n",
    "    graph_9_23_h051,\n",
    "    graph_9_24_h051,\n",
    "    graph_9_25_h051,\n",
    "    \n",
    "    graph_9_23_h207,\n",
    "    graph_9_24_h207,\n",
    "    graph_9_25_h207,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "edges_count=0\n",
    "for g in graphs:\n",
    "     edges_count+=len(g.t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_uuid2index_9_22_h201=torch.load(\"node_uuid2index_9_22_host=SysClient0201_datalabel=benign\")\n",
    "node_uuid2index_9_22_h402=torch.load(\"node_uuid2index_9_22_host=SysClient0402_datalabel=benign\")\n",
    "node_uuid2index_9_22_h660=torch.load(\"node_uuid2index_9_22_host=SysClient0660_datalabel=benign\")\n",
    "node_uuid2index_9_22_h501=torch.load(\"node_uuid2index_9_22_host=SysClient0501_datalabel=benign\")\n",
    "node_uuid2index_9_22_h051=torch.load(\"node_uuid2index_9_22_host=SysClient0051_datalabel=benign\")\n",
    "node_uuid2index_9_22_h209=torch.load(\"node_uuid2index_9_22_host=SysClient0209_datalabel=benign\")\n",
    "\n",
    "\n",
    "node_uuid2index_9_23_h201=torch.load(\"node_uuid2index_9_23_host=SysClient0201_datalabel=evaluation\")\n",
    "node_uuid2index_9_24_h201=torch.load(\"node_uuid2index_9_24_host=SysClient0201_datalabel=evaluation\")\n",
    "node_uuid2index_9_25_h201=torch.load(\"node_uuid2index_9_25_host=SysClient0201_datalabel=evaluation\")\n",
    "\n",
    "node_uuid2index_9_23_h402=torch.load(\"node_uuid2index_9_23_host=SysClient0402_datalabel=evaluation\")\n",
    "node_uuid2index_9_24_h402=torch.load(\"node_uuid2index_9_24_host=SysClient0402_datalabel=evaluation\")\n",
    "node_uuid2index_9_25_h402=torch.load(\"node_uuid2index_9_25_host=SysClient0402_datalabel=evaluation\")\n",
    "\n",
    "node_uuid2index_9_23_h660=torch.load(\"node_uuid2index_9_23_host=SysClient0660_datalabel=evaluation\")\n",
    "node_uuid2index_9_24_h660=torch.load(\"node_uuid2index_9_24_host=SysClient0660_datalabel=evaluation\")\n",
    "node_uuid2index_9_25_h660=torch.load(\"node_uuid2index_9_25_host=SysClient0660_datalabel=evaluation\")\n",
    "\n",
    "node_uuid2index_9_23_h501=torch.load(\"node_uuid2index_9_23_host=SysClient0501_datalabel=evaluation\")\n",
    "node_uuid2index_9_24_h501=torch.load(\"node_uuid2index_9_24_host=SysClient0501_datalabel=evaluation\")\n",
    "node_uuid2index_9_25_h501=torch.load(\"node_uuid2index_9_25_host=SysClient0501_datalabel=evaluation\")\n",
    "\n",
    "node_uuid2index_9_23_h051=torch.load(\"node_uuid2index_9_23_host=SysClient0051_datalabel=evaluation\")\n",
    "node_uuid2index_9_24_h051=torch.load(\"node_uuid2index_9_24_host=SysClient0051_datalabel=evaluation\")\n",
    "node_uuid2index_9_25_h051=torch.load(\"node_uuid2index_9_25_host=SysClient0051_datalabel=evaluation\")\n",
    "\n",
    "node_uuid2index_9_23_h207=torch.load(\"node_uuid2index_9_23_host=SysClient0207_datalabel=evaluation\")\n",
    "node_uuid2index_9_24_h207=torch.load(\"node_uuid2index_9_24_host=SysClient0207_datalabel=evaluation\")\n",
    "node_uuid2index_9_25_h207=torch.load(\"node_uuid2index_9_25_host=SysClient0207_datalabel=evaluation\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_dics=[\n",
    "    node_uuid2index_9_22_h201,\n",
    "    node_uuid2index_9_22_h402,\n",
    "    node_uuid2index_9_22_h660,\n",
    "    node_uuid2index_9_22_h501,\n",
    "    node_uuid2index_9_22_h051,\n",
    "    node_uuid2index_9_22_h209,\n",
    "    node_uuid2index_9_23_h201,\n",
    "    node_uuid2index_9_24_h201,\n",
    "    node_uuid2index_9_25_h201,\n",
    "    node_uuid2index_9_23_h402,\n",
    "    node_uuid2index_9_24_h402,\n",
    "    node_uuid2index_9_25_h402,\n",
    "    node_uuid2index_9_23_h660,\n",
    "    node_uuid2index_9_24_h660,\n",
    "    node_uuid2index_9_25_h660,\n",
    "    node_uuid2index_9_23_h501,\n",
    "    node_uuid2index_9_24_h501,\n",
    "    node_uuid2index_9_25_h501,\n",
    "    node_uuid2index_9_23_h051,\n",
    "    node_uuid2index_9_24_h051,\n",
    "    node_uuid2index_9_25_h051,\n",
    "    node_uuid2index_9_23_h207,\n",
    "    node_uuid2index_9_24_h207,\n",
    "    node_uuid2index_9_25_h207,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes=set()\n",
    "for dic in node_dics:\n",
    "    for n in dic:\n",
    "        if type(n)==str:\n",
    "            nodes.add(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kairos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "47.7109px",
    "left": "21px",
    "top": "204.141px",
    "width": "199.344px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

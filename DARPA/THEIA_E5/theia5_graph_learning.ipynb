{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs/grad/opumni/Fall2024/COMP7860_Project/.conda/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# encoding=utf-8\n",
    "import os.path as osp\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "from torch_geometric.data import TemporalData\n",
    "from torch_geometric.datasets import JODIEDataset\n",
    "from torch_geometric.datasets import ICEWS18\n",
    "from torch_geometric.nn import TGNMemory, TransformerConv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn.models.tgn import (LastNeighborLoader, IdentityMessage, MeanAggregator,\n",
    "                                           LastAggregator)\n",
    "from torch_geometric import *\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "from random import choice\n",
    "import gc\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "# msg structure:      [src_node_feature,edge_attr,dst_node_feature]\n",
    "\n",
    "# compute the best partition\n",
    "import datetime\n",
    "# import community as community_louvain\n",
    "\n",
    "import xxhash\n",
    "\n",
    "# Find the edge index which the edge vector is corresponding to\n",
    "def tensor_find(t,x):\n",
    "    \"\"\"\n",
    "    Find the 1-based row index of the first occurrence of a value in a PyTorch tensor.\n",
    "\n",
    "    Parameters:\n",
    "    t (torch.Tensor): The PyTorch tensor to search.\n",
    "    x (Any): The value to locate within the tensor.\n",
    "\n",
    "    Returns:\n",
    "    int: The 1-based row index of the first occurrence of the value in the tensor.\n",
    "    \"\"\"\n",
    "    t_np=t.cpu().numpy()\n",
    "    idx=np.argwhere(t_np==x)\n",
    "    return idx[0][0]+1\n",
    "\n",
    "\n",
    "def std(t):\n",
    "    \"\"\"\n",
    "    Calculate the standard deviation of elements in the input data.\n",
    "\n",
    "    Parameters:\n",
    "    t (list, tuple, or ndarray): The input data to compute the standard deviation.\n",
    "                                 This can be a Python list, tuple, or a NumPy ndarray.\n",
    "\n",
    "    Returns:\n",
    "    float: The standard deviation of the input data.\n",
    "    \"\"\"\n",
    "    t = np.array(t)\n",
    "    return np.std(t)\n",
    "\n",
    "\n",
    "def var(t):\n",
    "    \"\"\"\n",
    "    Calculate the variance of elements in the input data.\n",
    "\n",
    "    Parameters:\n",
    "    t (list, tuple, or ndarray): The input data to compute the variance.\n",
    "                                 This can be a Python list, tuple, or a NumPy ndarray.\n",
    "\n",
    "    Returns:\n",
    "    float: The variance of the input data.\n",
    "    \"\"\"\n",
    "    t = np.array(t)\n",
    "    return np.var(t)\n",
    "\n",
    "\n",
    "def mean(t):\n",
    "    \"\"\"\n",
    "    Calculate the mean of elements in the input data.\n",
    "\n",
    "    Parameters:\n",
    "    t (list, tuple, or ndarray): The input data to compute the mean.\n",
    "                                 This can be a Python list, tuple, or a NumPy ndarray.\n",
    "\n",
    "    Returns:\n",
    "    float: The mean of the input data.\n",
    "    \"\"\"\n",
    "    t = np.array(t)\n",
    "    return np.mean(t)\n",
    "\n",
    "def hashgen(l):\n",
    "    \"\"\"\n",
    "    Generate a single hash value from a list of string values.\n",
    "\n",
    "    Parameters:\n",
    "    l (list of str): A list of string values, which can represent properties of a node or edge.\n",
    "\n",
    "    Returns:\n",
    "    int: A single hashed integer value generated from the input list.\n",
    "    \"\"\"\n",
    "    hasher = xxhash.xxh64()\n",
    "    for e in l:\n",
    "        hasher.update(e)\n",
    "    return hasher.intdigest()\n",
    "\n",
    "\n",
    "def cal_pos_edges_loss(link_pred_ratio):\n",
    "    \"\"\"\n",
    "    Calculate the loss for positive edges using a binary classification approach.\n",
    "\n",
    "    Parameters:\n",
    "    link_pred_ratio (list or Tensor): A list or tensor containing predicted link probabilities.\n",
    "\n",
    "    Returns:\n",
    "    Tensor: A tensor containing the computed loss for each prediction.\n",
    "    \"\"\"\n",
    "    loss = []\n",
    "    for i in link_pred_ratio:\n",
    "        # Compare predicted values with a target tensor of ones (positive class)\n",
    "        loss.append(criterion(i, torch.ones(1)))\n",
    "    return torch.tensor(loss)\n",
    "\n",
    "\n",
    "def cal_pos_edges_loss_multiclass(link_pred_ratio, labels):\n",
    "    \"\"\"\n",
    "    Calculate the loss for positive edges in a multi-class classification setting.\n",
    "\n",
    "    Parameters:\n",
    "    link_pred_ratio (list of Tensors): A list of tensors containing predicted class probabilities for links.\n",
    "    labels (list of Tensors): A list of tensors containing the ground truth labels for the links.\n",
    "\n",
    "    Returns:\n",
    "    Tensor: A tensor containing the computed loss for each prediction.\n",
    "    \"\"\"\n",
    "    loss = []\n",
    "    for i in range(len(link_pred_ratio)):\n",
    "        # Compare predicted values with ground truth labels for multi-class classification\n",
    "        loss.append(criterion(link_pred_ratio[i].reshape(1, -1), labels[i].reshape(-1)))\n",
    "    return torch.tensor(loss)\n",
    "\n",
    "\n",
    "def cal_pos_edges_loss_autoencoder(decoded, msg):\n",
    "    \"\"\"\n",
    "    Calculate the loss for positive edges in an autoencoder setting.\n",
    "\n",
    "    Parameters:\n",
    "    decoded (list of Tensors): A list of tensors representing the decoded outputs.\n",
    "    msg (list of Tensors): A list of tensors representing the original messages (inputs to the autoencoder).\n",
    "\n",
    "    Returns:\n",
    "    Tensor: A tensor containing the computed loss for each decoded message.\n",
    "    \"\"\"\n",
    "    loss = []\n",
    "    for i in range(len(decoded)):\n",
    "        # Compare the decoded outputs with the original messages\n",
    "        loss.append(criterion(decoded[i].reshape(1, -1), msg[i].reshape(-1)))\n",
    "    return torch.tensor(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(120000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 120 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 120  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "import time\n",
    "import pytz\n",
    "from time import mktime\n",
    "from datetime import datetime\n",
    "import time\n",
    "def ns_time_to_datetime(ns):\n",
    "    \"\"\"\n",
    "    :param ns: int nano timestamp\n",
    "    :return: datetime   format: 2013-10-10 23:40:00.000000000\n",
    "    \"\"\"\n",
    "    dt = datetime.fromtimestamp(int(ns) // 1000000000)\n",
    "    s = dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    s += '.' + str(int(int(ns) % 1000000000)).zfill(9)\n",
    "    return s\n",
    "\n",
    "def ns_time_to_datetime_US(ns):\n",
    "    \"\"\"\n",
    "    :param ns: int nano timestamp\n",
    "    :return: datetime   format: 2013-10-10 23:40:00.000000000\n",
    "    \"\"\"\n",
    "    tz = pytz.timezone('US/Eastern')\n",
    "    dt = pytz.datetime.datetime.fromtimestamp(int(ns) // 1000000000, tz)\n",
    "    s = dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    s += '.' + str(int(int(ns) % 1000000000)).zfill(9)\n",
    "    return s\n",
    "\n",
    "def time_to_datetime_US(s):\n",
    "    \"\"\"\n",
    "    :param ns: int nano timestamp\n",
    "    :return: datetime   format: 2013-10-10 23:40:00\n",
    "    \"\"\"\n",
    "    tz = pytz.timezone('US/Eastern')\n",
    "    dt = pytz.datetime.datetime.fromtimestamp(int(s), tz)\n",
    "    s = dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    return s\n",
    "\n",
    "def datetime_to_ns_time(date):\n",
    "    \"\"\"\n",
    "    :param date: str   format: %Y-%m-%d %H:%M:%S   e.g. 2013-10-10 23:40:00\n",
    "    :return: nano timestamp\n",
    "    \"\"\"\n",
    "    timeArray = time.strptime(date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    timeStamp = int(time.mktime(timeArray))\n",
    "    timeStamp = timeStamp * 1000000000\n",
    "    return timeStamp\n",
    "\n",
    "def datetime_to_ns_time_US(date):\n",
    "    \"\"\"\n",
    "    :param date: str   format: %Y-%m-%d %H:%M:%S   e.g. 2013-10-10 23:40:00\n",
    "    :return: nano timestamp\n",
    "    \"\"\"\n",
    "    tz = pytz.timezone('US/Eastern')\n",
    "    timeArray = time.strptime(date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    dt = datetime.fromtimestamp(mktime(timeArray))\n",
    "    timestamp = tz.localize(dt)\n",
    "    timestamp = timestamp.timestamp()\n",
    "    timeStamp = timestamp * 1000000000\n",
    "    return int(timeStamp)\n",
    "\n",
    "def datetime_to_timestamp_US(date):\n",
    "    \"\"\"\n",
    "    :param date: str   format: %Y-%m-%d %H:%M:%S   e.g. 2013-10-10 23:40:00\n",
    "    :return: nano timestamp\n",
    "    \"\"\"\n",
    "    tz = pytz.timezone('US/Eastern')\n",
    "    timeArray = time.strptime(date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    dt = datetime.fromtimestamp(mktime(timeArray))\n",
    "    timestamp = tz.localize(dt)\n",
    "    timestamp = timestamp.timestamp()\n",
    "    timeStamp = timestamp\n",
    "    return int(timeStamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "from psycopg2 import extras as ex\n",
    "connect = psycopg2.connect(database = 'tc_e5_theia_dataset_db',\n",
    "                           host = 'localhost',\n",
    "                           user = 'postgres',\n",
    "                           password = '123456',\n",
    "                           port = '5432'\n",
    "                          )\n",
    "\n",
    "cur = connect.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_5_8=torch.load(\"./train_graphs/graph_5_8.TemporalData.simple\").to(device=device)\n",
    "graph_5_9=torch.load(\"./train_graphs/graph_5_9.TemporalData.simple\").to(device=device)\n",
    "\n",
    "\n",
    "train_data=graph_5_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the map for nodeid to msg\n",
    "sql=\"select * from node2id ORDER BY index_id;\"\n",
    "cur.execute(sql)\n",
    "rows = cur.fetchall()\n",
    "\n",
    "nodeid2msg={}  # nodeid => msg and node hash => nodeid\n",
    "for i in rows:\n",
    "    nodeid2msg[i[0]]=i[-1]\n",
    "    nodeid2msg[i[-1]]={i[1]:i[2]}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel2id={1: 'EVENT_CONNECT',\n",
    " 'EVENT_CONNECT': 1,\n",
    " 2: 'EVENT_EXECUTE',\n",
    " 'EVENT_EXECUTE': 2,\n",
    " 3: 'EVENT_OPEN',\n",
    " 'EVENT_OPEN': 3,\n",
    " 4: 'EVENT_READ',\n",
    " 'EVENT_READ': 4,\n",
    " 5: 'EVENT_RECVFROM',\n",
    " 'EVENT_RECVFROM': 5,\n",
    " 6: 'EVENT_RECVMSG',\n",
    " 'EVENT_RECVMSG': 6,\n",
    " 7: 'EVENT_SENDMSG',\n",
    " 'EVENT_SENDMSG': 7,\n",
    " 8: 'EVENT_SENDTO',\n",
    " 'EVENT_SENDTO': 8,\n",
    " 9: 'EVENT_WRITE',\n",
    " 'EVENT_WRITE': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, val_data, test_data = data.train_val_test_split(val_ratio=0.15, test_ratio=0.15)\n",
    "# max_node_num = max(torch.cat([data.dst,data.src]))+1\n",
    "# max_node_num = data.num_nodes+1\n",
    "max_node_num = 967389  # +1\n",
    "# min_dst_idx, max_dst_idx = int(data.dst.min()), int(data.dst.max())\n",
    "min_dst_idx, max_dst_idx = 0, max_node_num\n",
    "neighbor_loader = LastNeighborLoader(max_node_num, size=20, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphAttentionEmbedding(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    The GraphAttentionEmbedding class implements a graph attention-based \n",
    "    embedding model using a two-layer TransformerConv. \n",
    "    It is designed for temporal graph networks, where the embedding considers \n",
    "    both node features and edge attributes, including temporal information.\n",
    "\n",
    "    Parameters:\n",
    "    - in_channels (int): Input feature dimensionality for nodes.\n",
    "    - out_channels (int): Output feature dimensionality for nodes.\n",
    "    - msg_dim (int): Dimensionality of edge message features.\n",
    "    - time_enc (TimeEncoder): Time encoding module.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, msg_dim, time_enc):\n",
    "        super(GraphAttentionEmbedding, self).__init__()\n",
    "        self.time_enc = time_enc\n",
    "        edge_dim = msg_dim + time_enc.out_channels\n",
    "\n",
    "        # First TransformerConv layer with 8 heads\n",
    "        self.conv = TransformerConv(in_channels, out_channels, heads=8,\n",
    "                                    dropout=0.0, edge_dim=edge_dim)\n",
    "        \n",
    "        # Second TransformerConv layer with 1 head, no concatenation\n",
    "        self.conv2 = TransformerConv(out_channels*8, out_channels,heads=1, concat=False,\n",
    "                             dropout=0.0, edge_dim=edge_dim)\n",
    "\n",
    "    def forward(self, x, last_update, edge_index, t, msg):\n",
    "        \"\"\"\n",
    "        Forward pass of the GraphAttentionEmbedding model.\n",
    "\n",
    "        Parameters:\n",
    "        - x (torch.Tensor): Node features of shape (num_nodes, in_channels).\n",
    "        - last_update (torch.Tensor): Timestamps of last updates for each node.\n",
    "        - edge_index (torch.Tensor): Edge index in COO format of shape (2, num_edges).\n",
    "        - t (torch.Tensor): Edge timestamps of shape (num_edges,).\n",
    "        - msg (torch.Tensor): Edge message features of shape (num_edges, msg_dim).\n",
    "\n",
    "        Returns:\n",
    "        - torch.Tensor: Updated node embeddings of shape (num_nodes, out_channels).\n",
    "        \"\"\"\n",
    "        last_update.to(device)\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "\n",
    "        # Compute relative time differences and encode them\n",
    "        rel_t = last_update[edge_index[0]] - t\n",
    "        rel_t_enc = self.time_enc(rel_t.to(x.dtype))\n",
    "\n",
    "        # Concatenate relative time encoding and message features as edge attributes\n",
    "        edge_attr = torch.cat([rel_t_enc, msg], dim=-1)\n",
    "\n",
    "        # Apply the first TransformerConv layer with ReLU activation\n",
    "        x = F.relu(self.conv(x, edge_index, edge_attr))\n",
    "\n",
    "        # Apply the second TransformerConv layer with ReLU activation\n",
    "        x = F.relu(self.conv2(x, edge_index, edge_attr))\n",
    "        return x\n",
    "\n",
    "\n",
    "class LinkPredictor(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A neural network for Event Type pediction tasks, transforming node embeddings\n",
    "    and predicting link properties.\n",
    "\n",
    "    Parameters:\n",
    "    - in_channels (int): The dimensionality of the input node embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        super(LinkPredictor, self).__init__()\n",
    "        \n",
    "        # Linear transformations for source and destination embeddings\n",
    "        self.lin_src = Linear(in_channels, in_channels*2)\n",
    "        self.lin_dst = Linear(in_channels, in_channels*2)\n",
    "        \n",
    "        # Sequential feedforward network for link prediction\n",
    "        self.lin_seq = nn.Sequential(\n",
    "            Linear(in_channels*4, in_channels*8),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            nn.Tanh(),\n",
    "            Linear(in_channels*8, in_channels*2),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            nn.Tanh(),\n",
    "            Linear(in_channels*2, int(in_channels//2)),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            nn.Tanh(),\n",
    "\n",
    "            # Final prediction layer\n",
    "            # train_data.msg contains feature vector of src and dest and edge (event) information.\n",
    "            # train_data.msg.shape[1]-32 is the size of the edge (event) info\n",
    "            Linear(int(in_channels//2), train_data.msg.shape[1]-32)                   \n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, z_src, z_dst):\n",
    "        \"\"\"\n",
    "        Forward pass for the LinkPredictor.\n",
    "\n",
    "        Parameters:\n",
    "        - z_src (torch.Tensor): Source node embeddings, shape (batch_size, in_channels).\n",
    "        - z_dst (torch.Tensor): Destination node embeddings, shape (batch_size, in_channels).\n",
    "\n",
    "        Returns:\n",
    "        - torch.Tensor: Predicted Edge (event) properties, shape (batch_size, train_data.msg.shape[1] - 32).\n",
    "        \"\"\"\n",
    "        h = torch.cat([self.lin_src(z_src) , self.lin_dst(z_dst)],dim=-1)      \n",
    "         \n",
    "        h = self.lin_seq (h)\n",
    "        \n",
    "        return h\n",
    "\n",
    "memory_dim = 100         # node state\n",
    "time_dim = 100\n",
    "embedding_dim = 100      # edge embedding\n",
    "\n",
    "# create the memory\n",
    "memory = TGNMemory(\n",
    "    max_node_num,\n",
    "    train_data.msg.size(-1),\n",
    "    memory_dim,\n",
    "    time_dim,\n",
    "    message_module=IdentityMessage(train_data.msg.size(-1), memory_dim, time_dim),\n",
    "    aggregator_module=LastAggregator(),\n",
    ").to(device)\n",
    "\n",
    "# create the graph neural network with transformer\n",
    "gnn = GraphAttentionEmbedding(\n",
    "    in_channels=memory_dim,\n",
    "    out_channels=embedding_dim,\n",
    "    msg_dim=train_data.msg.size(-1),\n",
    "    time_enc=memory.time_enc,\n",
    ").to(device)\n",
    "\n",
    "# create the MLP link predictor\n",
    "link_pred = LinkPredictor(in_channels=embedding_dim).to(device)\n",
    "\n",
    "# set Adam optimizer for all 3 networks\n",
    "optimizer = torch.optim.Adam(\n",
    "    set(memory.parameters()) | set(gnn.parameters())\n",
    "    | set(link_pred.parameters()), lr=0.00005, eps=1e-08,weight_decay=0.01)\n",
    "\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Helper vector to map global node indices to local ones.\n",
    "assoc = torch.empty(max_node_num, dtype=torch.long, device=device)\n",
    "\n",
    "saved_nodes=set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH=1024\n",
    "\n",
    "def train(train_data):\n",
    "    \"\"\"\n",
    "    Trains the Temporal Graph Network (TGN) using sequential batches of data.\n",
    "\n",
    "    Parameters:\n",
    "    - train_data: Dataset object with sequential batches, timestamps, and messages.\n",
    "\n",
    "    Returns:\n",
    "    - float: Average loss over all events in the training data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set networks to training mode\n",
    "    memory.train()\n",
    "    gnn.train()\n",
    "    link_pred.train()\n",
    "\n",
    "    memory.reset_state()  # Start with a fresh memory.\n",
    "    neighbor_loader.reset_state()  # Start with an empty graph.\n",
    "    saved_nodes=set()\n",
    "\n",
    "    # Tracks total loss over the training data\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Process each batch in the training dataset\n",
    "    for batch in train_data.seq_batches(batch_size=BATCH):\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Extract batch data: source, destination, timestamps, and messages\n",
    "        src, pos_dst, t, msg = batch.src, batch.dst, batch.t, batch.msg        \n",
    "        \n",
    "        # Retrieve unique nodes involved in the batch and their neighbors\n",
    "        n_id = torch.cat([src, pos_dst]).unique()\n",
    "        n_id, edge_index, e_id = neighbor_loader(n_id)\n",
    "\n",
    "        # Helper vector to map global node indices to local ones.\n",
    "        assoc[n_id] = torch.arange(n_id.size(0), device=device)\n",
    "\n",
    "        # Get updated memory of all nodes involved in the computation.\n",
    "        z, last_update = memory(n_id)\n",
    "        \n",
    "        # Pass embeddings through the GNN to update them\n",
    "        z = gnn(z, last_update, edge_index, train_data.t[e_id], train_data.msg[e_id])\n",
    "        \n",
    "        # Compute predictions for positive edges\n",
    "        pos_out = link_pred(z[assoc[src]], z[assoc[pos_dst]])       \n",
    "\n",
    "         # Concatenate predictions\n",
    "        y_pred = torch.cat([pos_out], dim=0)\n",
    "        \n",
    "        # Ground-truth label generation using tensor_find\n",
    "        # msg contains feature vector of src and dest and edge (event) information.\n",
    "        # extracting event info from them\n",
    "        y_true=[]\n",
    "        for m in msg:\n",
    "            l=tensor_find(m[16:-16],1)-1\n",
    "            y_true.append(l)           \n",
    "          \n",
    "        y_true = torch.tensor(y_true).to(device=device)\n",
    "        y_true=y_true.reshape(-1).to(torch.long).to(device=device)\n",
    "        \n",
    "        # Compute loss using predictions and ground-truth labels\n",
    "        loss = criterion(y_pred, y_true)\n",
    "        \n",
    "        # Update memory and neighbor loader with ground-truth state.\n",
    "        memory.update_state(src, pos_dst, t, msg)\n",
    "        neighbor_loader.insert(src, pos_dst)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Detach memory to free computation graph\n",
    "        memory.detach()\n",
    "\n",
    "        # Accumulate total loss scaled by the number of events in the batch\n",
    "        total_loss += float(loss) * batch.num_events\n",
    "\n",
    "    # Return the average loss over all events\n",
    "    return total_loss / train_data.num_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch: 01, Loss: 0.4587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [1:04:52<31:21:11, 3892.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch: 01, Loss: 0.2003\n",
      "  Epoch: 02, Loss: 0.2427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [2:15:27<31:50:40, 4094.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch: 02, Loss: 0.1733\n",
      "  Epoch: 03, Loss: 0.2272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [3:37:47<33:36:06, 4480.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch: 03, Loss: 0.1668\n",
      "  Epoch: 04, Loss: 0.2313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [5:26:57<38:15:32, 5297.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch: 04, Loss: 0.1602\n",
      "  Epoch: 05, Loss: 0.2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [6:53:44<36:33:40, 5264.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch: 05, Loss: 0.1588\n",
      "  Epoch: 06, Loss: 0.2219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [8:36:29<37:08:18, 5570.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch: 06, Loss: 0.1575\n",
      "  Epoch: 07, Loss: 0.2210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [10:11:47<35:53:56, 5618.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch: 07, Loss: 0.1571\n",
      "  Epoch: 08, Loss: 0.2159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [12:10:20<37:14:44, 6094.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch: 08, Loss: 0.1558\n",
      "  Epoch: 09, Loss: 0.2160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [13:54:48<35:52:05, 6148.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch: 09, Loss: 0.1544\n",
      "  Epoch: 10, Loss: 0.2238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [15:37:35<34:11:29, 6154.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch: 10, Loss: 0.1536\n",
      "  Epoch: 11, Loss: 0.2171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [17:26:27<33:05:26, 6269.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch: 11, Loss: 0.1534\n",
      "  Epoch: 12, Loss: 0.2129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [19:02:52<30:36:43, 6122.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch: 12, Loss: 0.1521\n",
      "  Epoch: 13, Loss: 0.2180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [21:00:07<30:13:01, 6398.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch: 13, Loss: 0.1522\n",
      "  Epoch: 14, Loss: 0.2136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [22:41:10<27:59:17, 6297.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch: 14, Loss: 0.1515\n",
      "  Epoch: 15, Loss: 0.2103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [24:30:50<26:35:39, 6382.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch: 15, Loss: 0.1520\n",
      "  Epoch: 16, Loss: 0.2139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [26:26:30<25:28:24, 6550.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch: 16, Loss: 0.1512\n",
      "  Epoch: 17, Loss: 0.2129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [28:27:10<24:24:11, 6757.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch: 17, Loss: 0.1516\n",
      "  Epoch: 18, Loss: 0.2127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [30:12:36<22:05:37, 6628.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch: 18, Loss: 0.1508\n",
      "  Epoch: 19, Loss: 0.2108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [31:53:25<19:43:13, 6453.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch: 19, Loss: 0.1506\n",
      "  Epoch: 20, Loss: 0.2080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [33:31:19<17:26:40, 6280.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch: 20, Loss: 0.1505\n",
      "  Epoch: 21, Loss: 0.2098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [35:25:10<16:06:46, 6445.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch: 21, Loss: 0.1503\n",
      "  Epoch: 22, Loss: 0.2095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [37:15:00<14:25:09, 6488.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch: 22, Loss: 0.1504\n",
      "  Epoch: 23, Loss: 0.2095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [39:02:24<12:35:27, 6475.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch: 23, Loss: 0.1499\n",
      "  Epoch: 24, Loss: 0.2106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [40:48:22<10:44:01, 6440.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch: 24, Loss: 0.1498\n",
      "  Epoch: 25, Loss: 0.2169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [42:49:15<9:16:59, 6683.88s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch: 25, Loss: 0.1502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [43:00:05<8:36:01, 6192.22s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m31\u001b[39m)):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m train_graphs:\n\u001b[0;32m----> 7\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m  Epoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# store the models in file\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 72\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_data)\u001b[0m\n\u001b[1;32m     69\u001b[0m neighbor_loader\u001b[38;5;241m.\u001b[39minsert(src, pos_dst)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Detach memory to free computation graph\u001b[39;00m\n",
      "File \u001b[0;32m~/Fall2024/COMP7860_Project/.conda/lib/python3.9/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Fall2024/COMP7860_Project/.conda/lib/python3.9/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train on benign graphs\n",
    "train_graphs=[graph_5_8,graph_5_9]\n",
    "\n",
    "# train fro 30 epochs\n",
    "for epoch in tqdm(range(1, 31)):\n",
    "    for g in train_graphs:\n",
    "        loss = train(g)\n",
    "        print(f'  Epoch: {epoch:02d}, Loss: {loss:.4f}')\n",
    "\n",
    "# store the models in file\n",
    "model=[memory,gnn, link_pred,neighbor_loader]\n",
    "os.system(\"mkdir -p ./models/\")\n",
    "torch.save(model,\"./models/model_saved_share.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=[memory,gnn, link_pred,neighbor_loader]\n",
    "os.system(\"mkdir -p ./models/\")\n",
    "torch.save(model,\"./models/model_saved_share.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "# Disable gradient computation for inference\n",
    "@torch.no_grad()\n",
    "\n",
    "def test_day_new(inference_data, path):\n",
    "    \"\"\"\n",
    "    Evaluate the Temporal Graph Network (TGN) on inference data.\n",
    "    Stores result for each time window in txt file.\n",
    "    Each text file contains event information. \n",
    "    Example: {'loss': 2.8073678016662598, 'srcnode': 76938, 'dstnode': 868, 'srcmsg': \"{'subject': 'system_server'}\", 'dstmsg': \"{'file': '/data/system/sync/pending.xml'}\", 'edge_type': 'EVENT_OPEN', 'time': 1522814400030000000}\n",
    "\n",
    "    Parameters:\n",
    "    - inference_data: Dataset containing sequential batches for temporal graph inference.\n",
    "    - path (str): Path to save logs and results.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Summary of results, including loss and timing for each time window.\n",
    "    \"\"\"\n",
    "\n",
    "    if os.path.exists(path):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(path)\n",
    "    \n",
    "    # Set networks to evaluation mode\n",
    "    memory.eval()\n",
    "    gnn.eval()\n",
    "    link_pred.eval()\n",
    "    \n",
    "    memory.reset_state()  # Start with a fresh memory.  \n",
    "    neighbor_loader.reset_state()  # Start with an empty graph.\n",
    "    \n",
    "    # Initialize tracking variables\n",
    "    time_with_loss={}\n",
    "    total_loss = 0    \n",
    "    edge_list=[]\n",
    "    \n",
    "    unique_nodes=torch.tensor([]).to(device=device)\n",
    "    total_edges=0\n",
    "\n",
    "\n",
    "    start_time=inference_data.t[0]\n",
    "    event_count=0\n",
    "    \n",
    "    pos_o=[]\n",
    "    loss_list=[]\n",
    "\n",
    "    print(\"after merge:\",inference_data)\n",
    "    \n",
    "    # Record the running time to evaluate the performance\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    for batch in inference_data.seq_batches(batch_size=BATCH):\n",
    "        \n",
    "        src, pos_dst, t, msg = batch.src, batch.dst, batch.t, batch.msg\n",
    "        unique_nodes=torch.cat([unique_nodes,src,pos_dst]).unique()\n",
    "        total_edges+=BATCH\n",
    "        \n",
    "        # Retrieve embeddings and neighbors\n",
    "        n_id = torch.cat([src, pos_dst]).unique()       \n",
    "        n_id, edge_index, e_id = neighbor_loader(n_id)\n",
    "        assoc[n_id] = torch.arange(n_id.size(0), device=device)\n",
    "\n",
    "        # Get memory and update embeddings via GNN\n",
    "        z, last_update = memory(n_id)\n",
    "        z = gnn(z, last_update, edge_index, inference_data.t[e_id], inference_data.msg[e_id])\n",
    "\n",
    "        # Predict edge properties\n",
    "        pos_out = link_pred(z[assoc[src]], z[assoc[pos_dst]])\n",
    "        pos_o.append(pos_out)\n",
    "        y_pred = torch.cat([pos_out], dim=0)\n",
    "\n",
    "        # Generate ground-truth labels\n",
    "        y_true=[]\n",
    "        for m in msg:\n",
    "            # Extract label index from the message\n",
    "            l=tensor_find(m[16:-16],1)-1\n",
    "            y_true.append(l) \n",
    "        y_true = torch.tensor(y_true).to(device=device)\n",
    "        y_true=y_true.reshape(-1).to(torch.long).to(device=device)\n",
    "\n",
    "        # Only consider which edge hasn't been correctly predicted.\n",
    "        # For benign graphs, the behaviors patterns are similar and therefore their losses are small\n",
    "        # For anoamlous behaviors, some behaviors might not be seen before, so the probability of predicting those edges are low. Thus their losses are high.\n",
    "        loss = criterion(y_pred, y_true)\n",
    "        total_loss += float(loss) * batch.num_events\n",
    "        \n",
    "        # update the edges in the batch to the memory and neighbor_loader\n",
    "        memory.update_state(src, pos_dst, t, msg)\n",
    "        neighbor_loader.insert(src, pos_dst)\n",
    "        \n",
    "        # compute the loss for each edge\n",
    "        each_edge_loss= cal_pos_edges_loss_multiclass(pos_out,y_true)\n",
    "        \n",
    "        # Process edges for logging\n",
    "        for i in range(len(pos_out)):\n",
    "            srcnode=int(src[i])\n",
    "            dstnode=int(pos_dst[i])  \n",
    "            \n",
    "            srcmsg=str(nodeid2msg[srcnode]) \n",
    "            dstmsg=str(nodeid2msg[dstnode])\n",
    "            t_var=int(t[i])\n",
    "            edgeindex=tensor_find(msg[i][16:-16],1)   \n",
    "            edge_type=rel2id[edgeindex]\n",
    "            loss=each_edge_loss[i]    \n",
    "\n",
    "            temp_dic={}\n",
    "            temp_dic['loss']=float(loss)\n",
    "            temp_dic['srcnode']=srcnode\n",
    "            temp_dic['dstnode']=dstnode\n",
    "            temp_dic['srcmsg']=srcmsg\n",
    "            temp_dic['dstmsg']=dstmsg\n",
    "            temp_dic['edge_type']=edge_type\n",
    "            temp_dic['time']=t_var\n",
    "            \n",
    "            edge_list.append(temp_dic)\n",
    "        \n",
    "        # Check if the time interval is over (15 minutes - Window Size)\n",
    "        event_count+=len(batch.src)\n",
    "        if t[-1]>start_time+60000000000*15:\n",
    "            # Here is a checkpoint, which records all edge losses in the current time window\n",
    "            time_interval=ns_time_to_datetime_US(start_time)+\"~\"+ns_time_to_datetime_US(t[-1])\n",
    "\n",
    "            end = time.perf_counter()\n",
    "            time_with_loss[time_interval]={'loss':loss,\n",
    "                                          'nodes_count':len(unique_nodes),\n",
    "                                          'total_edges':total_edges,\n",
    "                                          'costed_time':(end-start)}\n",
    "            \n",
    "            \n",
    "            log=open(path+\"/\"+time_interval+\".txt\",'w')\n",
    "            \n",
    "            # Compute average loss for the interval\n",
    "            for e in edge_list:\n",
    "                loss+=e['loss']\n",
    "            loss=loss/event_count   \n",
    "\n",
    "            # Save results to log file\n",
    "            print(f'Time: {time_interval}, Loss: {loss:.4f}, Nodes_count: {len(unique_nodes)}, Cost Time: {(end-start):.2f}s')\n",
    "            edge_list = sorted(edge_list, key=lambda x:x['loss'],reverse=True)  # Rank the results based on edge losses\n",
    "            for e in edge_list: \n",
    "                log.write(str(e))\n",
    "                log.write(\"\\n\") \n",
    "            \n",
    "            # Reset tracking variables for the next interval\n",
    "            event_count=0\n",
    "            total_loss=0\n",
    "            loss=0\n",
    "            start_time=t[-1]\n",
    "            log.close()\n",
    "            edge_list.clear()\n",
    "\n",
    "    return time_with_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_5_11=torch.load(\"./train_graphs/graph_5_11.TemporalData.simple\").to(device=device)\n",
    "graph_5_14=torch.load(\"./train_graphs/graph_5_14.TemporalData.simple\").to(device=device)\n",
    "graph_5_15=torch.load(\"./train_graphs/graph_5_15.TemporalData.simple\").to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load(\"./models/model_saved_share.pt\")\n",
    "memory,gnn, link_pred,neighbor_loader=model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after merge: TemporalData(dst=[9622633], msg=[9622633, 41], src=[9622633], t=[9622633])\n",
      "Time: 2019-05-08 00:00:01.330026026~2019-05-08 00:15:29.528868509, Loss: 0.2662, Nodes_count: 2356, Cost Time: 10.62s\n",
      "Time: 2019-05-08 00:15:29.528868509~2019-05-08 00:34:01.494985889, Loss: 0.1486, Nodes_count: 82297, Cost Time: 40.50s\n",
      "Time: 2019-05-08 00:34:01.494985889~2019-05-08 00:49:53.634712131, Loss: 0.1085, Nodes_count: 96517, Cost Time: 82.49s\n",
      "Time: 2019-05-08 00:49:53.634712131~2019-05-08 01:05:30.922847747, Loss: 0.0524, Nodes_count: 96653, Cost Time: 124.98s\n",
      "Time: 2019-05-08 01:05:30.922847747~2019-05-08 01:20:31.497361112, Loss: 0.2423, Nodes_count: 96737, Cost Time: 134.82s\n",
      "Time: 2019-05-08 01:20:31.497361112~2019-05-08 01:35:41.695160354, Loss: 0.1922, Nodes_count: 96837, Cost Time: 146.28s\n",
      "Time: 2019-05-08 01:35:41.695160354~2019-05-08 01:53:50.594670267, Loss: 0.0796, Nodes_count: 97677, Cost Time: 220.94s\n",
      "Time: 2019-05-08 01:53:50.594670267~2019-05-08 02:09:43.350837131, Loss: 0.2341, Nodes_count: 97794, Cost Time: 233.67s\n",
      "Time: 2019-05-08 02:09:43.350837131~2019-05-08 02:26:01.494039907, Loss: 0.1697, Nodes_count: 98001, Cost Time: 251.82s\n",
      "Time: 2019-05-08 02:26:01.494039907~2019-05-08 02:42:31.494332605, Loss: 0.1426, Nodes_count: 98124, Cost Time: 264.66s\n",
      "Time: 2019-05-08 02:42:31.494332605~2019-05-08 02:58:57.023132578, Loss: 0.1645, Nodes_count: 98414, Cost Time: 279.58s\n",
      "Time: 2019-05-08 02:58:57.023132578~2019-05-08 03:13:57.095448637, Loss: 0.1182, Nodes_count: 98591, Cost Time: 320.70s\n",
      "Time: 2019-05-08 03:13:57.095448637~2019-05-08 03:32:08.466033172, Loss: 0.1644, Nodes_count: 98910, Cost Time: 341.01s\n",
      "Time: 2019-05-08 03:32:08.466033172~2019-05-08 03:48:47.382438643, Loss: 0.1883, Nodes_count: 99001, Cost Time: 354.88s\n",
      "Time: 2019-05-08 03:48:47.382438643~2019-05-08 04:04:46.414529639, Loss: 0.2085, Nodes_count: 99069, Cost Time: 365.88s\n",
      "Time: 2019-05-08 04:04:46.414529639~2019-05-08 04:20:01.518779113, Loss: 0.0849, Nodes_count: 99216, Cost Time: 408.95s\n",
      "Time: 2019-05-08 04:20:01.518779113~2019-05-08 04:35:58.858520828, Loss: 0.1416, Nodes_count: 99285, Cost Time: 419.23s\n",
      "Time: 2019-05-08 04:35:58.858520828~2019-05-08 04:51:14.379786874, Loss: 0.1486, Nodes_count: 99427, Cost Time: 440.22s\n",
      "Time: 2019-05-08 04:51:14.379786874~2019-05-08 05:06:20.739790014, Loss: 0.2155, Nodes_count: 100686, Cost Time: 456.46s\n",
      "Time: 2019-05-08 05:06:20.739790014~2019-05-08 05:21:29.411470192, Loss: 0.0680, Nodes_count: 100989, Cost Time: 499.30s\n",
      "Time: 2019-05-08 05:21:29.411470192~2019-05-08 05:37:31.515609538, Loss: 0.1893, Nodes_count: 101151, Cost Time: 516.20s\n",
      "Time: 2019-05-08 05:37:31.515609538~2019-05-08 05:53:31.497131397, Loss: 0.1724, Nodes_count: 101427, Cost Time: 543.19s\n",
      "Time: 2019-05-08 05:53:31.497131397~2019-05-08 06:10:58.534552244, Loss: 0.0651, Nodes_count: 104732, Cost Time: 583.48s\n",
      "Time: 2019-05-08 06:10:58.534552244~2019-05-08 06:27:01.496508811, Loss: 0.2213, Nodes_count: 104809, Cost Time: 593.54s\n",
      "Time: 2019-05-08 06:27:01.496508811~2019-05-08 06:44:01.510476913, Loss: 0.0556, Nodes_count: 115074, Cost Time: 718.59s\n",
      "Time: 2019-05-08 06:44:01.510476913~2019-05-08 06:59:29.081176105, Loss: 0.0838, Nodes_count: 124443, Cost Time: 785.27s\n",
      "Time: 2019-05-08 06:59:29.081176105~2019-05-08 07:16:21.527799306, Loss: 0.1534, Nodes_count: 124605, Cost Time: 812.23s\n",
      "Time: 2019-05-08 07:16:21.527799306~2019-05-08 07:31:31.498367791, Loss: 0.1517, Nodes_count: 124721, Cost Time: 827.32s\n",
      "Time: 2019-05-08 07:31:31.498367791~2019-05-08 07:47:59.950266127, Loss: 0.1960, Nodes_count: 124931, Cost Time: 839.92s\n",
      "Time: 2019-05-08 07:47:59.950266127~2019-05-08 08:04:24.283283892, Loss: 0.2074, Nodes_count: 126779, Cost Time: 856.86s\n",
      "Time: 2019-05-08 08:04:24.283283892~2019-05-08 08:19:25.079188234, Loss: 0.3586, Nodes_count: 128447, Cost Time: 900.70s\n",
      "Time: 2019-05-08 08:19:25.079188234~2019-05-08 08:35:56.405929191, Loss: 3.7717, Nodes_count: 129797, Cost Time: 1007.61s\n",
      "Time: 2019-05-08 08:35:56.405929191~2019-05-08 08:51:31.494691070, Loss: 0.1195, Nodes_count: 130330, Cost Time: 1076.17s\n",
      "Time: 2019-05-08 08:51:31.494691070~2019-05-08 09:07:45.182895158, Loss: 0.2141, Nodes_count: 143431, Cost Time: 1166.10s\n",
      "Time: 2019-05-08 09:07:45.182895158~2019-05-08 09:23:31.510817939, Loss: 3.9662, Nodes_count: 144348, Cost Time: 1242.81s\n",
      "Time: 2019-05-08 09:23:31.510817939~2019-05-08 09:38:32.042400342, Loss: 3.5510, Nodes_count: 144920, Cost Time: 1309.76s\n",
      "Time: 2019-05-08 09:38:32.042400342~2019-05-08 09:53:59.985955797, Loss: 2.4288, Nodes_count: 145296, Cost Time: 1369.09s\n",
      "Time: 2019-05-08 09:53:59.985955797~2019-05-08 10:09:28.157340956, Loss: 0.2345, Nodes_count: 145645, Cost Time: 1409.21s\n",
      "Time: 2019-05-08 10:09:28.157340956~2019-05-08 10:24:33.040435131, Loss: 0.1749, Nodes_count: 146004, Cost Time: 1464.99s\n",
      "Time: 2019-05-08 10:24:33.040435131~2019-05-08 10:39:56.645975541, Loss: 0.1880, Nodes_count: 146530, Cost Time: 1554.49s\n",
      "Time: 2019-05-08 10:39:56.645975541~2019-05-08 10:54:57.371031778, Loss: 0.1619, Nodes_count: 147237, Cost Time: 1657.19s\n",
      "Time: 2019-05-08 10:54:57.371031778~2019-05-08 11:11:40.968208138, Loss: 0.1271, Nodes_count: 147497, Cost Time: 1900.94s\n",
      "Time: 2019-05-08 11:11:40.968208138~2019-05-08 11:26:47.315251658, Loss: 0.1561, Nodes_count: 147672, Cost Time: 1925.28s\n",
      "Time: 2019-05-08 11:26:47.315251658~2019-05-08 11:44:32.386385923, Loss: 0.2211, Nodes_count: 147949, Cost Time: 1962.32s\n",
      "Time: 2019-05-08 11:44:32.386385923~2019-05-08 11:59:56.165297922, Loss: 0.1406, Nodes_count: 148425, Cost Time: 2017.17s\n",
      "Time: 2019-05-08 11:59:56.165297922~2019-05-08 12:15:54.940816182, Loss: 0.3896, Nodes_count: 148682, Cost Time: 2038.74s\n",
      "Time: 2019-05-08 12:15:54.940816182~2019-05-08 12:31:15.278340529, Loss: 0.1698, Nodes_count: 148905, Cost Time: 2073.73s\n",
      "Time: 2019-05-08 12:31:15.278340529~2019-05-08 12:46:31.494879192, Loss: 0.2771, Nodes_count: 149119, Cost Time: 2098.61s\n",
      "Time: 2019-05-08 12:46:31.494879192~2019-05-08 13:02:51.596182752, Loss: 0.1450, Nodes_count: 149458, Cost Time: 2200.03s\n",
      "Time: 2019-05-08 13:02:51.596182752~2019-05-08 13:18:09.403271887, Loss: 0.1364, Nodes_count: 149781, Cost Time: 2346.14s\n",
      "Time: 2019-05-08 13:18:09.403271887~2019-05-08 13:33:49.475905288, Loss: 0.9960, Nodes_count: 150210, Cost Time: 2504.30s\n",
      "Time: 2019-05-08 13:33:49.475905288~2019-05-08 13:49:07.975590004, Loss: 0.5654, Nodes_count: 150519, Cost Time: 2531.99s\n",
      "Time: 2019-05-08 13:49:07.975590004~2019-05-08 14:04:08.362986281, Loss: 0.1703, Nodes_count: 150920, Cost Time: 2621.51s\n",
      "Time: 2019-05-08 14:04:08.362986281~2019-05-08 14:20:38.626291924, Loss: 0.2480, Nodes_count: 151096, Cost Time: 2644.87s\n",
      "Time: 2019-05-08 14:20:38.626291924~2019-05-08 14:38:16.822010916, Loss: 0.2020, Nodes_count: 151436, Cost Time: 2686.94s\n",
      "Time: 2019-05-08 14:38:16.822010916~2019-05-08 14:53:23.122855676, Loss: 1.2434, Nodes_count: 151782, Cost Time: 2731.53s\n",
      "Time: 2019-05-08 14:53:23.122855676~2019-05-08 15:08:42.441638215, Loss: 0.2451, Nodes_count: 152098, Cost Time: 2853.55s\n",
      "Time: 2019-05-08 15:08:42.441638215~2019-05-08 15:24:01.898655291, Loss: 0.2810, Nodes_count: 152278, Cost Time: 2882.32s\n",
      "Time: 2019-05-08 15:24:01.898655291~2019-05-08 15:39:06.558035649, Loss: 0.2560, Nodes_count: 152525, Cost Time: 2913.92s\n",
      "Time: 2019-05-08 15:39:06.558035649~2019-05-08 15:54:07.906775809, Loss: 0.2375, Nodes_count: 153033, Cost Time: 2950.86s\n",
      "Time: 2019-05-08 15:54:07.906775809~2019-05-08 16:09:11.911547021, Loss: 0.1166, Nodes_count: 153293, Cost Time: 3022.25s\n",
      "Time: 2019-05-08 16:09:11.911547021~2019-05-08 16:24:14.553496865, Loss: 0.2973, Nodes_count: 153511, Cost Time: 3059.91s\n",
      "Time: 2019-05-08 16:24:14.553496865~2019-05-08 16:41:01.513629313, Loss: 0.1817, Nodes_count: 153647, Cost Time: 3166.33s\n",
      "Time: 2019-05-08 16:41:01.513629313~2019-05-08 16:59:31.493980102, Loss: 0.1220, Nodes_count: 153658, Cost Time: 3168.34s\n",
      "Time: 2019-05-08 16:59:31.493980102~2019-05-08 17:18:31.513488653, Loss: 0.1420, Nodes_count: 153667, Cost Time: 3169.23s\n",
      "Time: 2019-05-08 17:18:31.513488653~2019-05-08 17:34:01.511886204, Loss: 0.1206, Nodes_count: 153667, Cost Time: 3169.86s\n",
      "Time: 2019-05-08 17:34:01.511886204~2019-05-08 17:53:01.523458251, Loss: 0.1655, Nodes_count: 153675, Cost Time: 3170.70s\n",
      "Time: 2019-05-08 17:53:01.523458251~2019-05-08 18:10:31.516914310, Loss: 0.1115, Nodes_count: 153681, Cost Time: 3171.54s\n",
      "Time: 2019-05-08 18:10:31.516914310~2019-05-08 18:28:01.502529875, Loss: 0.1422, Nodes_count: 153690, Cost Time: 3172.47s\n",
      "Time: 2019-05-08 18:28:01.502529875~2019-05-08 18:46:31.493999871, Loss: 0.0884, Nodes_count: 153693, Cost Time: 3173.32s\n",
      "Time: 2019-05-08 18:46:31.493999871~2019-05-08 19:04:31.510623654, Loss: 0.1592, Nodes_count: 153701, Cost Time: 3174.16s\n",
      "Time: 2019-05-08 19:04:31.510623654~2019-05-08 19:23:01.507250100, Loss: 0.1323, Nodes_count: 153710, Cost Time: 3175.02s\n",
      "Time: 2019-05-08 19:23:01.507250100~2019-05-08 19:39:31.523720172, Loss: 0.0813, Nodes_count: 153710, Cost Time: 3175.66s\n",
      "Time: 2019-05-08 19:39:31.523720172~2019-05-08 19:55:31.512169904, Loss: 0.1355, Nodes_count: 153720, Cost Time: 3176.32s\n",
      "Time: 2019-05-08 19:55:31.512169904~2019-05-08 20:14:01.524943347, Loss: 0.1813, Nodes_count: 153728, Cost Time: 3177.19s\n",
      "Time: 2019-05-08 20:14:01.524943347~2019-05-08 20:33:31.498044174, Loss: 0.2058, Nodes_count: 153736, Cost Time: 3178.06s\n",
      "Time: 2019-05-08 20:33:31.498044174~2019-05-08 20:48:31.524002588, Loss: 0.1776, Nodes_count: 153739, Cost Time: 3178.70s\n",
      "Time: 2019-05-08 20:48:31.524002588~2019-05-08 21:04:31.490231913, Loss: 0.1497, Nodes_count: 153747, Cost Time: 3179.33s\n",
      "Time: 2019-05-08 21:04:31.490231913~2019-05-08 21:24:01.495025698, Loss: 0.2245, Nodes_count: 153756, Cost Time: 3180.19s\n",
      "Time: 2019-05-08 21:24:01.495025698~2019-05-08 21:39:31.522563147, Loss: 0.1063, Nodes_count: 153756, Cost Time: 3180.82s\n",
      "Time: 2019-05-08 21:39:31.522563147~2019-05-08 21:58:01.519005788, Loss: 0.1569, Nodes_count: 153767, Cost Time: 3181.70s\n",
      "Time: 2019-05-08 21:58:01.519005788~2019-05-08 22:14:31.523095977, Loss: 0.1671, Nodes_count: 153774, Cost Time: 3182.55s\n",
      "Time: 2019-05-08 22:14:31.523095977~2019-05-08 22:32:42.535693417, Loss: 0.1070, Nodes_count: 153775, Cost Time: 3183.43s\n",
      "Time: 2019-05-08 22:32:42.535693417~2019-05-08 22:51:31.495982089, Loss: 0.2111, Nodes_count: 153785, Cost Time: 3184.26s\n",
      "Time: 2019-05-08 22:51:31.495982089~2019-05-08 23:11:31.517681557, Loss: 0.1956, Nodes_count: 153792, Cost Time: 3185.08s\n",
      "Time: 2019-05-08 23:11:31.517681557~2019-05-08 23:29:31.506809805, Loss: 0.1393, Nodes_count: 153800, Cost Time: 3185.94s\n",
      "Time: 2019-05-08 23:29:31.506809805~2019-05-08 23:49:01.517454902, Loss: 0.0958, Nodes_count: 153803, Cost Time: 3186.80s\n"
     ]
    }
   ],
   "source": [
    "# Test the data for 2019-05-08, create and store time window with loss\n",
    "ans_5_8=test_day_new(graph_5_8,\"graph_5_8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after merge: TemporalData(dst=[6898178], msg=[6898178, 41], src=[6898178], t=[6898178])\n",
      "Time: 2019-05-09 00:00:00.207323955~2019-05-09 00:15:01.493243668, Loss: 0.3950, Nodes_count: 73, Cost Time: 0.27s\n",
      "Time: 2019-05-09 00:15:01.493243668~2019-05-09 00:32:01.509088277, Loss: 0.1783, Nodes_count: 124, Cost Time: 0.70s\n",
      "Time: 2019-05-09 00:32:01.509088277~2019-05-09 00:50:31.512334564, Loss: 0.2014, Nodes_count: 138, Cost Time: 1.17s\n",
      "Time: 2019-05-09 00:50:31.512334564~2019-05-09 01:09:31.519558739, Loss: 0.2061, Nodes_count: 152, Cost Time: 1.63s\n",
      "Time: 2019-05-09 01:09:31.519558739~2019-05-09 01:28:01.511221355, Loss: 0.1224, Nodes_count: 185, Cost Time: 2.09s\n",
      "Time: 2019-05-09 01:28:01.511221355~2019-05-09 01:43:31.496122592, Loss: 0.1725, Nodes_count: 193, Cost Time: 2.46s\n",
      "Time: 2019-05-09 01:43:31.496122592~2019-05-09 02:02:31.501625321, Loss: 0.1325, Nodes_count: 204, Cost Time: 2.93s\n",
      "Time: 2019-05-09 02:02:31.501625321~2019-05-09 02:21:01.508194986, Loss: 0.1382, Nodes_count: 210, Cost Time: 3.43s\n",
      "Time: 2019-05-09 02:21:01.508194986~2019-05-09 02:41:01.496942401, Loss: 0.1557, Nodes_count: 213, Cost Time: 3.88s\n",
      "Time: 2019-05-09 02:41:01.496942401~2019-05-09 02:58:31.546557126, Loss: 0.2896, Nodes_count: 224, Cost Time: 4.36s\n",
      "Time: 2019-05-09 02:58:31.546557126~2019-05-09 03:14:31.541454570, Loss: 0.4312, Nodes_count: 232, Cost Time: 4.73s\n",
      "Time: 2019-05-09 03:14:31.541454570~2019-05-09 03:33:31.522432333, Loss: 0.2869, Nodes_count: 233, Cost Time: 5.19s\n",
      "Time: 2019-05-09 03:33:31.522432333~2019-05-09 03:49:31.487819035, Loss: 0.1366, Nodes_count: 244, Cost Time: 5.55s\n",
      "Time: 2019-05-09 03:49:31.487819035~2019-05-09 04:08:31.512408415, Loss: 0.1179, Nodes_count: 252, Cost Time: 6.00s\n",
      "Time: 2019-05-09 04:08:31.512408415~2019-05-09 04:26:01.506692561, Loss: 0.1482, Nodes_count: 262, Cost Time: 6.49s\n",
      "Time: 2019-05-09 04:26:01.506692561~2019-05-09 04:44:01.496220655, Loss: 0.1673, Nodes_count: 264, Cost Time: 6.96s\n",
      "Time: 2019-05-09 04:44:01.496220655~2019-05-09 05:03:01.500856474, Loss: 0.2106, Nodes_count: 275, Cost Time: 7.43s\n",
      "Time: 2019-05-09 05:03:01.500856474~2019-05-09 05:20:01.521604357, Loss: 0.2259, Nodes_count: 283, Cost Time: 7.93s\n",
      "Time: 2019-05-09 05:20:01.521604357~2019-05-09 05:39:31.512589142, Loss: 0.1939, Nodes_count: 283, Cost Time: 8.38s\n",
      "Time: 2019-05-09 05:39:31.512589142~2019-05-09 05:58:01.497381298, Loss: 0.1593, Nodes_count: 294, Cost Time: 8.88s\n",
      "Time: 2019-05-09 05:58:01.497381298~2019-05-09 06:16:31.498553054, Loss: 0.2492, Nodes_count: 302, Cost Time: 9.34s\n",
      "Time: 2019-05-09 06:16:31.498553054~2019-05-09 06:34:01.518723426, Loss: 0.2312, Nodes_count: 312, Cost Time: 9.87s\n",
      "Time: 2019-05-09 06:34:01.518723426~2019-05-09 06:50:01.488237695, Loss: 0.1978, Nodes_count: 315, Cost Time: 10.21s\n",
      "Time: 2019-05-09 06:50:01.488237695~2019-05-09 07:08:31.498981836, Loss: 0.2370, Nodes_count: 323, Cost Time: 10.68s\n",
      "Time: 2019-05-09 07:08:31.498981836~2019-05-09 07:27:31.511153471, Loss: 0.1191, Nodes_count: 332, Cost Time: 11.18s\n",
      "Time: 2019-05-09 07:27:31.511153471~2019-05-09 07:42:31.716512490, Loss: 0.1215, Nodes_count: 456, Cost Time: 11.91s\n",
      "Time: 2019-05-09 07:42:31.716512490~2019-05-09 07:58:01.494245825, Loss: 0.1173, Nodes_count: 483, Cost Time: 12.60s\n",
      "Time: 2019-05-09 07:58:01.494245825~2019-05-09 08:14:13.608285038, Loss: 0.2201, Nodes_count: 2280, Cost Time: 29.78s\n",
      "Time: 2019-05-09 08:14:13.608285038~2019-05-09 08:29:22.417122531, Loss: 0.2378, Nodes_count: 44265, Cost Time: 44.99s\n",
      "Time: 2019-05-09 08:29:22.417122531~2019-05-09 08:44:31.520902442, Loss: 0.3301, Nodes_count: 44720, Cost Time: 54.81s\n",
      "Time: 2019-05-09 08:44:31.520902442~2019-05-09 09:02:07.321314205, Loss: 0.2848, Nodes_count: 45306, Cost Time: 70.93s\n",
      "Time: 2019-05-09 09:02:07.321314205~2019-05-09 09:18:51.969852163, Loss: 0.3713, Nodes_count: 117689, Cost Time: 114.34s\n",
      "Time: 2019-05-09 09:18:51.969852163~2019-05-09 09:35:33.594129613, Loss: 0.8405, Nodes_count: 134368, Cost Time: 179.97s\n",
      "Time: 2019-05-09 09:35:33.594129613~2019-05-09 09:52:04.489245008, Loss: 0.1758, Nodes_count: 134701, Cost Time: 227.89s\n",
      "Time: 2019-05-09 09:52:04.489245008~2019-05-09 10:10:50.477780495, Loss: 0.1570, Nodes_count: 140070, Cost Time: 312.98s\n",
      "Time: 2019-05-09 10:10:50.477780495~2019-05-09 10:26:31.516032725, Loss: 0.2842, Nodes_count: 140268, Cost Time: 335.34s\n",
      "Time: 2019-05-09 10:26:31.516032725~2019-05-09 10:41:47.720010114, Loss: 0.1510, Nodes_count: 140498, Cost Time: 363.25s\n",
      "Time: 2019-05-09 10:41:47.720010114~2019-05-09 10:57:07.794058850, Loss: 0.1494, Nodes_count: 142057, Cost Time: 405.33s\n",
      "Time: 2019-05-09 10:57:07.794058850~2019-05-09 11:13:01.501042121, Loss: 0.1247, Nodes_count: 142284, Cost Time: 435.79s\n",
      "Time: 2019-05-09 11:13:01.501042121~2019-05-09 11:29:31.497349974, Loss: 0.1045, Nodes_count: 142410, Cost Time: 454.28s\n",
      "Time: 2019-05-09 11:29:31.497349974~2019-05-09 11:44:56.921108170, Loss: 0.2716, Nodes_count: 142483, Cost Time: 464.78s\n",
      "Time: 2019-05-09 11:44:56.921108170~2019-05-09 12:01:01.498472073, Loss: 0.0837, Nodes_count: 142722, Cost Time: 492.31s\n",
      "Time: 2019-05-09 12:01:01.498472073~2019-05-09 12:16:05.165292532, Loss: 0.1041, Nodes_count: 142793, Cost Time: 526.82s\n",
      "Time: 2019-05-09 12:16:05.165292532~2019-05-09 12:33:01.508907545, Loss: 0.2328, Nodes_count: 142847, Cost Time: 534.50s\n",
      "Time: 2019-05-09 12:33:01.508907545~2019-05-09 12:48:26.310257706, Loss: 0.1853, Nodes_count: 143090, Cost Time: 563.48s\n",
      "Time: 2019-05-09 12:48:26.310257706~2019-05-09 13:05:29.047611314, Loss: 0.2809, Nodes_count: 143137, Cost Time: 575.02s\n",
      "Time: 2019-05-09 13:05:29.047611314~2019-05-09 13:23:01.522698356, Loss: 0.1287, Nodes_count: 143349, Cost Time: 602.56s\n",
      "Time: 2019-05-09 13:23:01.522698356~2019-05-09 13:38:10.752604347, Loss: 0.1403, Nodes_count: 143514, Cost Time: 636.05s\n",
      "Time: 2019-05-09 13:38:10.752604347~2019-05-09 13:54:01.545877241, Loss: 0.2007, Nodes_count: 143678, Cost Time: 647.20s\n",
      "Time: 2019-05-09 13:54:01.545877241~2019-05-09 14:11:23.357414494, Loss: 0.1436, Nodes_count: 143904, Cost Time: 684.09s\n",
      "Time: 2019-05-09 14:11:23.357414494~2019-05-09 14:26:37.796285168, Loss: 0.2639, Nodes_count: 143982, Cost Time: 696.42s\n",
      "Time: 2019-05-09 14:26:37.796285168~2019-05-09 14:42:21.923485594, Loss: 0.1416, Nodes_count: 144129, Cost Time: 714.95s\n",
      "Time: 2019-05-09 14:42:21.923485594~2019-05-09 15:02:01.503382988, Loss: 0.1105, Nodes_count: 144321, Cost Time: 743.83s\n",
      "Time: 2019-05-09 15:02:01.503382988~2019-05-09 15:21:01.709415274, Loss: 0.0946, Nodes_count: 146506, Cost Time: 787.03s\n",
      "Time: 2019-05-09 15:21:01.709415274~2019-05-09 15:37:01.522052920, Loss: 0.1509, Nodes_count: 146612, Cost Time: 812.34s\n",
      "Time: 2019-05-09 15:37:01.522052920~2019-05-09 15:53:01.516479316, Loss: 0.1063, Nodes_count: 146700, Cost Time: 841.10s\n",
      "Time: 2019-05-09 15:53:01.516479316~2019-05-09 16:08:25.314884693, Loss: 0.1696, Nodes_count: 146776, Cost Time: 854.77s\n",
      "Time: 2019-05-09 16:08:25.314884693~2019-05-09 16:23:31.523358360, Loss: 0.2280, Nodes_count: 146897, Cost Time: 869.59s\n",
      "Time: 2019-05-09 16:23:31.523358360~2019-05-09 16:42:27.541450150, Loss: 0.2019, Nodes_count: 147069, Cost Time: 890.64s\n",
      "Time: 2019-05-09 16:42:27.541450150~2019-05-09 16:58:10.720672915, Loss: 0.1616, Nodes_count: 150651, Cost Time: 922.26s\n",
      "Time: 2019-05-09 16:58:10.720672915~2019-05-09 17:13:25.458500818, Loss: 0.2066, Nodes_count: 150897, Cost Time: 950.88s\n",
      "Time: 2019-05-09 17:13:25.458500818~2019-05-09 17:28:26.799470003, Loss: 0.2080, Nodes_count: 150975, Cost Time: 966.37s\n",
      "Time: 2019-05-09 17:28:26.799470003~2019-05-09 17:46:31.517885767, Loss: 0.0983, Nodes_count: 151091, Cost Time: 991.04s\n",
      "Time: 2019-05-09 17:46:31.517885767~2019-05-09 18:04:31.517197232, Loss: 0.0885, Nodes_count: 151123, Cost Time: 994.45s\n",
      "Time: 2019-05-09 18:04:31.517197232~2019-05-09 18:20:01.489626299, Loss: 0.1494, Nodes_count: 151305, Cost Time: 1032.66s\n",
      "Time: 2019-05-09 18:20:01.489626299~2019-05-09 18:36:31.516859871, Loss: 0.1823, Nodes_count: 151349, Cost Time: 1043.30s\n",
      "Time: 2019-05-09 18:36:31.516859871~2019-05-09 18:51:31.522296215, Loss: 0.1055, Nodes_count: 151586, Cost Time: 1098.97s\n",
      "Time: 2019-05-09 18:51:31.522296215~2019-05-09 19:08:38.541227489, Loss: 0.1482, Nodes_count: 151821, Cost Time: 1132.89s\n",
      "Time: 2019-05-09 19:08:38.541227489~2019-05-09 19:24:45.344333837, Loss: 0.1545, Nodes_count: 152224, Cost Time: 1172.22s\n",
      "Time: 2019-05-09 19:24:45.344333837~2019-05-09 19:41:59.034293716, Loss: 0.2250, Nodes_count: 152323, Cost Time: 1185.98s\n",
      "Time: 2019-05-09 19:41:59.034293716~2019-05-09 19:56:59.054260720, Loss: 0.0527, Nodes_count: 159406, Cost Time: 1283.81s\n",
      "Time: 2019-05-09 19:56:59.054260720~2019-05-09 20:12:01.515706054, Loss: 0.0893, Nodes_count: 160289, Cost Time: 1347.84s\n",
      "Time: 2019-05-09 20:12:01.515706054~2019-05-09 20:27:05.021522389, Loss: 0.1581, Nodes_count: 160464, Cost Time: 1372.02s\n",
      "Time: 2019-05-09 20:27:05.021522389~2019-05-09 20:45:31.496488143, Loss: 0.1650, Nodes_count: 160655, Cost Time: 1397.67s\n",
      "Time: 2019-05-09 20:45:31.496488143~2019-05-09 21:01:01.504046556, Loss: 0.1801, Nodes_count: 160829, Cost Time: 1420.46s\n",
      "Time: 2019-05-09 21:01:01.504046556~2019-05-09 21:16:42.061927432, Loss: 0.0721, Nodes_count: 162965, Cost Time: 1493.04s\n",
      "Time: 2019-05-09 21:16:42.061927432~2019-05-09 21:32:36.728807875, Loss: 0.1265, Nodes_count: 163095, Cost Time: 1520.86s\n",
      "Time: 2019-05-09 21:32:36.728807875~2019-05-09 21:49:34.447004737, Loss: 0.0952, Nodes_count: 164521, Cost Time: 1573.48s\n",
      "Time: 2019-05-09 21:49:34.447004737~2019-05-09 22:07:01.506607705, Loss: 0.1580, Nodes_count: 164655, Cost Time: 1589.12s\n",
      "Time: 2019-05-09 22:07:01.506607705~2019-05-09 22:23:01.535512940, Loss: 0.2099, Nodes_count: 164758, Cost Time: 1601.45s\n",
      "Time: 2019-05-09 22:23:01.535512940~2019-05-09 22:39:01.541001793, Loss: 0.1440, Nodes_count: 164937, Cost Time: 1633.80s\n",
      "Time: 2019-05-09 22:39:01.541001793~2019-05-09 22:57:14.841448199, Loss: 0.0833, Nodes_count: 166447, Cost Time: 1673.47s\n",
      "Time: 2019-05-09 22:57:14.841448199~2019-05-09 23:12:31.543635344, Loss: 0.1205, Nodes_count: 166607, Cost Time: 1720.01s\n",
      "Time: 2019-05-09 23:12:31.543635344~2019-05-09 23:27:51.753944130, Loss: 0.1065, Nodes_count: 167730, Cost Time: 1783.58s\n",
      "Time: 2019-05-09 23:27:51.753944130~2019-05-09 23:45:37.981699694, Loss: 0.1446, Nodes_count: 167948, Cost Time: 1817.75s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ans_5_9=test_day_new(graph_5_9,\"graph_5_9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after merge: TemporalData(dst=[6488182], msg=[6488182, 41], src=[6488182], t=[6488182])\n",
      "Time: 2019-05-11 00:00:00.500131269~2019-05-11 00:15:10.585413361, Loss: 0.4813, Nodes_count: 1858, Cost Time: 7.68s\n",
      "Time: 2019-05-11 00:15:10.585413361~2019-05-11 00:31:01.430200716, Loss: 0.4722, Nodes_count: 2315, Cost Time: 19.29s\n",
      "Time: 2019-05-11 00:31:01.430200716~2019-05-11 00:46:29.482831031, Loss: 0.3280, Nodes_count: 47459, Cost Time: 44.37s\n",
      "Time: 2019-05-11 00:46:29.482831031~2019-05-11 01:01:37.064383098, Loss: 0.4018, Nodes_count: 47932, Cost Time: 58.17s\n",
      "Time: 2019-05-11 01:01:37.064383098~2019-05-11 01:16:39.942709627, Loss: 0.3520, Nodes_count: 53616, Cost Time: 77.04s\n",
      "Time: 2019-05-11 01:16:39.942709627~2019-05-11 01:32:01.462298208, Loss: 0.3217, Nodes_count: 54094, Cost Time: 103.11s\n",
      "Time: 2019-05-11 01:32:01.462298208~2019-05-11 01:47:38.109830109, Loss: 0.2666, Nodes_count: 59005, Cost Time: 126.45s\n",
      "Time: 2019-05-11 01:47:38.109830109~2019-05-11 02:03:11.829718951, Loss: 0.6230, Nodes_count: 59411, Cost Time: 148.11s\n",
      "Time: 2019-05-11 02:03:11.829718951~2019-05-11 02:18:49.612834801, Loss: 0.2686, Nodes_count: 62282, Cost Time: 170.94s\n",
      "Time: 2019-05-11 02:18:49.612834801~2019-05-11 02:34:35.963377275, Loss: 0.4400, Nodes_count: 62635, Cost Time: 184.88s\n",
      "Time: 2019-05-11 02:34:35.963377275~2019-05-11 02:51:01.459395653, Loss: 0.3559, Nodes_count: 63120, Cost Time: 207.88s\n",
      "Time: 2019-05-11 02:51:01.459395653~2019-05-11 03:06:06.971449468, Loss: 0.5144, Nodes_count: 63371, Cost Time: 217.37s\n",
      "Time: 2019-05-11 03:06:06.971449468~2019-05-11 03:22:04.391793517, Loss: 0.4020, Nodes_count: 63736, Cost Time: 231.92s\n",
      "Time: 2019-05-11 03:22:04.391793517~2019-05-11 03:37:32.924133941, Loss: 0.4402, Nodes_count: 64066, Cost Time: 245.84s\n",
      "Time: 2019-05-11 03:37:32.924133941~2019-05-11 03:52:38.714923518, Loss: 0.3539, Nodes_count: 64476, Cost Time: 270.23s\n",
      "Time: 2019-05-11 03:52:38.714923518~2019-05-11 04:09:01.471666913, Loss: 0.4054, Nodes_count: 65749, Cost Time: 290.02s\n",
      "Time: 2019-05-11 04:09:01.471666913~2019-05-11 04:25:28.350226445, Loss: 0.5455, Nodes_count: 66037, Cost Time: 299.41s\n",
      "Time: 2019-05-11 04:25:28.350226445~2019-05-11 04:41:31.612705711, Loss: 0.4224, Nodes_count: 66392, Cost Time: 314.68s\n",
      "Time: 2019-05-11 04:41:31.612705711~2019-05-11 04:56:49.395636083, Loss: 0.6004, Nodes_count: 66654, Cost Time: 325.29s\n",
      "Time: 2019-05-11 04:56:49.395636083~2019-05-11 05:13:04.898139559, Loss: 0.2562, Nodes_count: 78779, Cost Time: 356.51s\n",
      "Time: 2019-05-11 05:13:04.898139559~2019-05-11 05:29:01.492754751, Loss: 0.4078, Nodes_count: 79245, Cost Time: 377.86s\n",
      "Time: 2019-05-11 05:29:01.492754751~2019-05-11 05:45:26.427321308, Loss: 0.2374, Nodes_count: 82652, Cost Time: 412.40s\n",
      "Time: 2019-05-11 05:45:26.427321308~2019-05-11 06:00:32.541397033, Loss: 0.3053, Nodes_count: 83778, Cost Time: 450.18s\n",
      "Time: 2019-05-11 06:00:32.541397033~2019-05-11 06:16:02.917974906, Loss: 0.1775, Nodes_count: 85543, Cost Time: 514.74s\n",
      "Time: 2019-05-11 06:16:02.917974906~2019-05-11 06:32:01.493579408, Loss: 0.5119, Nodes_count: 85798, Cost Time: 527.20s\n",
      "Time: 2019-05-11 06:32:01.493579408~2019-05-11 06:48:01.495937539, Loss: 0.3907, Nodes_count: 86142, Cost Time: 546.38s\n",
      "Time: 2019-05-11 06:48:01.495937539~2019-05-11 07:03:06.190296071, Loss: 0.6888, Nodes_count: 86334, Cost Time: 552.53s\n",
      "Time: 2019-05-11 07:03:06.190296071~2019-05-11 07:18:09.159477610, Loss: 0.2137, Nodes_count: 89545, Cost Time: 603.50s\n",
      "Time: 2019-05-11 07:18:09.159477610~2019-05-11 07:35:01.101406729, Loss: 0.2319, Nodes_count: 91022, Cost Time: 644.80s\n",
      "Time: 2019-05-11 07:35:01.101406729~2019-05-11 07:50:01.504859344, Loss: 0.3902, Nodes_count: 91530, Cost Time: 666.59s\n",
      "Time: 2019-05-11 07:50:01.504859344~2019-05-11 08:05:27.045713282, Loss: 0.3873, Nodes_count: 97044, Cost Time: 711.94s\n",
      "Time: 2019-05-11 08:05:27.045713282~2019-05-11 08:21:31.505389845, Loss: 0.5320, Nodes_count: 97357, Cost Time: 724.03s\n",
      "Time: 2019-05-11 08:21:31.505389845~2019-05-11 08:37:10.242927755, Loss: 0.3081, Nodes_count: 97689, Cost Time: 747.98s\n",
      "Time: 2019-05-11 08:37:10.242927755~2019-05-11 08:52:11.577068452, Loss: 0.2902, Nodes_count: 98080, Cost Time: 776.50s\n",
      "Time: 2019-05-11 08:52:11.577068452~2019-05-11 09:07:31.497392437, Loss: 0.1946, Nodes_count: 103404, Cost Time: 833.94s\n",
      "Time: 2019-05-11 09:07:31.497392437~2019-05-11 09:23:43.378546037, Loss: 0.2122, Nodes_count: 105647, Cost Time: 892.77s\n",
      "Time: 2019-05-11 09:23:43.378546037~2019-05-11 09:39:28.743031655, Loss: 0.1993, Nodes_count: 107075, Cost Time: 949.37s\n",
      "Time: 2019-05-11 09:39:28.743031655~2019-05-11 09:55:12.543113845, Loss: 0.8060, Nodes_count: 107275, Cost Time: 955.87s\n",
      "Time: 2019-05-11 09:55:12.543113845~2019-05-11 10:10:40.816335674, Loss: 0.3918, Nodes_count: 107587, Cost Time: 974.60s\n",
      "Time: 2019-05-11 10:10:40.816335674~2019-05-11 10:26:38.131479341, Loss: 0.5640, Nodes_count: 107941, Cost Time: 993.74s\n",
      "Time: 2019-05-11 10:26:38.131479341~2019-05-11 10:43:01.494767519, Loss: 0.2023, Nodes_count: 111651, Cost Time: 1061.08s\n",
      "Time: 2019-05-11 10:43:01.494767519~2019-05-11 10:58:29.047869392, Loss: 0.2044, Nodes_count: 113302, Cost Time: 1116.05s\n",
      "Time: 2019-05-11 10:58:29.047869392~2019-05-11 11:14:01.491540813, Loss: 0.1962, Nodes_count: 115513, Cost Time: 1175.39s\n",
      "Time: 2019-05-11 11:14:01.491540813~2019-05-11 11:29:31.376280190, Loss: 0.3276, Nodes_count: 115860, Cost Time: 1199.74s\n",
      "Time: 2019-05-11 11:29:31.376280190~2019-05-11 11:45:00.345862636, Loss: 0.4829, Nodes_count: 116119, Cost Time: 1211.34s\n",
      "Time: 2019-05-11 11:45:00.345862636~2019-05-11 12:01:12.133236819, Loss: 0.3546, Nodes_count: 116484, Cost Time: 1235.67s\n",
      "Time: 2019-05-11 12:01:12.133236819~2019-05-11 12:16:36.422369171, Loss: 0.3645, Nodes_count: 116750, Cost Time: 1255.53s\n",
      "Time: 2019-05-11 12:16:36.422369171~2019-05-11 12:32:11.330592128, Loss: 0.1774, Nodes_count: 123718, Cost Time: 1330.26s\n",
      "Time: 2019-05-11 12:32:11.330592128~2019-05-11 12:47:47.220351426, Loss: 0.3395, Nodes_count: 124018, Cost Time: 1355.67s\n",
      "Time: 2019-05-11 12:47:47.220351426~2019-05-11 13:03:23.643575678, Loss: 0.3681, Nodes_count: 124294, Cost Time: 1374.58s\n",
      "Time: 2019-05-11 13:03:23.643575678~2019-05-11 13:18:29.629091674, Loss: 0.3513, Nodes_count: 124615, Cost Time: 1397.35s\n",
      "Time: 2019-05-11 13:18:29.629091674~2019-05-11 13:33:41.349874830, Loss: 0.3734, Nodes_count: 125014, Cost Time: 1419.21s\n",
      "Time: 2019-05-11 13:33:41.349874830~2019-05-11 13:48:47.890783419, Loss: 0.4148, Nodes_count: 125251, Cost Time: 1433.93s\n",
      "Time: 2019-05-11 13:48:47.890783419~2019-05-11 14:04:31.519639837, Loss: 0.7324, Nodes_count: 125396, Cost Time: 1439.28s\n",
      "Time: 2019-05-11 14:04:31.519639837~2019-05-11 14:19:36.223542340, Loss: 0.3742, Nodes_count: 125628, Cost Time: 1454.92s\n",
      "Time: 2019-05-11 14:19:36.223542340~2019-05-11 14:34:58.512935630, Loss: 0.8970, Nodes_count: 125785, Cost Time: 1459.90s\n",
      "Time: 2019-05-11 14:34:58.512935630~2019-05-11 14:50:01.493772506, Loss: 0.5098, Nodes_count: 125951, Cost Time: 1469.27s\n",
      "Time: 2019-05-11 14:50:01.493772506~2019-05-11 15:05:01.505056736, Loss: 0.4437, Nodes_count: 126126, Cost Time: 1480.54s\n",
      "Time: 2019-05-11 15:05:01.505056736~2019-05-11 15:20:31.495771178, Loss: 0.8954, Nodes_count: 126293, Cost Time: 1485.37s\n",
      "Time: 2019-05-11 15:20:31.495771178~2019-05-11 15:37:25.002879746, Loss: 0.4684, Nodes_count: 126511, Cost Time: 1496.09s\n",
      "Time: 2019-05-11 15:37:25.002879746~2019-05-11 15:52:31.494545785, Loss: 0.6794, Nodes_count: 126687, Cost Time: 1503.67s\n",
      "Time: 2019-05-11 15:52:31.494545785~2019-05-11 16:08:01.493484725, Loss: 0.6902, Nodes_count: 126862, Cost Time: 1509.40s\n",
      "Time: 2019-05-11 16:08:01.493484725~2019-05-11 16:23:41.450431419, Loss: 0.4497, Nodes_count: 127085, Cost Time: 1521.11s\n",
      "Time: 2019-05-11 16:23:41.450431419~2019-05-11 16:39:13.198252375, Loss: 0.6992, Nodes_count: 127241, Cost Time: 1527.46s\n",
      "Time: 2019-05-11 16:39:13.198252375~2019-05-11 16:55:01.500153909, Loss: 0.7117, Nodes_count: 127424, Cost Time: 1533.67s\n",
      "Time: 2019-05-11 16:55:01.500153909~2019-05-11 17:11:03.959014293, Loss: 0.6469, Nodes_count: 127646, Cost Time: 1540.94s\n",
      "Time: 2019-05-11 17:11:03.959014293~2019-05-11 17:27:33.517836395, Loss: 1.3853, Nodes_count: 127766, Cost Time: 1543.66s\n",
      "Time: 2019-05-11 17:27:33.517836395~2019-05-11 17:43:31.490443808, Loss: 0.4925, Nodes_count: 127962, Cost Time: 1554.33s\n",
      "Time: 2019-05-11 17:43:31.490443808~2019-05-11 17:59:31.493502219, Loss: 0.9664, Nodes_count: 128138, Cost Time: 1558.68s\n",
      "Time: 2019-05-11 17:59:31.493502219~2019-05-11 18:15:44.708305071, Loss: 0.6394, Nodes_count: 128342, Cost Time: 1566.83s\n",
      "Time: 2019-05-11 18:15:44.708305071~2019-05-11 18:32:01.493784231, Loss: 0.3329, Nodes_count: 128620, Cost Time: 1583.84s\n",
      "Time: 2019-05-11 18:32:01.493784231~2019-05-11 18:47:13.969095860, Loss: 0.4997, Nodes_count: 128806, Cost Time: 1594.56s\n",
      "Time: 2019-05-11 18:47:13.969095860~2019-05-11 19:03:42.787479327, Loss: 0.5126, Nodes_count: 129067, Cost Time: 1605.51s\n",
      "Time: 2019-05-11 19:03:42.787479327~2019-05-11 19:19:45.328437923, Loss: 0.9219, Nodes_count: 129209, Cost Time: 1610.52s\n",
      "Time: 2019-05-11 19:19:45.328437923~2019-05-11 19:36:04.866440471, Loss: 0.6992, Nodes_count: 129381, Cost Time: 1617.14s\n",
      "Time: 2019-05-11 19:36:04.866440471~2019-05-11 19:51:40.042976171, Loss: 0.3909, Nodes_count: 129623, Cost Time: 1633.26s\n",
      "Time: 2019-05-11 19:51:40.042976171~2019-05-11 20:07:24.862800224, Loss: 0.4330, Nodes_count: 129856, Cost Time: 1645.21s\n",
      "Time: 2019-05-11 20:07:24.862800224~2019-05-11 20:24:01.506044420, Loss: 0.4720, Nodes_count: 130072, Cost Time: 1657.55s\n",
      "Time: 2019-05-11 20:24:01.506044420~2019-05-11 20:39:47.303979026, Loss: 1.3460, Nodes_count: 130181, Cost Time: 1660.49s\n",
      "Time: 2019-05-11 20:39:47.303979026~2019-05-11 20:55:01.495228602, Loss: 0.5412, Nodes_count: 130372, Cost Time: 1669.67s\n",
      "Time: 2019-05-11 20:55:01.495228602~2019-05-11 21:11:31.496595479, Loss: 1.2320, Nodes_count: 130508, Cost Time: 1673.21s\n",
      "Time: 2019-05-11 21:11:31.496595479~2019-05-11 21:28:01.492916934, Loss: 1.4287, Nodes_count: 130631, Cost Time: 1675.86s\n",
      "Time: 2019-05-11 21:28:01.492916934~2019-05-11 21:44:43.279039868, Loss: 0.4216, Nodes_count: 130851, Cost Time: 1689.05s\n",
      "Time: 2019-05-11 21:44:43.279039868~2019-05-11 21:59:49.871208266, Loss: 0.6046, Nodes_count: 131137, Cost Time: 1700.92s\n",
      "Time: 2019-05-11 21:59:49.871208266~2019-05-11 22:15:17.913406650, Loss: 0.8709, Nodes_count: 131276, Cost Time: 1706.23s\n",
      "Time: 2019-05-11 22:15:17.913406650~2019-05-11 22:30:29.105231854, Loss: 0.6803, Nodes_count: 131438, Cost Time: 1712.63s\n",
      "Time: 2019-05-11 22:30:29.105231854~2019-05-11 22:45:41.943179151, Loss: 0.7553, Nodes_count: 131586, Cost Time: 1718.37s\n",
      "Time: 2019-05-11 22:45:41.943179151~2019-05-11 23:02:31.492113855, Loss: 1.2313, Nodes_count: 131706, Cost Time: 1721.88s\n",
      "Time: 2019-05-11 23:02:31.492113855~2019-05-11 23:17:43.542872267, Loss: 0.4440, Nodes_count: 131889, Cost Time: 1733.57s\n",
      "Time: 2019-05-11 23:17:43.542872267~2019-05-11 23:33:01.508230259, Loss: 0.5872, Nodes_count: 132062, Cost Time: 1741.82s\n",
      "Time: 2019-05-11 23:33:01.508230259~2019-05-11 23:48:02.369685328, Loss: 0.4929, Nodes_count: 132229, Cost Time: 1751.45s\n"
     ]
    }
   ],
   "source": [
    "ans_5_11=test_day_new(graph_5_11,\"graph_5_11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after merge: TemporalData(dst=[13591537], msg=[13591537, 41], src=[13591537], t=[13591537])\n",
      "Time: 2019-05-14 00:00:00.216652068~2019-05-14 00:15:02.152576344, Loss: 0.2322, Nodes_count: 115823, Cost Time: 26.00s\n",
      "Time: 2019-05-14 00:15:02.152576344~2019-05-14 00:30:52.456495816, Loss: 0.3641, Nodes_count: 116237, Cost Time: 45.00s\n",
      "Time: 2019-05-14 00:30:52.456495816~2019-05-14 00:46:31.488675323, Loss: 0.2998, Nodes_count: 116665, Cost Time: 68.78s\n",
      "Time: 2019-05-14 00:46:31.488675323~2019-05-14 01:02:22.766494572, Loss: 0.1727, Nodes_count: 117163, Cost Time: 99.47s\n",
      "Time: 2019-05-14 01:02:22.766494572~2019-05-14 01:18:47.800927242, Loss: 0.1523, Nodes_count: 117448, Cost Time: 134.35s\n",
      "Time: 2019-05-14 01:18:47.800927242~2019-05-14 01:33:57.109874818, Loss: 0.3200, Nodes_count: 117893, Cost Time: 160.91s\n",
      "Time: 2019-05-14 01:33:57.109874818~2019-05-14 01:49:42.711286391, Loss: 0.1248, Nodes_count: 138660, Cost Time: 235.21s\n",
      "Time: 2019-05-14 01:49:42.711286391~2019-05-14 02:04:42.847148244, Loss: 0.1366, Nodes_count: 140997, Cost Time: 301.73s\n",
      "Time: 2019-05-14 02:04:42.847148244~2019-05-14 02:21:17.881023437, Loss: 0.4091, Nodes_count: 141332, Cost Time: 317.23s\n",
      "Time: 2019-05-14 02:21:17.881023437~2019-05-14 02:37:08.796215519, Loss: 0.1828, Nodes_count: 142788, Cost Time: 369.81s\n",
      "Time: 2019-05-14 02:37:08.796215519~2019-05-14 02:53:02.686777403, Loss: 0.0949, Nodes_count: 144511, Cost Time: 470.02s\n",
      "Time: 2019-05-14 02:53:02.686777403~2019-05-14 03:08:06.039823042, Loss: 0.2825, Nodes_count: 145216, Cost Time: 511.56s\n",
      "Time: 2019-05-14 03:08:06.039823042~2019-05-14 03:24:24.125824282, Loss: 0.3779, Nodes_count: 145513, Cost Time: 532.08s\n",
      "Time: 2019-05-14 03:24:24.125824282~2019-05-14 03:40:31.492266909, Loss: 0.4797, Nodes_count: 145841, Cost Time: 547.91s\n",
      "Time: 2019-05-14 03:40:31.492266909~2019-05-14 03:55:39.463370919, Loss: 0.3095, Nodes_count: 146249, Cost Time: 577.14s\n",
      "Time: 2019-05-14 03:55:39.463370919~2019-05-14 04:11:20.402783947, Loss: 0.1534, Nodes_count: 150094, Cost Time: 655.17s\n",
      "Time: 2019-05-14 04:11:20.402783947~2019-05-14 04:27:29.028367610, Loss: 0.2928, Nodes_count: 150415, Cost Time: 682.98s\n",
      "Time: 2019-05-14 04:27:29.028367610~2019-05-14 04:42:31.507049782, Loss: 0.2768, Nodes_count: 150717, Cost Time: 704.39s\n",
      "Time: 2019-05-14 04:42:31.507049782~2019-05-14 04:57:54.101068941, Loss: 0.4810, Nodes_count: 151015, Cost Time: 718.72s\n",
      "Time: 2019-05-14 04:57:54.101068941~2019-05-14 05:13:31.492618479, Loss: 0.1268, Nodes_count: 171417, Cost Time: 808.39s\n",
      "Time: 2019-05-14 05:13:31.492618479~2019-05-14 05:29:31.505968490, Loss: 0.3224, Nodes_count: 171785, Cost Time: 833.29s\n",
      "Time: 2019-05-14 05:29:31.505968490~2019-05-14 05:44:42.157151223, Loss: 0.2018, Nodes_count: 172142, Cost Time: 904.54s\n",
      "Time: 2019-05-14 05:44:42.157151223~2019-05-14 05:59:43.139781502, Loss: 0.4220, Nodes_count: 172464, Cost Time: 919.98s\n",
      "Time: 2019-05-14 05:59:43.139781502~2019-05-14 06:14:50.863134060, Loss: 0.3723, Nodes_count: 172768, Cost Time: 945.86s\n",
      "Time: 2019-05-14 06:14:50.863134060~2019-05-14 06:30:25.403853123, Loss: 0.2890, Nodes_count: 173132, Cost Time: 975.49s\n",
      "Time: 2019-05-14 06:30:25.403853123~2019-05-14 06:45:43.292845666, Loss: 0.3435, Nodes_count: 173440, Cost Time: 998.31s\n",
      "Time: 2019-05-14 06:45:43.292845666~2019-05-14 07:00:48.956786874, Loss: 0.1492, Nodes_count: 178031, Cost Time: 1072.28s\n",
      "Time: 2019-05-14 07:00:48.956786874~2019-05-14 07:15:55.106970028, Loss: 0.3117, Nodes_count: 178329, Cost Time: 1096.98s\n",
      "Time: 2019-05-14 07:15:55.106970028~2019-05-14 07:31:06.351388922, Loss: 0.3430, Nodes_count: 178615, Cost Time: 1121.72s\n",
      "Time: 2019-05-14 07:31:06.351388922~2019-05-14 07:46:06.406187653, Loss: 0.3815, Nodes_count: 194457, Cost Time: 1162.27s\n",
      "Time: 2019-05-14 07:46:06.406187653~2019-05-14 08:01:28.100458703, Loss: 0.7490, Nodes_count: 218033, Cost Time: 1230.59s\n",
      "Time: 2019-05-14 08:01:28.100458703~2019-05-14 08:16:28.839199678, Loss: 0.5279, Nodes_count: 219548, Cost Time: 1263.90s\n",
      "Time: 2019-05-14 08:16:28.839199678~2019-05-14 08:31:32.729512360, Loss: 3.1025, Nodes_count: 220563, Cost Time: 1295.78s\n",
      "Time: 2019-05-14 08:31:32.729512360~2019-05-14 08:46:44.052873581, Loss: 0.1142, Nodes_count: 223312, Cost Time: 1451.54s\n",
      "Time: 2019-05-14 08:46:44.052873581~2019-05-14 09:02:14.558261420, Loss: 0.3565, Nodes_count: 223618, Cost Time: 1477.35s\n",
      "Time: 2019-05-14 09:02:14.558261420~2019-05-14 09:17:20.971655668, Loss: 0.4336, Nodes_count: 224861, Cost Time: 1535.64s\n",
      "Time: 2019-05-14 09:17:20.971655668~2019-05-14 09:32:31.497798481, Loss: 3.1055, Nodes_count: 225931, Cost Time: 1591.66s\n",
      "Time: 2019-05-14 09:32:31.497798481~2019-05-14 09:49:09.590528813, Loss: 0.3946, Nodes_count: 226185, Cost Time: 1611.91s\n",
      "Time: 2019-05-14 09:49:09.590528813~2019-05-14 10:05:01.487422951, Loss: 0.4007, Nodes_count: 226435, Cost Time: 1634.12s\n",
      "Time: 2019-05-14 10:05:01.487422951~2019-05-14 10:21:01.484905000, Loss: 0.4381, Nodes_count: 226651, Cost Time: 1653.46s\n",
      "Time: 2019-05-14 10:21:01.484905000~2019-05-14 10:37:26.048664593, Loss: 0.3558, Nodes_count: 226884, Cost Time: 1682.45s\n",
      "Time: 2019-05-14 10:37:26.048664593~2019-05-14 10:53:01.494421034, Loss: 0.3807, Nodes_count: 227097, Cost Time: 1703.19s\n",
      "Time: 2019-05-14 10:53:01.494421034~2019-05-14 11:08:27.055236406, Loss: 0.2907, Nodes_count: 227347, Cost Time: 1743.73s\n",
      "Time: 2019-05-14 11:08:27.055236406~2019-05-14 11:24:01.496118837, Loss: 0.2773, Nodes_count: 228240, Cost Time: 1781.17s\n",
      "Time: 2019-05-14 11:24:01.496118837~2019-05-14 11:40:15.252528842, Loss: 0.2409, Nodes_count: 228519, Cost Time: 1803.65s\n",
      "Time: 2019-05-14 11:40:15.252528842~2019-05-14 11:55:25.711738425, Loss: 0.2425, Nodes_count: 228910, Cost Time: 1836.15s\n",
      "Time: 2019-05-14 11:55:25.711738425~2019-05-14 12:10:32.440531011, Loss: 0.1603, Nodes_count: 229430, Cost Time: 1881.46s\n",
      "Time: 2019-05-14 12:10:32.440531011~2019-05-14 12:26:47.026847931, Loss: 0.2126, Nodes_count: 229782, Cost Time: 1907.46s\n",
      "Time: 2019-05-14 12:26:47.026847931~2019-05-14 12:43:01.495215198, Loss: 0.0878, Nodes_count: 251852, Cost Time: 2296.23s\n",
      "Time: 2019-05-14 12:43:01.495215198~2019-05-14 12:59:29.343065601, Loss: 0.1600, Nodes_count: 252085, Cost Time: 2322.65s\n",
      "Time: 2019-05-14 12:59:29.343065601~2019-05-14 13:14:36.494846495, Loss: 0.1741, Nodes_count: 252413, Cost Time: 2358.02s\n",
      "Time: 2019-05-14 13:14:36.494846495~2019-05-14 13:31:01.488594793, Loss: 0.1039, Nodes_count: 257768, Cost Time: 2477.97s\n",
      "Time: 2019-05-14 13:31:01.488594793~2019-05-14 13:46:56.649368141, Loss: 0.1610, Nodes_count: 258251, Cost Time: 2527.82s\n",
      "Time: 2019-05-14 13:46:56.649368141~2019-05-14 14:01:56.861865565, Loss: 0.0958, Nodes_count: 259633, Cost Time: 2650.67s\n",
      "Time: 2019-05-14 14:01:56.861865565~2019-05-14 14:18:12.441876858, Loss: 0.0752, Nodes_count: 263279, Cost Time: 2898.13s\n",
      "Time: 2019-05-14 14:18:12.441876858~2019-05-14 14:33:35.665615598, Loss: 0.2444, Nodes_count: 263633, Cost Time: 2929.36s\n",
      "Time: 2019-05-14 14:33:35.665615598~2019-05-14 14:49:05.595227210, Loss: 0.1684, Nodes_count: 264051, Cost Time: 2979.25s\n",
      "Time: 2019-05-14 14:49:05.595227210~2019-05-14 15:04:31.495739830, Loss: 0.0595, Nodes_count: 265872, Cost Time: 3090.54s\n",
      "Time: 2019-05-14 15:04:31.495739830~2019-05-14 15:19:40.210880344, Loss: 0.0565, Nodes_count: 266578, Cost Time: 3310.16s\n",
      "Time: 2019-05-14 15:19:40.210880344~2019-05-14 15:35:01.495871430, Loss: 0.0988, Nodes_count: 267273, Cost Time: 3435.90s\n",
      "Time: 2019-05-14 15:35:01.495871430~2019-05-14 15:50:01.496409854, Loss: 0.1892, Nodes_count: 267693, Cost Time: 3478.04s\n",
      "Time: 2019-05-14 15:50:01.496409854~2019-05-14 16:07:01.495577354, Loss: 0.1723, Nodes_count: 268033, Cost Time: 3513.00s\n",
      "Time: 2019-05-14 16:07:01.495577354~2019-05-14 16:22:09.008166964, Loss: 0.0935, Nodes_count: 271364, Cost Time: 3646.53s\n",
      "Time: 2019-05-14 16:22:09.008166964~2019-05-14 16:37:48.629717740, Loss: 0.0881, Nodes_count: 272556, Cost Time: 3783.09s\n",
      "Time: 2019-05-14 16:37:48.629717740~2019-05-14 16:52:56.416852310, Loss: 0.0743, Nodes_count: 272979, Cost Time: 3895.22s\n",
      "Time: 2019-05-14 16:52:56.416852310~2019-05-14 17:08:03.416037709, Loss: 0.1620, Nodes_count: 273287, Cost Time: 3921.76s\n",
      "Time: 2019-05-14 17:08:03.416037709~2019-05-14 17:23:18.956163567, Loss: 0.0985, Nodes_count: 274632, Cost Time: 4050.44s\n",
      "Time: 2019-05-14 17:23:18.956163567~2019-05-14 17:39:05.176280359, Loss: 0.0958, Nodes_count: 275760, Cost Time: 4256.71s\n",
      "Time: 2019-05-14 17:39:05.176280359~2019-05-14 17:55:18.763900563, Loss: 0.0601, Nodes_count: 284023, Cost Time: 4390.07s\n",
      "Time: 2019-05-14 17:55:18.763900563~2019-05-14 18:10:19.195011436, Loss: 0.1750, Nodes_count: 284367, Cost Time: 4429.98s\n",
      "Time: 2019-05-14 18:10:19.195011436~2019-05-14 18:25:19.291228993, Loss: 0.1893, Nodes_count: 284815, Cost Time: 4485.91s\n",
      "Time: 2019-05-14 18:25:19.291228993~2019-05-14 18:40:21.201780869, Loss: 0.1755, Nodes_count: 285126, Cost Time: 4531.20s\n",
      "Time: 2019-05-14 18:40:21.201780869~2019-05-14 18:56:52.129475445, Loss: 0.1510, Nodes_count: 285559, Cost Time: 4603.40s\n",
      "Time: 2019-05-14 18:56:52.129475445~2019-05-14 19:12:10.712408509, Loss: 0.1681, Nodes_count: 285752, Cost Time: 4633.57s\n",
      "Time: 2019-05-14 19:12:10.712408509~2019-05-14 19:28:38.128423572, Loss: 0.2277, Nodes_count: 285983, Cost Time: 4651.87s\n",
      "Time: 2019-05-14 19:28:38.128423572~2019-05-14 19:45:01.500731472, Loss: 0.1535, Nodes_count: 290209, Cost Time: 4740.92s\n",
      "Time: 2019-05-14 19:45:01.500731472~2019-05-14 20:00:01.564775961, Loss: 0.1310, Nodes_count: 291986, Cost Time: 4847.71s\n",
      "Time: 2019-05-14 20:00:01.564775961~2019-05-14 20:15:31.498565817, Loss: 0.1421, Nodes_count: 292396, Cost Time: 4954.62s\n",
      "Time: 2019-05-14 20:15:31.498565817~2019-05-14 20:30:39.905147822, Loss: 0.0858, Nodes_count: 293779, Cost Time: 5057.29s\n",
      "Time: 2019-05-14 20:30:39.905147822~2019-05-14 20:48:29.853305652, Loss: 0.1832, Nodes_count: 294093, Cost Time: 5089.44s\n",
      "Time: 2019-05-14 20:48:29.853305652~2019-05-14 21:03:35.529877137, Loss: 0.1680, Nodes_count: 294339, Cost Time: 5116.39s\n",
      "Time: 2019-05-14 21:03:35.529877137~2019-05-14 21:19:23.539915401, Loss: 0.0900, Nodes_count: 295923, Cost Time: 5221.68s\n",
      "Time: 2019-05-14 21:19:23.539915401~2019-05-14 21:35:16.383991146, Loss: 0.1972, Nodes_count: 296150, Cost Time: 5254.20s\n",
      "Time: 2019-05-14 21:35:16.383991146~2019-05-14 21:52:04.868022874, Loss: 0.1509, Nodes_count: 296443, Cost Time: 5297.16s\n",
      "Time: 2019-05-14 21:52:04.868022874~2019-05-14 22:08:01.492103293, Loss: 0.1075, Nodes_count: 298124, Cost Time: 5395.73s\n",
      "Time: 2019-05-14 22:08:01.492103293~2019-05-14 22:24:09.949262623, Loss: 0.1804, Nodes_count: 298300, Cost Time: 5415.58s\n",
      "Time: 2019-05-14 22:24:09.949262623~2019-05-14 22:39:18.367975095, Loss: 0.0667, Nodes_count: 299158, Cost Time: 5584.40s\n",
      "Time: 2019-05-14 22:39:18.367975095~2019-05-14 22:54:58.932966824, Loss: 0.0885, Nodes_count: 299583, Cost Time: 5709.62s\n",
      "Time: 2019-05-14 22:54:58.932966824~2019-05-14 23:11:08.033781569, Loss: 0.2233, Nodes_count: 299920, Cost Time: 5743.72s\n",
      "Time: 2019-05-14 23:11:08.033781569~2019-05-14 23:27:10.374817359, Loss: 0.2506, Nodes_count: 300223, Cost Time: 5775.78s\n",
      "Time: 2019-05-14 23:27:10.374817359~2019-05-14 23:42:22.657126844, Loss: 0.2975, Nodes_count: 300399, Cost Time: 5791.07s\n",
      "Time: 2019-05-14 23:42:22.657126844~2019-05-14 23:57:53.548510363, Loss: 0.2972, Nodes_count: 300645, Cost Time: 5812.12s\n"
     ]
    }
   ],
   "source": [
    "ans_5_14=test_day_new(graph_5_14,\"graph_5_14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after merge: TemporalData(dst=[12310324], msg=[12310324, 41], src=[12310324], t=[12310324])\n",
      "Time: 2019-05-15 00:00:01.490408727~2019-05-15 00:16:14.833595653, Loss: 0.1279, Nodes_count: 1544, Cost Time: 15.97s\n",
      "Time: 2019-05-15 00:16:14.833595653~2019-05-15 00:32:01.492056162, Loss: 0.1570, Nodes_count: 2670, Cost Time: 34.95s\n",
      "Time: 2019-05-15 00:32:01.492056162~2019-05-15 00:47:15.554515213, Loss: 0.2672, Nodes_count: 2893, Cost Time: 42.58s\n",
      "Time: 2019-05-15 00:47:15.554515213~2019-05-15 01:04:31.491761640, Loss: 0.2826, Nodes_count: 3099, Cost Time: 48.01s\n",
      "Time: 2019-05-15 01:04:31.491761640~2019-05-15 01:20:01.492131631, Loss: 0.1450, Nodes_count: 3276, Cost Time: 57.79s\n",
      "Time: 2019-05-15 01:20:01.492131631~2019-05-15 01:36:01.495126517, Loss: 0.1847, Nodes_count: 3536, Cost Time: 72.35s\n",
      "Time: 2019-05-15 01:36:01.495126517~2019-05-15 01:51:02.896532154, Loss: 0.2568, Nodes_count: 3830, Cost Time: 86.79s\n",
      "Time: 2019-05-15 01:51:02.896532154~2019-05-15 02:07:19.144870551, Loss: 0.1857, Nodes_count: 79255, Cost Time: 113.75s\n",
      "Time: 2019-05-15 02:07:19.144870551~2019-05-15 02:23:18.291403804, Loss: 0.2482, Nodes_count: 79530, Cost Time: 126.07s\n",
      "Time: 2019-05-15 02:23:18.291403804~2019-05-15 02:39:26.758938680, Loss: 0.2385, Nodes_count: 79822, Cost Time: 142.96s\n",
      "Time: 2019-05-15 02:39:26.758938680~2019-05-15 02:54:29.939561154, Loss: 0.1052, Nodes_count: 99877, Cost Time: 173.54s\n",
      "Time: 2019-05-15 02:54:29.939561154~2019-05-15 03:09:30.148005357, Loss: 0.0919, Nodes_count: 106760, Cost Time: 211.44s\n",
      "Time: 2019-05-15 03:09:30.148005357~2019-05-15 03:25:02.394441209, Loss: 0.1017, Nodes_count: 108498, Cost Time: 257.89s\n",
      "Time: 2019-05-15 03:25:02.394441209~2019-05-15 03:41:44.920119418, Loss: 0.1910, Nodes_count: 108768, Cost Time: 276.97s\n",
      "Time: 2019-05-15 03:41:44.920119418~2019-05-15 03:58:07.697665053, Loss: 0.1147, Nodes_count: 109051, Cost Time: 305.88s\n",
      "Time: 2019-05-15 03:58:07.697665053~2019-05-15 04:14:56.274252703, Loss: 0.1380, Nodes_count: 109336, Cost Time: 328.36s\n",
      "Time: 2019-05-15 04:14:56.274252703~2019-05-15 04:31:01.490574676, Loss: 0.1615, Nodes_count: 109546, Cost Time: 343.17s\n",
      "Time: 2019-05-15 04:31:01.490574676~2019-05-15 04:46:31.301354716, Loss: 0.2645, Nodes_count: 109724, Cost Time: 353.22s\n",
      "Time: 2019-05-15 04:46:31.301354716~2019-05-15 05:01:36.395374506, Loss: 0.3035, Nodes_count: 109882, Cost Time: 359.34s\n",
      "Time: 2019-05-15 05:01:36.395374506~2019-05-15 05:17:01.503229576, Loss: 0.1517, Nodes_count: 110073, Cost Time: 372.52s\n",
      "Time: 2019-05-15 05:17:01.503229576~2019-05-15 05:32:11.337521289, Loss: 0.3240, Nodes_count: 110244, Cost Time: 378.47s\n",
      "Time: 2019-05-15 05:32:11.337521289~2019-05-15 05:48:01.503688497, Loss: 0.2848, Nodes_count: 110478, Cost Time: 390.33s\n",
      "Time: 2019-05-15 05:48:01.503688497~2019-05-15 06:05:01.495772298, Loss: 0.2758, Nodes_count: 110709, Cost Time: 399.56s\n",
      "Time: 2019-05-15 06:05:01.495772298~2019-05-15 06:20:51.005863855, Loss: 0.2397, Nodes_count: 111046, Cost Time: 417.93s\n",
      "Time: 2019-05-15 06:20:51.005863855~2019-05-15 06:36:01.491983616, Loss: 0.2966, Nodes_count: 111214, Cost Time: 425.47s\n",
      "Time: 2019-05-15 06:36:01.491983616~2019-05-15 06:53:31.493116975, Loss: 0.1541, Nodes_count: 111500, Cost Time: 443.52s\n",
      "Time: 2019-05-15 06:53:31.493116975~2019-05-15 07:09:55.168118324, Loss: 0.2339, Nodes_count: 112628, Cost Time: 456.95s\n",
      "Time: 2019-05-15 07:09:55.168118324~2019-05-15 07:27:01.254806380, Loss: 0.3642, Nodes_count: 112769, Cost Time: 460.64s\n",
      "Time: 2019-05-15 07:27:01.254806380~2019-05-15 07:42:05.122895776, Loss: 0.0725, Nodes_count: 121941, Cost Time: 501.30s\n",
      "Time: 2019-05-15 07:42:05.122895776~2019-05-15 07:57:29.435273604, Loss: 0.4084, Nodes_count: 213125, Cost Time: 560.44s\n",
      "Time: 2019-05-15 07:57:29.435273604~2019-05-15 08:12:40.385079790, Loss: 0.1680, Nodes_count: 213403, Cost Time: 590.19s\n",
      "Time: 2019-05-15 08:12:40.385079790~2019-05-15 08:28:58.370499520, Loss: 0.0979, Nodes_count: 219211, Cost Time: 660.13s\n",
      "Time: 2019-05-15 08:28:58.370499520~2019-05-15 08:46:17.912177800, Loss: 0.1047, Nodes_count: 219943, Cost Time: 715.69s\n",
      "Time: 2019-05-15 08:46:17.912177800~2019-05-15 09:01:36.712206897, Loss: 0.0664, Nodes_count: 221269, Cost Time: 913.19s\n",
      "Time: 2019-05-15 09:01:36.712206897~2019-05-15 09:18:20.052280739, Loss: 0.0974, Nodes_count: 222259, Cost Time: 1067.88s\n",
      "Time: 2019-05-15 09:18:20.052280739~2019-05-15 09:33:20.409598023, Loss: 0.1736, Nodes_count: 223008, Cost Time: 1151.21s\n",
      "Time: 2019-05-15 09:33:20.409598023~2019-05-15 09:48:20.851554754, Loss: 0.2719, Nodes_count: 223266, Cost Time: 1172.30s\n",
      "Time: 2019-05-15 09:48:20.851554754~2019-05-15 10:04:07.712341272, Loss: 0.1036, Nodes_count: 225757, Cost Time: 1296.26s\n",
      "Time: 2019-05-15 10:04:07.712341272~2019-05-15 10:19:12.055930735, Loss: 0.0823, Nodes_count: 226533, Cost Time: 1525.54s\n",
      "Time: 2019-05-15 10:19:12.055930735~2019-05-15 10:34:12.998931412, Loss: 0.1865, Nodes_count: 226904, Cost Time: 1568.84s\n",
      "Time: 2019-05-15 10:34:12.998931412~2019-05-15 10:52:01.493441398, Loss: 0.2362, Nodes_count: 227239, Cost Time: 1597.48s\n",
      "Time: 2019-05-15 10:52:01.493441398~2019-05-15 11:07:01.494486145, Loss: 0.1139, Nodes_count: 228988, Cost Time: 1680.47s\n",
      "Time: 2019-05-15 11:07:01.494486145~2019-05-15 11:22:08.001455967, Loss: 0.1556, Nodes_count: 229450, Cost Time: 1729.61s\n",
      "Time: 2019-05-15 11:22:08.001455967~2019-05-15 11:38:31.497341568, Loss: 0.2146, Nodes_count: 229804, Cost Time: 1757.00s\n",
      "Time: 2019-05-15 11:38:31.497341568~2019-05-15 11:54:52.383589579, Loss: 0.0952, Nodes_count: 230238, Cost Time: 1842.45s\n",
      "Time: 2019-05-15 11:54:52.383589579~2019-05-15 13:27:01.496190252, Loss: 0.0236, Nodes_count: 232085, Cost Time: 1924.12s\n",
      "Time: 2019-05-15 13:27:01.496190252~2019-05-15 13:42:24.177751369, Loss: 0.3637, Nodes_count: 235626, Cost Time: 2119.72s\n",
      "Time: 2019-05-15 13:42:24.177751369~2019-05-15 13:58:15.520482252, Loss: 0.3998, Nodes_count: 236651, Cost Time: 2163.83s\n",
      "Time: 2019-05-15 13:58:15.520482252~2019-05-15 14:13:37.257086895, Loss: 6.8805, Nodes_count: 238954, Cost Time: 2245.20s\n",
      "Time: 2019-05-15 14:13:37.257086895~2019-05-15 14:29:18.996669142, Loss: 0.1729, Nodes_count: 239536, Cost Time: 2315.88s\n",
      "Time: 2019-05-15 14:29:18.996669142~2019-05-15 14:44:51.773840192, Loss: 0.1896, Nodes_count: 239832, Cost Time: 2350.68s\n",
      "Time: 2019-05-15 14:44:51.773840192~2019-05-15 15:00:26.765466538, Loss: 2.3482, Nodes_count: 240939, Cost Time: 2465.22s\n",
      "Time: 2019-05-15 15:00:26.765466538~2019-05-15 15:17:03.203703087, Loss: 0.3601, Nodes_count: 241316, Cost Time: 2485.55s\n",
      "Time: 2019-05-15 15:17:03.203703087~2019-05-15 15:34:25.452570637, Loss: 0.0816, Nodes_count: 241635, Cost Time: 2600.02s\n",
      "Time: 2019-05-15 15:34:25.452570637~2019-05-15 15:49:43.447021039, Loss: 0.1283, Nodes_count: 241797, Cost Time: 2630.79s\n",
      "Time: 2019-05-15 15:49:43.447021039~2019-05-15 16:05:41.064452218, Loss: 0.1518, Nodes_count: 242067, Cost Time: 2662.87s\n",
      "Time: 2019-05-15 16:05:41.064452218~2019-05-15 16:22:39.979479840, Loss: 0.1783, Nodes_count: 242202, Cost Time: 2678.47s\n",
      "Time: 2019-05-15 16:22:39.979479840~2019-05-15 16:38:00.022566187, Loss: 0.1286, Nodes_count: 242408, Cost Time: 2722.41s\n",
      "Time: 2019-05-15 16:38:00.022566187~2019-05-15 16:54:31.494483643, Loss: 0.1444, Nodes_count: 242698, Cost Time: 2767.05s\n",
      "Time: 2019-05-15 16:54:31.494483643~2019-05-15 17:10:01.626108726, Loss: 0.0794, Nodes_count: 242859, Cost Time: 2821.58s\n",
      "Time: 2019-05-15 17:10:01.626108726~2019-05-15 17:25:14.590228152, Loss: 0.1793, Nodes_count: 243111, Cost Time: 2851.44s\n",
      "Time: 2019-05-15 17:25:14.590228152~2019-05-15 17:43:54.631759423, Loss: 0.0878, Nodes_count: 243342, Cost Time: 2962.79s\n",
      "Time: 2019-05-15 17:43:54.631759423~2019-05-15 18:00:21.533587327, Loss: 0.2129, Nodes_count: 243514, Cost Time: 2984.90s\n",
      "Time: 2019-05-15 18:00:21.533587327~2019-05-15 18:16:33.957928738, Loss: 0.0595, Nodes_count: 243785, Cost Time: 3135.48s\n",
      "Time: 2019-05-15 18:16:33.957928738~2019-05-15 18:32:44.229252473, Loss: 0.0774, Nodes_count: 243999, Cost Time: 3223.08s\n",
      "Time: 2019-05-15 18:32:44.229252473~2019-05-15 18:50:02.896672585, Loss: 0.1603, Nodes_count: 244136, Cost Time: 3237.27s\n",
      "Time: 2019-05-15 18:50:02.896672585~2019-05-15 19:05:15.589701783, Loss: 0.1464, Nodes_count: 244358, Cost Time: 3262.99s\n",
      "Time: 2019-05-15 19:05:15.589701783~2019-05-15 19:21:31.509532475, Loss: 0.1390, Nodes_count: 244577, Cost Time: 3301.54s\n",
      "Time: 2019-05-15 19:21:31.509532475~2019-05-15 19:37:24.849404892, Loss: 0.0622, Nodes_count: 244683, Cost Time: 3340.45s\n",
      "Time: 2019-05-15 19:37:24.849404892~2019-05-15 19:56:19.975334466, Loss: 0.1050, Nodes_count: 244849, Cost Time: 3391.00s\n",
      "Time: 2019-05-15 19:56:19.975334466~2019-05-15 20:12:58.479720072, Loss: 0.1359, Nodes_count: 245209, Cost Time: 3449.03s\n",
      "Time: 2019-05-15 20:12:58.479720072~2019-05-15 20:28:31.496181001, Loss: 0.1094, Nodes_count: 245443, Cost Time: 3491.51s\n",
      "Time: 2019-05-15 20:28:31.496181001~2019-05-15 20:45:02.944896082, Loss: 0.1427, Nodes_count: 245578, Cost Time: 3523.13s\n",
      "Time: 2019-05-15 20:45:02.944896082~2019-05-15 21:00:14.411230352, Loss: 0.0912, Nodes_count: 245851, Cost Time: 3653.76s\n",
      "Time: 2019-05-15 21:00:14.411230352~2019-05-15 21:16:04.951215086, Loss: 0.0759, Nodes_count: 246079, Cost Time: 3762.63s\n",
      "Time: 2019-05-15 21:16:04.951215086~2019-05-15 21:31:25.960086974, Loss: 0.1822, Nodes_count: 246300, Cost Time: 3790.46s\n",
      "Time: 2019-05-15 21:31:25.960086974~2019-05-15 21:47:41.306583947, Loss: 0.2120, Nodes_count: 246527, Cost Time: 3816.49s\n",
      "Time: 2019-05-15 21:47:41.306583947~2019-05-15 22:03:31.522168702, Loss: 0.1847, Nodes_count: 246637, Cost Time: 3834.23s\n",
      "Time: 2019-05-15 22:03:31.522168702~2019-05-15 22:19:16.263929035, Loss: 0.1117, Nodes_count: 246740, Cost Time: 3869.65s\n",
      "Time: 2019-05-15 22:19:16.263929035~2019-05-15 22:37:52.734006062, Loss: 0.0824, Nodes_count: 246864, Cost Time: 3897.73s\n",
      "Time: 2019-05-15 22:37:52.734006062~2019-05-15 22:55:31.494815444, Loss: 0.1968, Nodes_count: 247066, Cost Time: 3922.95s\n",
      "Time: 2019-05-15 22:55:31.494815444~2019-05-15 23:11:23.284826570, Loss: 0.1094, Nodes_count: 247306, Cost Time: 3999.82s\n",
      "Time: 2019-05-15 23:11:23.284826570~2019-05-15 23:29:31.512587396, Loss: 0.1027, Nodes_count: 247400, Cost Time: 4078.51s\n",
      "Time: 2019-05-15 23:29:31.512587396~2019-05-15 23:46:09.097590467, Loss: 0.2157, Nodes_count: 247466, Cost Time: 4087.13s\n"
     ]
    }
   ],
   "source": [
    "ans_5_15=test_day_new(graph_5_15,\"graph_5_15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the node IDF\n",
    "\n",
    "Calculates the Inverse Document Frequencey of each nodes \n",
    "\n",
    "IDF_of_node_x = log(nummber_of_time_widows / (1 + nuber_of_time_window_that_has_node_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [04:02<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF weight calculate complete!\n"
     ]
    }
   ],
   "source": [
    "# Stores the time window for each node\n",
    "node_set=set()\n",
    "\n",
    "# list of all time windows. Times windows are generated and stored as files using test_day_new()\n",
    "file_list=[]\n",
    "\n",
    "file_path=\"graph_5_9/\"\n",
    "file_l=os.listdir(\"graph_5_9/\")\n",
    "for i in file_l:\n",
    "    file_list.append(file_path+i)\n",
    "\n",
    "\n",
    "node_IDF={}\n",
    "node_set = {}\n",
    "for f_path in tqdm(file_list):\n",
    "    f=open(f_path)\n",
    "    for line in f:\n",
    "        l=line.strip()\n",
    "        jdata=eval(l)\n",
    "        jdata=eval(l)\n",
    "        if jdata['loss']>0:\n",
    "            if 'netflow' not in str(jdata['srcmsg']):\n",
    "                if str(jdata['srcmsg']) not in node_set.keys():\n",
    "                    node_set[str(jdata['srcmsg'])] = set([f_path])\n",
    "                else:\n",
    "                    node_set[str(jdata['srcmsg'])].add(f_path)\n",
    "            if 'netflow' not in str(jdata['dstmsg']):\n",
    "                if str(jdata['dstmsg']) not in node_set.keys():\n",
    "                    node_set[str(jdata['dstmsg'])] = set([f_path])\n",
    "                else:\n",
    "                    node_set[str(jdata['dstmsg'])].add(f_path)\n",
    "for n in node_set:\n",
    "    include_count = len(node_set[n])   \n",
    "    IDF=math.log(len(file_list)/(include_count+1))\n",
    "    node_IDF[n] = IDF    \n",
    "\n",
    "\n",
    "torch.save(node_IDF,\"node_IDF\")\n",
    "print(\"IDF weight calculate complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_train_IDF(find_str,file_list):\n",
    "    \"\"\"\n",
    "    Calculate the IDF value for a term in a set of time windows.\n",
    "\n",
    "    Parameters:\n",
    "        find_str (str): The term to calculate the IDF for.\n",
    "        file_list (list): List of file paths representing the time windows.\n",
    "\n",
    "    Returns:\n",
    "        float: The computed IDF value.\n",
    "    \"\"\"\n",
    "    include_count=0\n",
    "    for f_path in (file_list):\n",
    "        f=open(f_path)\n",
    "        if find_str in f.read():\n",
    "            include_count+=1             \n",
    "    IDF=math.log(len(file_list)/(include_count+1))\n",
    "    return IDF\n",
    "\n",
    "\n",
    "def cal_IDF(find_str,file_path,file_list):\n",
    "    file_list=os.listdir(file_path)\n",
    "    include_count=0\n",
    "    different_neighbor=set()\n",
    "    for f_path in (file_list):\n",
    "        f=open(file_path+f_path)\n",
    "        if find_str in f.read():\n",
    "            include_count+=1                \n",
    "                \n",
    "    IDF=math.log(len(file_list)/(include_count+1))\n",
    "    \n",
    "    return IDF,1\n",
    "\n",
    "def cal_redundant(find_str,edge_list):\n",
    "    \n",
    "    different_neighbor=set()\n",
    "    for e in edge_list:\n",
    "        if find_str in str(e):\n",
    "            different_neighbor.add(e[0])\n",
    "            different_neighbor.add(e[1])\n",
    "    return len(different_neighbor)-2\n",
    "\n",
    "def cal_anomaly_loss(loss_list,edge_list,file_path):\n",
    "    \"\"\"\n",
    "    Calculate anomaly loss by analyzing loss values exceeding a threshold.\n",
    "\n",
    "    Parameters:\n",
    "        loss_list (list): List of loss values for each edge.\n",
    "        edge_list (list): List of edges corresponding to the loss values.\n",
    "        file_path (str): Path to data files (currently unused).\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - count (int): Number of anomalies detected.\n",
    "            - avg_loss (float): Average loss of anomalous edges.\n",
    "            - node_set (set): Set of unique nodes involved in anomalies.\n",
    "            - edge_set (set): Set of unique edges with anomalies.\n",
    "    \"\"\"\n",
    "    if len(loss_list)!=len(edge_list):\n",
    "        print(\"error!\")\n",
    "        return 0\n",
    "    count = 0  # Count of anomalies\n",
    "    loss_sum = 0  # Sum of anomalous loss values\n",
    "    loss_std = std(loss_list)  # Standard deviation of loss values\n",
    "    loss_mean = mean(loss_list)  # Mean of loss values\n",
    "    edge_set = set()  # Unique edges with anomalies\n",
    "    node_set = set()  # Unique nodes involved in anomalies\n",
    "    \n",
    "    thr = loss_mean + 1.5 * loss_std  # Threshold for anomaly detection\n",
    "\n",
    "    print(\"thr:\",thr)\n",
    "\n",
    "    for i in range(len(loss_list)):\n",
    "        # Check if loss exceeds the threshold. If exceeds then anomalous node.\n",
    "        if loss_list[i]>thr:\n",
    "            count+=1\n",
    "            src_node=edge_list[i][0]\n",
    "            dst_node=edge_list[i][1]\n",
    "            \n",
    "            loss_sum+=loss_list[i]\n",
    "    \n",
    "            node_set.add(src_node)\n",
    "            node_set.add(dst_node)\n",
    "            edge_set.add(edge_list[i][0]+edge_list[i][1])\n",
    "    return count, loss_sum/count,node_set,edge_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct the relations between time windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_include_key_word(s):\n",
    "    \"\"\"\n",
    "    Check if a given string includes any predefined keywords.\n",
    "\n",
    "    Parameters:\n",
    "        s (str): The string to check.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if any keyword is found in the string, False otherwise.\n",
    "    \"\"\"\n",
    "    keywords=[\n",
    "         'netflow',\n",
    "        '/dev/pts',\n",
    "         'proc',\n",
    "      ]\n",
    "    flag=False\n",
    "    for i in keywords:\n",
    "        if i in s:\n",
    "            flag=True\n",
    "    return flag\n",
    "\n",
    "\n",
    "def cal_set_rel(s1,s2,file_list):\n",
    "    \"\"\"\n",
    "    Calculate the relevance of the intersection of two sets based on IDF values.\n",
    "\n",
    "    Parameters:\n",
    "        s1 (set): The first set of elements.\n",
    "        s2 (set): The second set of elements.\n",
    "        node_IDF (dict): Dictionary containing precomputed IDF values for nodes.\n",
    "        file_list (list): List of files to calculate default IDF values if a node is missing in node_IDF.\n",
    "\n",
    "    Returns:\n",
    "        int: The count of elements in the intersection of s1 and s2 that pass the IDF threshold.\n",
    "    \"\"\"\n",
    "    # Intersection of the two sets\n",
    "    new_s=s1 & s2\n",
    "    count=0\n",
    "    for i in new_s:\n",
    "        # Skip processing if the element includes some specific keywords\n",
    "        if is_include_key_word(i) is not True:\n",
    "            # Fetch the IDF value from the dictionary or calculate a default value\n",
    "            if i in node_IDF.keys():\n",
    "                IDF=node_IDF[i]\n",
    "            else:\n",
    "                IDF=math.log(len(file_list)/(1))\n",
    "\n",
    "            # Count the node if IDF is above the threshold\n",
    "            if (IDF)>4.5 :\n",
    "                print(\"node:\",i,\" IDF:\",IDF)\n",
    "                count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store ground truth labels for each time window\n",
    "# Initialize all truth value as 0 (benign)\n",
    "labels={}\n",
    "pred_label={}    \n",
    "    \n",
    "filelist = os.listdir(\"graph_5_14\")\n",
    "for f in filelist:\n",
    "    labels[\"graph_5_14/\"+f]=0\n",
    "    pred_label[\"graph_5_14/\"+f]=0\n",
    "\n",
    "filelist = os.listdir(\"graph_5_15\")\n",
    "for f in filelist:\n",
    "    labels[\"graph_5_15/\"+f]=0\n",
    "    pred_label[\"graph_5_15/\"+f]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 attack time window. Set thei truth value to 1\n",
    "attack_list=[\n",
    "    'graph_5_15/2019-05-15 13:58:15.520482252~2019-05-15 14:13:37.257086895.txt',\n",
    "    'graph_5_15/2019-05-15 14:44:51.773840192~2019-05-15 15:00:26.765466538.txt',\n",
    "]\n",
    "\n",
    "for i in attack_list:\n",
    "    labels[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign count: 174\n",
      "Attack count: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Benign count: {len(labels.values()) - sum(labels.values())}\")\n",
    "print(f\"Attack count: {sum(labels.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection\n",
    "Steps:\n",
    "\n",
    "1. Create a list of time window queues\n",
    "2. Process all time window serially\n",
    "3. For a time window calculate relevance with each of the time window in the time window queues\n",
    "4. If the relevance passes a certain threshold then push it in the corresponding time window queue and move on to the next queue to check\n",
    "5. If no relevance is found then create a new queue with the time window and store it\n",
    "\n",
    "5-11 to 5-15 follows the same steps. Proper comment has been added to 5-11 only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_count: 0\n",
      "thr: 1.9822804353454408\n",
      "graph_5_11/2019-05-11 00:00:00.500131269~2019-05-11 00:15:10.585413361.txt    3.413261017214172  count: 5223  percentage: 0.0864506091101695  node count: 143  edge count: 167\n",
      "index_count: 1\n",
      "thr: 2.0174402361424812\n",
      "graph_5_11/2019-05-11 00:15:10.585413361~2019-05-11 00:31:01.430200716.txt    3.4539998442285835  count: 5515  percentage: 0.08686680947580645  node count: 87  edge count: 101\n",
      "index_count: 2\n",
      "thr: 1.429723559543546\n",
      "graph_5_11/2019-05-11 00:31:01.430200716~2019-05-11 00:46:29.482831031.txt    3.260913855585701  count: 6468  percentage: 0.04448173415492958  node count: 129  edge count: 152\n",
      "index_count: 3\n",
      "thr: 1.8731082378571418\n",
      "graph_5_11/2019-05-11 00:46:29.482831031~2019-05-11 01:01:37.064383098.txt    3.344380599554258  count: 4948  percentage: 0.08477247807017543  node count: 86  edge count: 98\n",
      "index_count: 4\n",
      "thr: 1.5793834584651942\n",
      "graph_5_11/2019-05-11 01:01:37.064383098~2019-05-11 01:16:39.942709627.txt    3.28695102075878  count: 5306  percentage: 0.05130337252475248  node count: 194  edge count: 208\n",
      "index_count: 5\n",
      "thr: 1.5661022572511567\n",
      "graph_5_11/2019-05-11 01:16:39.942709627~2019-05-11 01:32:01.462298208.txt    3.408160637651099  count: 5682  percentage: 0.05044389204545455  node count: 142  edge count: 161\n",
      "index_count: 6\n",
      "thr: 1.4030343192219998\n",
      "graph_5_11/2019-05-11 01:32:01.462298208~2019-05-11 01:47:38.109830109.txt    3.2885843272550996  count: 5817  percentage: 0.0473388671875  node count: 177  edge count: 203\n",
      "index_count: 7\n",
      "thr: 3.4371005235825924\n",
      "graph_5_11/2019-05-11 01:47:38.109830109~2019-05-11 02:03:11.829718951.txt    7.260935078199513  count: 6038  percentage: 0.05896484375  node count: 3354  edge count: 3352\n",
      "index_count: 8\n",
      "thr: 1.4432831450544539\n",
      "graph_5_11/2019-05-11 02:03:11.829718951~2019-05-11 02:18:49.612834801.txt    3.2801982589139587  count: 5672  percentage: 0.05176693925233645  node count: 154  edge count: 167\n",
      "index_count: 9\n",
      "thr: 2.012782362129451\n",
      "graph_5_11/2019-05-11 02:18:49.612834801~2019-05-11 02:34:35.963377275.txt    3.4322158164927203  count: 5254  percentage: 0.09001507675438597  node count: 122  edge count: 138\n",
      "index_count: 10\n",
      "thr: 1.6936464256383374\n",
      "graph_5_11/2019-05-11 02:34:35.963377275~2019-05-11 02:51:01.459395653.txt    3.321346482036342  count: 6636  percentage: 0.06416305693069307  node count: 123  edge count: 150\n",
      "index_count: 11\n",
      "thr: 2.2395108973941005\n",
      "graph_5_11/2019-05-11 02:51:01.459395653~2019-05-11 03:06:06.971449468.txt    3.4677116709043876  count: 4729  percentage: 0.1154541015625  node count: 69  edge count: 77\n",
      "index_count: 12\n",
      "thr: 1.860347884908551\n",
      "graph_5_11/2019-05-11 03:06:06.971449468~2019-05-11 03:22:04.391793517.txt    3.3454854095149202  count: 5566  percentage: 0.08235677083333333  node count: 81  edge count: 93\n",
      "index_count: 13\n",
      "thr: 1.9260064261299203\n",
      "graph_5_11/2019-05-11 03:22:04.391793517~2019-05-11 03:37:32.924133941.txt    3.4108496082200817  count: 5227  percentage: 0.08102368551587301  node count: 89  edge count: 103\n",
      "index_count: 14\n",
      "thr: 1.6659228473801435\n",
      "graph_5_11/2019-05-11 03:37:32.924133941~2019-05-11 03:52:38.714923518.txt    3.4093527534000625  count: 5798  percentage: 0.0577766262755102  node count: 103  edge count: 117\n",
      "index_count: 15\n",
      "thr: 1.8106703108425721\n",
      "graph_5_11/2019-05-11 03:52:38.714923518~2019-05-11 04:09:01.471666913.txt    3.3842363100903725  count: 6359  percentage: 0.07220884811046512  node count: 237  edge count: 274\n",
      "index_count: 16\n",
      "thr: 2.329371132084853\n",
      "graph_5_11/2019-05-11 04:09:01.471666913~2019-05-11 04:25:28.350226445.txt    3.5547411820368113  count: 4925  percentage: 0.11730659298780488  node count: 75  edge count: 85\n",
      "index_count: 17\n",
      "thr: 1.908795946775247\n",
      "graph_5_11/2019-05-11 04:25:28.350226445~2019-05-11 04:41:31.612705711.txt    3.471561819412883  count: 5478  percentage: 0.07642299107142857  node count: 99  edge count: 115\n",
      "index_count: 18\n",
      "thr: 2.26907679735693\n",
      "graph_5_11/2019-05-11 04:41:31.612705711~2019-05-11 04:56:49.395636083.txt    3.4620029846480147  count: 5496  percentage: 0.1052389705882353  node count: 76  edge count: 83\n",
      "index_count: 19\n",
      "thr: 1.3581681024607386\n",
      "graph_5_11/2019-05-11 04:56:49.395636083~2019-05-11 05:13:04.898139559.txt    3.090927443660404  count: 6966  percentage: 0.048940535071942445  node count: 165  edge count: 185\n",
      "index_count: 20\n",
      "thr: 1.808198308550284\n",
      "graph_5_11/2019-05-11 05:13:04.898139559~2019-05-11 05:29:01.492754751.txt    3.3464862256112804  count: 6465  percentage: 0.07256869612068965  node count: 93  edge count: 121\n",
      "index_count: 21\n",
      "thr: 1.3268526957397535\n",
      "graph_5_11/2019-05-11 05:29:01.492754751~2019-05-11 05:45:26.427321308.txt    3.2542522863448045  count: 6264  percentage: 0.04400854316546762  node count: 181  edge count: 204\n",
      "index_count: 22\n",
      "thr: 2.042410014157271\n",
      "graph_5_11/2019-05-11 05:45:26.427321308~2019-05-11 06:00:32.541397033.txt    4.703771928552858  count: 7072  percentage: 0.04933035714285714  node count: 2042  edge count: 2048\n",
      "index_count: 23\n",
      "thr: 1.1051198705109457\n",
      "graph_5_11/2019-05-11 06:00:32.541397033~2019-05-11 06:16:02.917974906.txt    2.3609260189759977  count: 11356  percentage: 0.053574124396135264  node count: 228  edge count: 251\n",
      "index_count: 24\n",
      "thr: 2.188614647388376\n",
      "graph_5_11/2019-05-11 06:16:02.917974906~2019-05-11 06:32:01.493579408.txt    3.4689609674656134  count: 4938  percentage: 0.10483186141304347  node count: 81  edge count: 89\n",
      "index_count: 25\n",
      "thr: 1.8040995815752503\n",
      "graph_5_11/2019-05-11 06:32:01.493579408~2019-05-11 06:48:01.495937539.txt    3.448962130526105  count: 5825  percentage: 0.06937166539634146  node count: 100  edge count: 116\n",
      "index_count: 26\n",
      "thr: 2.688356765730625\n",
      "graph_5_11/2019-05-11 06:48:01.495937539~2019-05-11 07:03:06.190296071.txt    3.8107166047913776  count: 3138  percentage: 0.122578125  node count: 58  edge count: 56\n",
      "index_count: 27\n",
      "thr: 1.211719358902849\n",
      "graph_5_11/2019-05-11 07:03:06.190296071~2019-05-11 07:18:09.159477610.txt    2.8101264345092765  count: 7349  percentage: 0.04376071836890244  node count: 214  edge count: 239\n",
      "index_count: 28\n",
      "thr: 1.3715732632641402\n",
      "graph_5_11/2019-05-11 07:18:09.159477610~2019-05-11 07:35:01.101406729.txt    3.4570343221568196  count: 5173  percentage: 0.04431366502192982  node count: 185  edge count: 198\n",
      "index_count: 29\n",
      "thr: 1.827109377453755\n",
      "graph_5_11/2019-05-11 07:35:01.101406729~2019-05-11 07:50:01.504859344.txt    3.4939345539259685  count: 5928  percentage: 0.06891741071428571  node count: 254  edge count: 276\n",
      "index_count: 30\n",
      "thr: 2.1795403069471453\n",
      "graph_5_11/2019-05-11 07:50:01.504859344~2019-05-11 08:05:27.045713282.txt    4.540749057518473  count: 9715  percentage: 0.06004623219936709  node count: 393  edge count: 430\n",
      "index_count: 31\n",
      "thr: 2.2667018347289667\n",
      "graph_5_11/2019-05-11 08:05:27.045713282~2019-05-11 08:21:31.505389845.txt    3.544748015652754  count: 4864  percentage: 0.10795454545454546  node count: 65  edge count: 71\n",
      "index_count: 32\n",
      "thr: 1.5522023674599497\n",
      "graph_5_11/2019-05-11 08:21:31.505389845~2019-05-11 08:37:10.242927755.txt    3.4459606299129275  count: 5172  percentage: 0.0505078125  node count: 99  edge count: 112\n",
      "index_count: 33\n",
      "thr: 1.491871832304148\n",
      "graph_5_11/2019-05-11 08:37:10.242927755~2019-05-11 08:52:11.577068452.txt    3.41379718645972  count: 5068  percentage: 0.04758864182692308  node count: 109  edge count: 123\n",
      "index_count: 34\n",
      "thr: 1.1734273697853315\n",
      "graph_5_11/2019-05-11 08:52:11.577068452~2019-05-11 09:07:31.497392437.txt    2.6948095888168395  count: 7423  percentage: 0.045024990295031056  node count: 269  edge count: 287\n",
      "index_count: 35\n",
      "thr: 1.2534762761697893\n",
      "graph_5_11/2019-05-11 09:07:31.497392437~2019-05-11 09:23:43.378546037.txt    3.145120980423617  count: 6225  percentage: 0.04025895074503311  node count: 155  edge count: 166\n",
      "index_count: 36\n",
      "thr: 1.2581471553583654\n",
      "graph_5_11/2019-05-11 09:23:43.378546037~2019-05-11 09:39:28.743031655.txt    3.117699859230517  count: 5919  percentage: 0.04446364182692308  node count: 213  edge count: 228\n",
      "index_count: 37\n",
      "thr: 2.9815168973893926\n",
      "graph_5_11/2019-05-11 09:39:28.743031655~2019-05-11 09:55:12.543113845.txt    4.01482287867678  count: 2906  percentage: 0.1289950284090909  node count: 58  edge count: 54\n",
      "index_count: 38\n",
      "thr: 1.8294751116692536\n",
      "graph_5_11/2019-05-11 09:55:12.543113845~2019-05-11 10:10:40.816335674.txt    3.5768728943494597  count: 4711  percentage: 0.06572265625  node count: 64  edge count: 70\n",
      "index_count: 39\n",
      "thr: 2.8936405008713697\n",
      "graph_5_11/2019-05-11 10:10:40.816335674~2019-05-11 10:26:38.131479341.txt    5.653324832366889  count: 5555  percentage: 0.06615615472560976  node count: 2125  edge count: 2131\n",
      "index_count: 40\n",
      "thr: 1.1902186419723284\n",
      "graph_5_11/2019-05-11 10:26:38.131479341~2019-05-11 10:43:01.494767519.txt    2.56948355072239  count: 8454  percentage: 0.05064944401840491  node count: 201  edge count: 217\n",
      "index_count: 41\n",
      "thr: 1.235182800482251\n",
      "graph_5_11/2019-05-11 10:43:01.494767519~2019-05-11 10:58:29.047869392.txt    3.1890416527056384  count: 5643  percentage: 0.03774480950342466  node count: 111  edge count: 130\n",
      "index_count: 42\n",
      "thr: 1.2262432089532622\n",
      "graph_5_11/2019-05-11 10:58:29.047869392~2019-05-11 11:14:01.491540813.txt    3.0895973379759973  count: 6218  percentage: 0.03943029626623377  node count: 91  edge count: 102\n",
      "index_count: 43\n",
      "thr: 1.5973962022772688\n",
      "graph_5_11/2019-05-11 11:14:01.491540813~2019-05-11 11:29:31.376280190.txt    3.4632981720869513  count: 4902  percentage: 0.05260559752747253  node count: 82  edge count: 93\n",
      "index_count: 44\n",
      "thr: 2.177868684186607\n",
      "graph_5_11/2019-05-11 11:29:31.376280190~2019-05-11 11:45:00.345862636.txt    3.4187766250369576  count: 4547  percentage: 0.1110107421875  node count: 77  edge count: 81\n",
      "index_count: 45\n",
      "thr: 1.6978746092587957\n",
      "graph_5_11/2019-05-11 11:45:00.345862636~2019-05-11 12:01:12.133236819.txt    3.5155865499524923  count: 5227  percentage: 0.05800559303977273  node count: 88  edge count: 102\n",
      "index_count: 46\n",
      "thr: 1.6986800574970609\n",
      "graph_5_11/2019-05-11 12:01:12.133236819~2019-05-11 12:16:36.422369171.txt    3.4692160077960357  count: 4728  percentage: 0.05844541139240506  node count: 79  edge count: 88\n",
      "index_count: 47\n",
      "thr: 1.152571192449222\n",
      "graph_5_11/2019-05-11 12:16:36.422369171~2019-05-11 12:32:11.330592128.txt    2.938751329459979  count: 6478  percentage: 0.03929299301242236  node count: 171  edge count: 189\n",
      "index_count: 48\n",
      "thr: 1.5936679683652297\n",
      "graph_5_11/2019-05-11 12:32:11.330592128~2019-05-11 12:47:47.220351426.txt    3.470677823468411  count: 5261  percentage: 0.04893043154761905  node count: 132  edge count: 150\n",
      "index_count: 49\n",
      "thr: 1.8261089697407218\n",
      "graph_5_11/2019-05-11 12:47:47.220351426~2019-05-11 13:03:23.643575678.txt    3.591601258490283  count: 4580  percentage: 0.06881009615384616  node count: 63  edge count: 72\n",
      "index_count: 50\n",
      "thr: 1.7265344340313875\n",
      "graph_5_11/2019-05-11 13:03:23.643575678~2019-05-11 13:18:29.629091674.txt    3.5556269791402357  count: 4732  percentage: 0.059244791666666664  node count: 76  edge count: 86\n",
      "index_count: 51\n",
      "thr: 1.8891507796444873\n",
      "graph_5_11/2019-05-11 13:18:29.629091674~2019-05-11 13:33:41.349874830.txt    3.7045743114121485  count: 5107  percentage: 0.06649739583333333  node count: 115  edge count: 126\n",
      "index_count: 52\n",
      "thr: 1.9222862266732312\n",
      "graph_5_11/2019-05-11 13:33:41.349874830~2019-05-11 13:48:47.890783419.txt    3.489661880391063  count: 4334  percentage: 0.07837818287037036  node count: 83  edge count: 89\n",
      "index_count: 53\n",
      "thr: 2.832084706398197\n",
      "graph_5_11/2019-05-11 13:48:47.890783419~2019-05-11 14:04:31.519639837.txt    3.8429279758916044  count: 3199  percentage: 0.13582710597826086  node count: 47  edge count: 46\n",
      "index_count: 54\n",
      "thr: 1.8398494200701312\n",
      "graph_5_11/2019-05-11 14:04:31.519639837~2019-05-11 14:19:36.223542340.txt    3.4652681920839394  count: 4462  percentage: 0.07644599780701754  node count: 65  edge count: 72\n",
      "index_count: 55\n",
      "thr: 3.2890503897854435\n",
      "graph_5_11/2019-05-11 14:19:36.223542340~2019-05-11 14:34:58.512935630.txt    4.200361413868848  count: 2416  percentage: 0.13878676470588236  node count: 45  edge count: 41\n",
      "index_count: 56\n",
      "thr: 2.2715269425925686\n",
      "graph_5_11/2019-05-11 14:34:58.512935630~2019-05-11 14:50:01.493772506.txt    3.5674773903526753  count: 4244  percentage: 0.11201435810810811  node count: 67  edge count: 72\n",
      "index_count: 57\n",
      "thr: 2.0237931863973566\n",
      "graph_5_11/2019-05-11 14:50:01.493772506~2019-05-11 15:05:01.505056736.txt    3.5040792906993747  count: 4285  percentage: 0.08903341090425532  node count: 59  edge count: 60\n",
      "index_count: 58\n",
      "thr: 3.276972607703995\n",
      "graph_5_11/2019-05-11 15:05:01.505056736~2019-05-11 15:20:31.495771178.txt    4.163600187078302  count: 2434  percentage: 0.13982077205882354  node count: 39  edge count: 35\n",
      "index_count: 59\n",
      "thr: 2.2222825529265724\n",
      "graph_5_11/2019-05-11 15:20:31.495771178~2019-05-11 15:37:25.002879746.txt    3.5441837346060034  count: 4732  percentage: 0.11270960365853659  node count: 72  edge count: 77\n",
      "index_count: 60\n",
      "thr: 2.6668488600127107\n",
      "graph_5_11/2019-05-11 15:37:25.002879746~2019-05-11 15:52:31.494545785.txt    3.8721584914991514  count: 3396  percentage: 0.11844308035714286  node count: 60  edge count: 59\n",
      "index_count: 61\n",
      "thr: 2.7219827132551777\n",
      "graph_5_11/2019-05-11 15:52:31.494545785~2019-05-11 16:08:01.493484725.txt    3.772435891993572  count: 3198  percentage: 0.130126953125  node count: 47  edge count: 45\n",
      "index_count: 62\n",
      "thr: 2.107076190946117\n",
      "graph_5_11/2019-05-11 16:08:01.493484725~2019-05-11 16:23:41.450431419.txt    3.5191208064516357  count: 4497  percentage: 0.09980912642045454  node count: 61  edge count: 63\n",
      "index_count: 63\n",
      "thr: 2.7515481004198574\n",
      "graph_5_11/2019-05-11 16:23:41.450431419~2019-05-11 16:39:13.198252375.txt    3.7442137898139234  count: 3180  percentage: 0.13502038043478262  node count: 59  edge count: 57\n",
      "index_count: 64\n",
      "thr: 2.8872771615440938\n",
      "graph_5_11/2019-05-11 16:39:13.198252375~2019-05-11 16:55:01.500153909.txt    3.9532985989252727  count: 2850  percentage: 0.12650923295454544  node count: 48  edge count: 49\n",
      "index_count: 65\n",
      "thr: 2.7570558977182547\n",
      "graph_5_11/2019-05-11 16:55:01.500153909~2019-05-11 17:11:03.959014293.txt    3.7910500680183876  count: 3675  percentage: 0.1380333533653846  node count: 50  edge count: 47\n",
      "index_count: 66\n",
      "thr: 4.088416998098429\n",
      "graph_5_11/2019-05-11 17:11:03.959014293~2019-05-11 17:27:33.517836395.txt    5.687543395062588  count: 331  percentage: 0.029385653409090908  node count: 11  edge count: 9\n",
      "index_count: 67\n",
      "thr: 2.2188349080787715\n",
      "graph_5_11/2019-05-11 17:27:33.517836395~2019-05-11 17:43:31.490443808.txt    3.531216134416296  count: 4559  percentage: 0.1085889862804878  node count: 70  edge count: 74\n",
      "index_count: 68\n",
      "thr: 3.381201753413965\n",
      "graph_5_11/2019-05-11 17:43:31.490443808~2019-05-11 17:59:31.493502219.txt    4.099529130379809  count: 2474  percentage: 0.1510009765625  node count: 36  edge count: 32\n",
      "index_count: 69\n",
      "thr: 2.679266612246174\n",
      "graph_5_11/2019-05-11 17:59:31.493502219~2019-05-11 18:15:44.708305071.txt    3.893884252704307  count: 3617  percentage: 0.12180091594827586  node count: 53  edge count: 47\n",
      "index_count: 70\n",
      "thr: 1.7851513586929917\n",
      "graph_5_11/2019-05-11 18:15:44.708305071~2019-05-11 18:32:01.493784231.txt    3.443880910590134  count: 4932  percentage: 0.07525634765625  node count: 75  edge count: 86\n",
      "index_count: 71\n",
      "thr: 2.2346773316702433\n",
      "graph_5_11/2019-05-11 18:32:01.493784231~2019-05-11 18:47:13.969095860.txt    3.4794363230431724  count: 4243  percentage: 0.11198796452702703  node count: 73  edge count: 76\n",
      "index_count: 72\n",
      "thr: 2.3387968523710825\n",
      "graph_5_11/2019-05-11 18:47:13.969095860~2019-05-11 19:03:42.787479327.txt    3.5251902603857928  count: 4668  percentage: 0.12320523648648649  node count: 55  edge count: 55\n",
      "index_count: 73\n",
      "thr: 3.274242353535804\n",
      "graph_5_11/2019-05-11 19:03:42.787479327~2019-05-11 19:19:45.328437923.txt    4.299113724009555  count: 2479  percentage: 0.12741570723684212  node count: 39  edge count: 35\n",
      "index_count: 74\n",
      "thr: 2.863821522271876\n",
      "graph_5_11/2019-05-11 19:19:45.328437923~2019-05-11 19:36:04.866440471.txt    3.9915013171387237  count: 2957  percentage: 0.12555197010869565  node count: 44  edge count: 43\n",
      "index_count: 75\n",
      "thr: 1.9361521029100082\n",
      "graph_5_11/2019-05-11 19:36:04.866440471~2019-05-11 19:51:40.042976171.txt    3.5386006171874715  count: 4577  percentage: 0.07981654575892858  node count: 71  edge count: 74\n",
      "index_count: 76\n",
      "thr: 2.1447999611177253\n",
      "graph_5_11/2019-05-11 19:51:40.042976171~2019-05-11 20:07:24.862800224.txt    3.531441635592005  count: 4377  percentage: 0.10425400152439024  node count: 51  edge count: 53\n",
      "index_count: 77\n",
      "thr: 2.1561321455736113\n",
      "graph_5_11/2019-05-11 20:07:24.862800224~2019-05-11 20:24:01.506044420.txt    3.445159697491618  count: 4648  percentage: 0.10807291666666667  node count: 57  edge count: 60\n",
      "index_count: 78\n",
      "thr: 4.0499533843274715\n",
      "graph_5_11/2019-05-11 20:24:01.506044420~2019-05-11 20:39:47.303979026.txt    4.8251182719714745  count: 723  percentage: 0.06418678977272728  node count: 20  edge count: 18\n",
      "index_count: 79\n",
      "thr: 2.412871271772591\n",
      "graph_5_11/2019-05-11 20:39:47.303979026~2019-05-11 20:55:01.495228602.txt    3.6809402292825815  count: 3677  percentage: 0.112213134765625  node count: 62  edge count: 62\n",
      "index_count: 80\n",
      "thr: 3.8625132250244203\n",
      "graph_5_11/2019-05-11 20:55:01.495228602~2019-05-11 21:11:31.496595479.txt    4.430185374045731  count: 1527  percentage: 0.11470853365384616  node count: 16  edge count: 13\n",
      "index_count: 81\n",
      "thr: 4.159008443370673\n",
      "graph_5_11/2019-05-11 21:11:31.496595479~2019-05-11 21:28:01.492916934.txt    6.853395133602376  count: 196  percentage: 0.01740056818181818  node count: 11  edge count: 9\n",
      "index_count: 82\n",
      "thr: 2.059860767587985\n",
      "graph_5_11/2019-05-11 21:28:01.492916934~2019-05-11 21:44:43.279039868.txt    3.528838877243513  count: 4731  percentage: 0.09428810586734694  node count: 74  edge count: 76\n",
      "index_count: 83\n",
      "thr: 3.055323832032634\n",
      "graph_5_11/2019-05-11 21:44:43.279039868~2019-05-11 21:59:49.871208266.txt    5.547534096607494  count: 4261  percentage: 0.08002178485576923  node count: 1619  edge count: 1617\n",
      "index_count: 84\n",
      "thr: 3.267897191468274\n",
      "graph_5_11/2019-05-11 21:59:49.871208266~2019-05-11 22:15:17.913406650.txt    4.219647121645651  count: 2426  percentage: 0.1316189236111111  node count: 35  edge count: 30\n",
      "index_count: 85\n",
      "thr: 2.839566405331892\n",
      "graph_5_11/2019-05-11 22:15:17.913406650~2019-05-11 22:30:29.105231854.txt    4.0632023548313105  count: 2674  percentage: 0.11869673295454546  node count: 43  edge count: 41\n",
      "index_count: 86\n",
      "thr: 2.837144738480258\n",
      "graph_5_11/2019-05-11 22:30:29.105231854~2019-05-11 22:45:41.943179151.txt    3.769379872395849  count: 2883  percentage: 0.13406808035714285  node count: 53  edge count: 48\n",
      "index_count: 87\n",
      "thr: 3.8821085006045717\n",
      "graph_5_11/2019-05-11 22:45:41.943179151~2019-05-11 23:02:31.492113855.txt    4.461165798572172  count: 1660  percentage: 0.12469951923076923  node count: 18  edge count: 15\n",
      "index_count: 88\n",
      "thr: 2.055491776755359\n",
      "graph_5_11/2019-05-11 23:02:31.492113855~2019-05-11 23:17:43.542872267.txt    3.5586798941607967  count: 4460  percentage: 0.08888711734693877  node count: 58  edge count: 63\n",
      "index_count: 89\n",
      "thr: 2.5283773919374295\n",
      "graph_5_11/2019-05-11 23:17:43.542872267~2019-05-11 23:33:01.508230259.txt    3.7412277367260334  count: 3544  percentage: 0.11934267241379311  node count: 57  edge count: 55\n",
      "index_count: 90\n",
      "thr: 2.2271376202340845\n",
      "graph_5_11/2019-05-11 23:33:01.508230259~2019-05-11 23:48:02.369685328.txt    3.5368833094557792  count: 4296  percentage: 0.10757211538461539  node count: 67  edge count: 68\n"
     ]
    }
   ],
   "source": [
    "# Variable names don't change the results\n",
    "\n",
    "# node_IDF=torch.load(\"node_IDF_5_9\")\n",
    "y_data_5_14=[]\n",
    "df_list_5_14=[]\n",
    "# node_set_list=[]\n",
    "\n",
    "# list of time window queues\n",
    "# It is a list (collection of queues) of list (queue) of dictionary (time window)\n",
    "history_list_5_14=[]\n",
    "\n",
    "tw_que=[]\n",
    "his_tw={}\n",
    "\n",
    "# Stores data for the currentl procesing time window\n",
    "current_tw={}\n",
    "loss_list_5_14=[]\n",
    "\n",
    "\n",
    "file_path_list=[]\n",
    "file_path=\"graph_5_11/\"\n",
    "file_l=os.listdir(\"graph_5_11/\")\n",
    "for i in file_l:\n",
    "    file_path_list.append(file_path+i)\n",
    "    \n",
    "    \n",
    "index_count=0\n",
    "for f_path in sorted(file_path_list):\n",
    "    f=open(f_path)\n",
    "\n",
    "    # List to store loss values for edges\n",
    "    edge_loss_list=[]\n",
    "\n",
    "    # List to store edges (source-destination pairs)\n",
    "    edge_list=[]\n",
    "\n",
    "    print('index_count:',index_count)\n",
    "    \n",
    "    for line in f:\n",
    "        l=line.strip()\n",
    "        jdata=eval(l)\n",
    "        edge_loss_list.append(jdata['loss'])\n",
    "        edge_list.append([str(jdata['srcmsg']),str(jdata['dstmsg'])])\n",
    "    df_list_5_14.append(pd.DataFrame(edge_loss_list))\n",
    "    \n",
    "    # Calculate anomaly loss metrics for the current time window\n",
    "    count,loss_avg,node_set,edge_set=cal_anomaly_loss(edge_loss_list,edge_list,\"graph_5_14/\")\n",
    "    current_tw['name']=f_path\n",
    "    current_tw['loss']=loss_avg\n",
    "    current_tw['index']=index_count\n",
    "    current_tw['nodeset']=node_set\n",
    "\n",
    "    # To check if the current time window is related to any historical time window\n",
    "    added_que_flag=False\n",
    "    \n",
    "    # For each queues \n",
    "    for hq in history_list_5_14:\n",
    "        # For each time window in a queue\n",
    "        for his_tw in hq:\n",
    "            # Calculate relvance between two time windows and if related push the current time window in the current queue and move on to check the next queue\n",
    "            if cal_set_rel(current_tw['nodeset'],his_tw['nodeset'],file_list)!=0 and current_tw['name']!=his_tw['name']:\n",
    "                print(\"history queue:\",his_tw['name'])\n",
    "                hq.append(copy.deepcopy(current_tw))\n",
    "                added_que_flag=True\n",
    "                break\n",
    "            if added_que_flag:\n",
    "                break\n",
    "            \n",
    "    # If not time window on any of the queues is similar, create a new queue with the current time window and add to the list\n",
    "    if added_que_flag is False:\n",
    "        temp_hq=[copy.deepcopy(current_tw)]\n",
    "        history_list_5_14.append(temp_hq)\n",
    "    index_count+=1\n",
    "    loss_list_5_14.append(loss_avg)\n",
    "    print( f_path,\"  \",loss_avg,\" count:\",count,\" percentage:\",count/len(edge_list),\" node count:\",len(node_set),\" edge count:\",len(edge_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['graph_5_11/2019-05-11 01:47:38.109830109~2019-05-11 02:03:11.829718951.txt']\n",
      "8.260935078199513\n",
      "['graph_5_11/2019-05-11 05:45:26.427321308~2019-05-11 06:00:32.541397033.txt']\n",
      "5.703771928552858\n",
      "['graph_5_11/2019-05-11 07:50:01.504859344~2019-05-11 08:05:27.045713282.txt']\n",
      "5.540749057518473\n",
      "['graph_5_11/2019-05-11 09:39:28.743031655~2019-05-11 09:55:12.543113845.txt']\n",
      "5.01482287867678\n",
      "['graph_5_11/2019-05-11 10:10:40.816335674~2019-05-11 10:26:38.131479341.txt']\n",
      "6.653324832366889\n",
      "['graph_5_11/2019-05-11 14:19:36.223542340~2019-05-11 14:34:58.512935630.txt']\n",
      "5.200361413868848\n",
      "['graph_5_11/2019-05-11 15:05:01.505056736~2019-05-11 15:20:31.495771178.txt']\n",
      "5.163600187078302\n",
      "['graph_5_11/2019-05-11 17:11:03.959014293~2019-05-11 17:27:33.517836395.txt']\n",
      "6.687543395062588\n",
      "['graph_5_11/2019-05-11 17:43:31.490443808~2019-05-11 17:59:31.493502219.txt']\n",
      "5.099529130379809\n",
      "['graph_5_11/2019-05-11 19:03:42.787479327~2019-05-11 19:19:45.328437923.txt']\n",
      "5.299113724009555\n",
      "['graph_5_11/2019-05-11 20:24:01.506044420~2019-05-11 20:39:47.303979026.txt']\n",
      "5.8251182719714745\n",
      "['graph_5_11/2019-05-11 20:55:01.495228602~2019-05-11 21:11:31.496595479.txt']\n",
      "5.430185374045731\n",
      "['graph_5_11/2019-05-11 21:11:31.496595479~2019-05-11 21:28:01.492916934.txt']\n",
      "7.853395133602376\n",
      "['graph_5_11/2019-05-11 21:44:43.279039868~2019-05-11 21:59:49.871208266.txt']\n",
      "6.547534096607494\n",
      "['graph_5_11/2019-05-11 21:59:49.871208266~2019-05-11 22:15:17.913406650.txt']\n",
      "5.219647121645651\n",
      "['graph_5_11/2019-05-11 22:15:17.913406650~2019-05-11 22:30:29.105231854.txt']\n",
      "5.0632023548313105\n",
      "['graph_5_11/2019-05-11 22:45:41.943179151~2019-05-11 23:02:31.492113855.txt']\n",
      "5.461165798572172\n"
     ]
    }
   ],
   "source": [
    "# Store the anomalous time window file path name\n",
    "name_list=[]\n",
    "\n",
    "# For each queue\n",
    "for hl in history_list_5_14:\n",
    "    # Calculate loss for each queue\n",
    "    loss_count=0\n",
    "    for hq in hl:\n",
    "        if loss_count==0:\n",
    "            loss_count=(loss_count+1)*(hq['loss']+1)\n",
    "        else:\n",
    "            loss_count=(loss_count)*(hq['loss']+1)\n",
    "\n",
    "    # If loss count is greater than 9 then it is anamalous queue\n",
    "    if loss_count>5:\n",
    "        name_list=[]\n",
    "        for i in hl:\n",
    "            name_list.append(i['name']) \n",
    "        print(name_list)\n",
    "        print(loss_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_count: 0\n",
      "thr: 1.0992022639441434\n",
      "graph_5_14/2019-05-14 00:00:00.216652068~2019-05-14 00:15:02.152576344.txt    2.2715391591619443  count: 9919  percentage: 0.054114656075418995  node count: 484  edge count: 554\n",
      "index_count: 1\n",
      "thr: 1.6962835574304205\n",
      "graph_5_14/2019-05-14 00:15:02.152576344~2019-05-14 00:30:52.456495816.txt    3.3969684547659287  count: 5049  percentage: 0.06403459821428571  node count: 90  edge count: 94\n",
      "index_count: 2\n",
      "thr: 1.5208833027290787\n",
      "graph_5_14/2019-05-14 00:30:52.456495816~2019-05-14 00:46:31.488675323.txt    3.3382268749424404  count: 4948  percentage: 0.053099244505494504  node count: 101  edge count: 111\n",
      "index_count: 3\n",
      "thr: 1.199508745825513\n",
      "graph_5_14/2019-05-14 00:46:31.488675323~2019-05-14 01:02:22.766494572.txt    3.12558900028578  count: 5647  percentage: 0.042420372596153846  node count: 123  edge count: 134\n",
      "index_count: 4\n",
      "thr: 1.1171231469970961\n",
      "graph_5_14/2019-05-14 01:02:22.766494572~2019-05-14 01:18:47.800927242.txt    2.607708723288659  count: 7485  percentage: 0.05041082974137931  node count: 78  edge count: 89\n",
      "index_count: 5\n",
      "thr: 1.541653497392334\n",
      "graph_5_14/2019-05-14 01:18:47.800927242~2019-05-14 01:33:57.109874818.txt    3.366090022434722  count: 5196  percentage: 0.0507421875  node count: 97  edge count: 111\n",
      "index_count: 6\n",
      "thr: 0.8930645884623287\n",
      "graph_5_14/2019-05-14 01:33:57.109874818~2019-05-14 01:49:42.711286391.txt    2.0513436525782334  count: 13304  percentage: 0.04607158687943262  node count: 132  edge count: 162\n",
      "index_count: 7\n",
      "thr: 0.9427575195642277\n",
      "graph_5_14/2019-05-14 01:49:42.711286391~2019-05-14 02:04:42.847148244.txt    2.0360702406360196  count: 12280  percentage: 0.05103058510638298  node count: 278  edge count: 305\n",
      "index_count: 8\n",
      "thr: 1.9355664643744905\n",
      "graph_5_14/2019-05-14 02:04:42.847148244~2019-05-14 02:21:17.881023437.txt    3.446722854271768  count: 5040  percentage: 0.087890625  node count: 67  edge count: 71\n",
      "index_count: 9\n",
      "thr: 1.1982017580339952\n",
      "graph_5_14/2019-05-14 02:21:17.881023437~2019-05-14 02:37:08.796215519.txt    2.764805773422122  count: 8000  percentage: 0.05073051948051948  node count: 1134  edge count: 1153\n",
      "index_count: 10\n",
      "thr: 0.8434184570811832\n",
      "graph_5_14/2019-05-14 02:37:08.796215519~2019-05-14 02:53:02.686777403.txt    2.257483956196583  count: 9989  percentage: 0.03695031368371212  node count: 110  edge count: 123\n",
      "index_count: 11\n",
      "thr: 1.6813601740021609\n",
      "graph_5_14/2019-05-14 02:53:02.686777403~2019-05-14 03:08:06.039823042.txt    4.121026490635867  count: 6463  percentage: 0.042935533588435375  node count: 1133  edge count: 1151\n",
      "index_count: 12\n",
      "thr: 1.802660803489022\n",
      "graph_5_14/2019-05-14 03:08:06.039823042~2019-05-14 03:24:24.125824282.txt    3.3958058167654688  count: 4848  percentage: 0.07636088709677419  node count: 74  edge count: 82\n",
      "index_count: 13\n",
      "thr: 2.057297176258465\n",
      "graph_5_14/2019-05-14 03:24:24.125824282~2019-05-14 03:40:31.492266909.txt    3.488155079156959  count: 4963  percentage: 0.0897533275462963  node count: 95  edge count: 103\n",
      "index_count: 14\n",
      "thr: 1.4910529375294623\n",
      "graph_5_14/2019-05-14 03:40:31.492266909~2019-05-14 03:55:39.463370919.txt    3.404186669624213  count: 5016  percentage: 0.045355902777777776  node count: 98  edge count: 114\n",
      "index_count: 15\n",
      "thr: 1.0098383099483843\n",
      "graph_5_14/2019-05-14 03:55:39.463370919~2019-05-14 04:11:20.402783947.txt    1.9672165716296737  count: 13894  percentage: 0.06195597888127854  node count: 105  edge count: 119\n",
      "index_count: 16\n",
      "thr: 1.4622641989108718\n",
      "graph_5_14/2019-05-14 04:11:20.402783947~2019-05-14 04:27:29.028367610.txt    3.406429308613625  count: 5011  percentage: 0.04531069155092592  node count: 87  edge count: 96\n",
      "index_count: 17\n",
      "thr: 1.5153837087743993\n",
      "graph_5_14/2019-05-14 04:27:29.028367610~2019-05-14 04:42:31.507049782.txt    3.3715392193934344  count: 4595  percentage: 0.05609130859375  node count: 115  edge count: 126\n",
      "index_count: 18\n",
      "thr: 2.0955848243913224\n",
      "graph_5_14/2019-05-14 04:42:31.507049782~2019-05-14 04:57:54.101068941.txt    3.5175450050708803  count: 4591  percentage: 0.09340413411458333  node count: 68  edge count: 72\n",
      "index_count: 19\n",
      "thr: 0.9360286749151364\n",
      "graph_5_14/2019-05-14 04:57:54.101068941~2019-05-14 05:13:31.492618479.txt    2.183267661923712  count: 11000  percentage: 0.045135241596638655  node count: 99  edge count: 120\n",
      "index_count: 20\n",
      "thr: 1.6047773083085142\n",
      "graph_5_14/2019-05-14 05:13:31.492618479~2019-05-14 05:29:31.505968490.txt    3.4343075854876486  count: 5123  percentage: 0.056212693117977525  node count: 80  edge count: 92\n",
      "index_count: 21\n",
      "thr: 1.4271969593502212\n",
      "graph_5_14/2019-05-14 05:29:31.505968490~2019-05-14 05:44:42.157151223.txt    3.9771559574034123  count: 5861  percentage: 0.035772705078125  node count: 1067  edge count: 1080\n",
      "index_count: 22\n",
      "thr: 2.029663665913165\n",
      "graph_5_14/2019-05-14 05:44:42.157151223~2019-05-14 05:59:43.139781502.txt    3.516935014023344  count: 4487  percentage: 0.09323055186170212  node count: 77  edge count: 84\n",
      "index_count: 23\n",
      "thr: 1.9594174155982407\n",
      "graph_5_14/2019-05-14 05:59:43.139781502~2019-05-14 06:14:50.863134060.txt    4.146399908266843  count: 5882  percentage: 0.05744140625  node count: 1197  edge count: 1206\n",
      "index_count: 24\n",
      "thr: 1.4737280817378546\n",
      "graph_5_14/2019-05-14 06:14:50.863134060~2019-05-14 06:30:25.403853123.txt    3.4417185078234582  count: 5026  percentage: 0.045871057242990655  node count: 98  edge count: 110\n",
      "index_count: 25\n",
      "thr: 1.65384973914959\n",
      "graph_5_14/2019-05-14 06:30:25.403853123~2019-05-14 06:45:43.292845666.txt    3.3962657081384195  count: 4894  percentage: 0.060497428797468354  node count: 115  edge count: 132\n",
      "index_count: 26\n",
      "thr: 1.0946658119117454\n",
      "graph_5_14/2019-05-14 06:45:43.292845666~2019-05-14 07:00:48.956786874.txt    2.5739369417580082  count: 7526  percentage: 0.04651651503164557  node count: 88  edge count: 100\n",
      "index_count: 27\n",
      "thr: 1.597900860011341\n",
      "graph_5_14/2019-05-14 07:00:48.956786874~2019-05-14 07:15:55.106970028.txt    3.444293217778843  count: 5053  percentage: 0.056074662642045456  node count: 87  edge count: 99\n",
      "index_count: 28\n",
      "thr: 1.5971138113714378\n",
      "graph_5_14/2019-05-14 07:15:55.106970028~2019-05-14 07:31:06.351388922.txt    3.440675196681261  count: 4539  percentage: 0.05094962284482758  node count: 102  edge count: 110\n",
      "index_count: 29\n",
      "thr: 1.96452110593392\n",
      "graph_5_14/2019-05-14 07:31:06.351388922~2019-05-14 07:46:06.406187653.txt    4.142800956392152  count: 8071  percentage: 0.06109950339147287  node count: 435  edge count: 463\n",
      "index_count: 30\n",
      "thr: 3.396155315713163\n",
      "graph_5_14/2019-05-14 07:46:06.406187653~2019-05-14 08:01:28.100458703.txt    5.5998626596683  count: 26869  percentage: 0.10933024088541667  node count: 740  edge count: 742\n",
      "index_count: 31\n",
      "thr: 2.9164002226929795\n",
      "graph_5_14/2019-05-14 08:01:28.100458703~2019-05-14 08:16:28.839199678.txt    5.822103423737506  count: 7293  percentage: 0.062474300986842105  node count: 398  edge count: 532\n",
      "index_count: 32\n",
      "thr: 9.432991417790054\n",
      "graph_5_14/2019-05-14 08:16:28.839199678~2019-05-14 08:31:32.729512360.txt    10.252709728885609  count: 19735  percentage: 0.19868516430412372  node count: 226  edge count: 329\n",
      "index_count: 33\n",
      "thr: 0.901372399841262\n",
      "graph_5_14/2019-05-14 08:31:32.729512360~2019-05-14 08:46:44.052873581.txt    2.0603751543354956  count: 13346  percentage: 0.045891560299295774  node count: 136  edge count: 165\n",
      "index_count: 34\n",
      "thr: 1.7558123878224516\n",
      "graph_5_14/2019-05-14 08:46:44.052873581~2019-05-14 09:02:14.558261420.txt    3.5006934271718837  count: 4646  percentage: 0.06390294894366197  node count: 80  edge count: 87\n",
      "index_count: 35\n",
      "thr: 2.578426061217417\n",
      "graph_5_14/2019-05-14 09:02:14.558261420~2019-05-14 09:17:20.971655668.txt    5.762763512472031  count: 9608  percentage: 0.050445228494623656  node count: 522  edge count: 831\n",
      "index_count: 36\n",
      "thr: 9.814271260495032\n",
      "graph_5_14/2019-05-14 09:17:20.971655668~2019-05-14 09:32:31.497798481.txt    10.52765499697875  count: 38521  percentage: 0.1835032393292683  node count: 204  edge count: 337\n",
      "index_count: 37\n",
      "thr: 1.800432683017212\n",
      "graph_5_14/2019-05-14 09:32:31.497798481~2019-05-14 09:49:09.590528813.txt    3.4272317290419645  count: 5249  percentage: 0.0692699535472973  node count: 100  edge count: 113\n",
      "index_count: 38\n",
      "thr: 1.7872549464898104\n",
      "graph_5_14/2019-05-14 09:49:09.590528813~2019-05-14 10:05:01.487422951.txt    3.473341881879995  count: 4784  percentage: 0.06399828767123288  node count: 97  edge count: 119\n",
      "index_count: 39\n",
      "thr: 1.9327027181575185\n",
      "graph_5_14/2019-05-14 10:05:01.487422951~2019-05-14 10:21:01.484905000.txt    3.5530624519930307  count: 4328  percentage: 0.07163665254237288  node count: 68  edge count: 74\n",
      "index_count: 40\n",
      "thr: 1.6161169913118143\n",
      "graph_5_14/2019-05-14 10:21:01.484905000~2019-05-14 10:37:26.048664593.txt    3.472175355001732  count: 5400  percentage: 0.048828125  node count: 105  edge count: 123\n",
      "index_count: 41\n",
      "thr: 1.809330042022495\n",
      "graph_5_14/2019-05-14 10:37:26.048664593~2019-05-14 10:53:01.494421034.txt    3.4201719305899334  count: 4923  percentage: 0.07175548041044776  node count: 198  edge count: 211\n",
      "index_count: 42\n",
      "thr: 1.4716773527064126\n",
      "graph_5_14/2019-05-14 10:53:01.494421034~2019-05-14 11:08:27.055236406.txt    3.2877455956343424  count: 5815  percentage: 0.046168381605691054  node count: 127  edge count: 147\n",
      "index_count: 43\n",
      "thr: 1.4300426658798293\n",
      "graph_5_14/2019-05-14 11:08:27.055236406~2019-05-14 11:24:01.496118837.txt    2.7668242769906506  count: 6165  percentage: 0.05902458639705882  node count: 225  edge count: 255\n",
      "index_count: 44\n",
      "thr: 1.26193150532161\n",
      "graph_5_14/2019-05-14 11:24:01.496118837~2019-05-14 11:40:15.252528842.txt    3.1475279835194914  count: 2169  percentage: 0.029833296654929578  node count: 82  edge count: 93\n",
      "index_count: 45\n",
      "thr: 1.3959607942743688\n",
      "graph_5_14/2019-05-14 11:40:15.252528842~2019-05-14 11:55:25.711738425.txt    4.257079296258367  count: 2314  percentage: 0.02378700657894737  node count: 583  edge count: 595\n",
      "index_count: 46\n",
      "thr: 0.9866237743431794\n",
      "graph_5_14/2019-05-14 11:55:25.711738425~2019-05-14 12:10:32.440531011.txt    1.7435882111677137  count: 9286  percentage: 0.06341510052447552  node count: 149  edge count: 179\n",
      "index_count: 47\n",
      "thr: 1.211892525776759\n",
      "graph_5_14/2019-05-14 12:10:32.440531011~2019-05-14 12:26:47.026847931.txt    2.668464325515438  count: 2787  percentage: 0.03833351672535211  node count: 85  edge count: 98\n",
      "index_count: 48\n",
      "thr: 0.6657023677421462\n",
      "graph_5_14/2019-05-14 12:26:47.026847931~2019-05-14 12:43:01.495215198.txt    1.491844975181904  count: 30330  percentage: 0.041717099471830985  node count: 219  edge count: 271\n",
      "index_count: 49\n",
      "thr: 1.050948185773845\n",
      "graph_5_14/2019-05-14 12:43:01.495215198~2019-05-14 12:59:29.343065601.txt    1.9684286493680536  count: 4266  percentage: 0.0586762764084507  node count: 101  edge count: 113\n",
      "index_count: 50\n",
      "thr: 0.9968060009050023\n",
      "graph_5_14/2019-05-14 12:59:29.343065601~2019-05-14 13:14:36.494846495.txt    1.6421700743942431  count: 8773  percentage: 0.07449898097826087  node count: 103  edge count: 123\n",
      "index_count: 51\n",
      "thr: 0.7558285618565947\n",
      "graph_5_14/2019-05-14 13:14:36.494846495~2019-05-14 13:31:01.488594793.txt    1.6239399587734453  count: 10338  percentage: 0.04673936631944445  node count: 125  edge count: 155\n",
      "index_count: 52\n",
      "thr: 0.9934575585008696\n",
      "graph_5_14/2019-05-14 13:31:01.488594793~2019-05-14 13:46:56.649368141.txt    1.6951103903898093  count: 10146  percentage: 0.06649800755033557  node count: 117  edge count: 140\n",
      "index_count: 53\n",
      "thr: 0.7253446256898012\n",
      "graph_5_14/2019-05-14 13:46:56.649368141~2019-05-14 14:01:56.861865565.txt    1.5821114935395295  count: 9852  percentage: 0.04433683755760369  node count: 93  edge count: 114\n",
      "index_count: 54\n",
      "thr: 0.6115241937959699\n",
      "graph_5_14/2019-05-14 14:01:56.861865565~2019-05-14 14:18:12.441876858.txt    1.499631320543632  count: 14831  percentage: 0.03602835432213931  node count: 136  edge count: 176\n",
      "index_count: 55\n",
      "thr: 1.2843512739001952\n",
      "graph_5_14/2019-05-14 14:18:12.441876858~2019-05-14 14:33:35.665615598.txt    2.921702010815658  count: 2629  percentage: 0.03291516426282051  node count: 85  edge count: 104\n",
      "index_count: 56\n",
      "thr: 0.9767597159674019\n",
      "graph_5_14/2019-05-14 14:33:35.665615598~2019-05-14 14:49:05.595227210.txt    1.6423286728037065  count: 11122  percentage: 0.06962389823717949  node count: 123  edge count: 153\n",
      "index_count: 57\n",
      "thr: 0.6138559408401707\n",
      "graph_5_14/2019-05-14 14:49:05.595227210~2019-05-14 15:04:31.495739830.txt    1.7825866861579318  count: 4224  percentage: 0.02610759493670886  node count: 89  edge count: 106\n",
      "index_count: 58\n",
      "thr: 0.5922163658450897\n",
      "graph_5_14/2019-05-14 15:04:31.495739830~2019-05-14 15:19:40.210880344.txt    1.6959343447703146  count: 7990  percentage: 0.026449947033898306  node count: 106  edge count: 127\n",
      "index_count: 59\n",
      "thr: 0.7514590552370828\n",
      "graph_5_14/2019-05-14 15:19:40.210880344~2019-05-14 15:35:01.495871430.txt    1.601873901805468  count: 8892  percentage: 0.04643633021390375  node count: 93  edge count: 115\n",
      "index_count: 60\n",
      "thr: 1.0811706144864144\n",
      "graph_5_14/2019-05-14 15:35:01.495871430~2019-05-14 15:50:01.496409854.txt    1.6816036424190322  count: 9248  percentage: 0.07853260869565218  node count: 98  edge count: 118\n",
      "index_count: 61\n",
      "thr: 1.0603899629832079\n",
      "graph_5_14/2019-05-14 15:50:01.496409854~2019-05-14 16:07:01.495577354.txt    1.779914621146039  count: 7501  percentage: 0.06845976927570094  node count: 82  edge count: 99\n",
      "index_count: 62\n",
      "thr: 0.7283127047440224\n",
      "graph_5_14/2019-05-14 16:07:01.495577354~2019-05-14 16:22:09.008166964.txt    1.6234951455003384  count: 9242  percentage: 0.042774363151658765  node count: 127  edge count: 156\n",
      "index_count: 63\n",
      "thr: 0.701616198811975\n",
      "graph_5_14/2019-05-14 16:22:09.008166964~2019-05-14 16:37:48.629717740.txt    1.5870965681583584  count: 8963  percentage: 0.04128740418632076  node count: 99  edge count: 126\n",
      "index_count: 64\n",
      "thr: 0.652238953010324\n",
      "graph_5_14/2019-05-14 16:37:48.629717740~2019-05-14 16:52:56.416852310.txt    1.655092397919601  count: 5383  percentage: 0.03348303144904458  node count: 76  edge count: 91\n",
      "index_count: 65\n",
      "thr: 1.0583385414344708\n",
      "graph_5_14/2019-05-14 16:52:56.416852310~2019-05-14 17:08:03.416037709.txt    1.9783680726959563  count: 4533  percentage: 0.05824681332236842  node count: 85  edge count: 100\n",
      "index_count: 66\n",
      "thr: 0.7070156786515744\n",
      "graph_5_14/2019-05-14 17:08:03.416037709~2019-05-14 17:23:18.956163567.txt    1.6177356040823174  count: 10733  percentage: 0.0406257570251938  node count: 141  edge count: 180\n",
      "index_count: 67\n",
      "thr: 0.7082390497880179\n",
      "graph_5_14/2019-05-14 17:23:18.956163567~2019-05-14 17:39:05.176280359.txt    1.489377322508632  count: 14106  percentage: 0.048504896566901406  node count: 103  edge count: 124\n",
      "index_count: 68\n",
      "thr: 0.6637983051903507\n",
      "graph_5_14/2019-05-14 17:39:05.176280359~2019-05-14 17:55:18.763900563.txt    2.1752232855949245  count: 3660  percentage: 0.021149223372781065  node count: 82  edge count: 101\n",
      "index_count: 69\n",
      "thr: 1.003750109488742\n",
      "graph_5_14/2019-05-14 17:55:18.763900563~2019-05-14 18:10:19.195011436.txt    1.6262071832518754  count: 8687  percentage: 0.07376868206521739  node count: 103  edge count: 125\n",
      "index_count: 70\n",
      "thr: 0.9999815185650427\n",
      "graph_5_14/2019-05-14 18:10:19.195011436~2019-05-14 18:25:19.291228993.txt    1.4997669782623166  count: 13019  percentage: 0.08590450802364864  node count: 136  edge count: 164\n",
      "index_count: 71\n",
      "thr: 0.9774518324249748\n",
      "graph_5_14/2019-05-14 18:25:19.291228993~2019-05-14 18:40:21.201780869.txt    1.5783456582852657  count: 10437  percentage: 0.07721502130681818  node count: 85  edge count: 108\n",
      "index_count: 72\n",
      "thr: 0.855717624669684\n",
      "graph_5_14/2019-05-14 18:40:21.201780869~2019-05-14 18:56:52.129475445.txt    1.4922862141563635  count: 15512  percentage: 0.06673320484581498  node count: 158  edge count: 194\n",
      "index_count: 73\n",
      "thr: 0.9775298703462327\n",
      "graph_5_14/2019-05-14 18:56:52.129475445~2019-05-14 19:12:10.712408509.txt    1.7876097504894572  count: 6260  percentage: 0.06573420698924731  node count: 92  edge count: 111\n",
      "index_count: 74\n",
      "thr: 1.2918481278913718\n",
      "graph_5_14/2019-05-14 19:12:10.712408509~2019-05-14 19:28:38.128423572.txt    3.562649660977126  count: 1337  percentage: 0.028384001358695652  node count: 76  edge count: 89\n",
      "index_count: 75\n",
      "thr: 0.9440498682839072\n",
      "graph_5_14/2019-05-14 19:28:38.128423572~2019-05-14 19:45:01.500731472.txt    1.584246481162634  count: 10918  percentage: 0.07108072916666666  node count: 85  edge count: 107\n",
      "index_count: 76\n",
      "thr: 0.8203111167839727\n",
      "graph_5_14/2019-05-14 19:45:01.500731472~2019-05-14 20:00:01.564775961.txt    1.5079707192507754  count: 13284  percentage: 0.06033793604651163  node count: 102  edge count: 127\n",
      "index_count: 77\n",
      "thr: 0.9179216301672848\n",
      "graph_5_14/2019-05-14 20:00:01.564775961~2019-05-14 20:15:31.498565817.txt    1.6033290181154083  count: 12145  percentage: 0.06445843240489131  node count: 104  edge count: 127\n",
      "index_count: 78\n",
      "thr: 0.712169251381187\n",
      "graph_5_14/2019-05-14 20:15:31.498565817~2019-05-14 20:30:39.905147822.txt    1.7154205215722322  count: 5600  percentage: 0.035978618421052634  node count: 87  edge count: 102\n",
      "index_count: 79\n",
      "thr: 1.0811730765172953\n",
      "graph_5_14/2019-05-14 20:30:39.905147822~2019-05-14 20:48:29.853305652.txt    1.8359581554383233  count: 6184  percentage: 0.06862571022727272  node count: 66  edge count: 82\n",
      "index_count: 80\n",
      "thr: 1.0463835981900276\n",
      "graph_5_14/2019-05-14 20:48:29.853305652~2019-05-14 21:03:35.529877137.txt    1.8249918199061725  count: 5357  percentage: 0.06883480674342106  node count: 60  edge count: 71\n",
      "index_count: 81\n",
      "thr: 0.694239957998492\n",
      "graph_5_14/2019-05-14 21:03:35.529877137~2019-05-14 21:19:23.539915401.txt    1.6475825619778839  count: 7921  percentage: 0.03683500744047619  node count: 102  edge count: 123\n",
      "index_count: 82\n",
      "thr: 1.071577323224794\n",
      "graph_5_14/2019-05-14 21:19:23.539915401~2019-05-14 21:35:16.383991146.txt    1.7283351282310682  count: 6833  percentage: 0.07414279513888888  node count: 99  edge count: 121\n",
      "index_count: 83\n",
      "thr: 0.9303446383638082\n",
      "graph_5_14/2019-05-14 21:35:16.383991146~2019-05-14 21:52:04.868022874.txt    1.7823368984746577  count: 6821  percentage: 0.05244986466535433  node count: 99  edge count: 123\n",
      "index_count: 84\n",
      "thr: 0.7896112242428096\n",
      "graph_5_14/2019-05-14 21:52:04.868022874~2019-05-14 22:08:01.492103293.txt    1.6417853836807834  count: 7707  percentage: 0.04793864450636943  node count: 81  edge count: 96\n",
      "index_count: 85\n",
      "thr: 1.073004689813434\n",
      "graph_5_14/2019-05-14 22:08:01.492103293~2019-05-14 22:24:09.949262623.txt    1.8881900851679927  count: 3888  percentage: 0.06546336206896551  node count: 66  edge count: 78\n",
      "index_count: 86\n",
      "thr: 0.6472375138225903\n",
      "graph_5_14/2019-05-14 22:24:09.949262623~2019-05-14 22:39:18.367975095.txt    1.70579367128436  count: 6697  percentage: 0.03056093019859813  node count: 78  edge count: 94\n",
      "index_count: 87\n",
      "thr: 0.7075014756746041\n",
      "graph_5_14/2019-05-14 22:39:18.367975095~2019-05-14 22:54:58.932966824.txt    1.5814302260159925  count: 7771  percentage: 0.041020903716216216  node count: 82  edge count: 102\n",
      "index_count: 88\n",
      "thr: 1.1727776616843726\n",
      "graph_5_14/2019-05-14 22:54:58.932966824~2019-05-14 23:11:08.033781569.txt    2.2357219637800383  count: 3725  percentage: 0.044909818672839504  node count: 84  edge count: 99\n",
      "index_count: 89\n",
      "thr: 1.2327643583419912\n",
      "graph_5_14/2019-05-14 23:11:08.033781569~2019-05-14 23:27:10.374817359.txt    2.490779085643765  count: 3189  percentage: 0.03892822265625  node count: 71  edge count: 85\n",
      "index_count: 90\n",
      "thr: 1.4546392104468187\n",
      "graph_5_14/2019-05-14 23:27:10.374817359~2019-05-14 23:42:22.657126844.txt    3.665730471942803  count: 1236  percentage: 0.031763980263157895  node count: 59  edge count: 67\n",
      "index_count: 91\n",
      "thr: 1.4435615437370484\n",
      "graph_5_14/2019-05-14 23:42:22.657126844~2019-05-14 23:57:53.548510363.txt    3.88445722077856  count: 1510  percentage: 0.026811079545454544  node count: 82  edge count: 93\n"
     ]
    }
   ],
   "source": [
    "# 5-14\n",
    "\n",
    "# node_IDF=torch.load(\"node_IDF_5_9\")\n",
    "y_data_5_14=[]\n",
    "df_list_5_14=[]\n",
    "# node_set_list=[]\n",
    "history_list_5_14=[]\n",
    "tw_que=[]\n",
    "his_tw={}\n",
    "current_tw={}\n",
    "loss_list_5_14=[]\n",
    "\n",
    "\n",
    "file_path_list=[]\n",
    "file_path=\"graph_5_14/\"\n",
    "file_l=os.listdir(\"graph_5_14/\")\n",
    "for i in file_l:\n",
    "    file_path_list.append(file_path+i)\n",
    "    \n",
    "    \n",
    "index_count=0\n",
    "for f_path in sorted(file_path_list):\n",
    "    f=open(f_path)\n",
    "    edge_loss_list=[]\n",
    "    edge_list=[]\n",
    "    print('index_count:',index_count)\n",
    "    \n",
    "    for line in f:\n",
    "        l=line.strip()\n",
    "        jdata=eval(l)\n",
    "        edge_loss_list.append(jdata['loss'])\n",
    "        edge_list.append([str(jdata['srcmsg']),str(jdata['dstmsg'])])\n",
    "    df_list_5_14.append(pd.DataFrame(edge_loss_list))\n",
    "    count,loss_avg,node_set,edge_set=cal_anomaly_loss(edge_loss_list,edge_list,\"graph_5_14/\")\n",
    "\n",
    "    current_tw['name']=f_path\n",
    "    current_tw['loss']=loss_avg\n",
    "    current_tw['index']=index_count\n",
    "    current_tw['nodeset']=node_set\n",
    "\n",
    "    added_que_flag=False\n",
    "    for hq in history_list_5_14:\n",
    "        for his_tw in hq:\n",
    "\n",
    "            if cal_set_rel(current_tw['nodeset'],his_tw['nodeset'],file_list)!=0 and current_tw['name']!=his_tw['name']:\n",
    "                print(\"history queue:\",his_tw['name'])\n",
    "\n",
    "                hq.append(copy.deepcopy(current_tw))\n",
    "                added_que_flag=True\n",
    "                break\n",
    "            if added_que_flag:\n",
    "                break\n",
    "    if added_que_flag is False:\n",
    "        temp_hq=[copy.deepcopy(current_tw)]\n",
    "        history_list_5_14.append(temp_hq)\n",
    "    index_count+=1\n",
    "    loss_list_5_14.append(loss_avg)\n",
    "    print( f_path,\"  \",loss_avg,\" count:\",count,\" percentage:\",count/len(edge_list),\" node count:\",len(node_set),\" edge count:\",len(edge_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list=[]\n",
    "for hl in history_list_5_14:\n",
    "    loss_count=0\n",
    "    for hq in hl:\n",
    "        if loss_count==0:\n",
    "            loss_count=(loss_count+1)*(hq['loss']+1)\n",
    "        else:\n",
    "            loss_count=(loss_count)*(hq['loss']+1)\n",
    "#     name_list=[]\n",
    "    if loss_count>12:\n",
    "        name_list=[]\n",
    "        for i in hl:\n",
    "            name_list.append(i['name']) \n",
    "        print(name_list)\n",
    "        for i in name_list:\n",
    "            pred_label[i]=1\n",
    "        print(loss_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_count: 0\n",
      "thr: 0.7017160930906966\n",
      "graph_5_15/2019-05-15 00:00:01.490408727~2019-05-15 00:16:14.833595653.txt    1.569451990186191  count: 7442  percentage: 0.04200912210982659  node count: 430  edge count: 710\n",
      "index_count: 1\n",
      "thr: 0.8338568772713835\n",
      "graph_5_15/2019-05-15 00:16:14.833595653~2019-05-15 00:32:01.492056162.txt    1.6007974350398273  count: 7705  percentage: 0.05532657398897059  node count: 138  edge count: 180\n",
      "index_count: 2\n",
      "thr: 1.322699930062194\n",
      "graph_5_15/2019-05-15 00:32:01.492056162~2019-05-15 00:47:15.554515213.txt    3.302451719005372  count: 1273  percentage: 0.03453233506944445  node count: 56  edge count: 67\n",
      "index_count: 3\n",
      "thr: 1.4335928802529354\n",
      "graph_5_15/2019-05-15 00:47:15.554515213~2019-05-15 01:04:31.491761640.txt    3.393008336262723  count: 1195  percentage: 0.04322193287037037  node count: 55  edge count: 64\n",
      "index_count: 4\n",
      "thr: 0.8126172968089068\n",
      "graph_5_15/2019-05-15 01:04:31.491761640~2019-05-15 01:20:01.492131631.txt    2.0165322843454856  count: 3439  percentage: 0.036504330842391304  node count: 94  edge count: 111\n",
      "index_count: 5\n",
      "thr: 0.9800244315218276\n",
      "graph_5_15/2019-05-15 01:20:01.492131631~2019-05-15 01:36:01.495126517.txt    1.5751001672670206  count: 7548  percentage: 0.08282127808988764  node count: 84  edge count: 106\n",
      "index_count: 6\n",
      "thr: 1.2086156472034937\n",
      "graph_5_15/2019-05-15 01:36:01.495126517~2019-05-15 01:51:02.896532154.txt    2.439103189732772  count: 2846  percentage: 0.04087201286764706  node count: 62  edge count: 74\n",
      "index_count: 7\n",
      "thr: 0.8628138808967066\n",
      "graph_5_15/2019-05-15 01:51:02.896532154~2019-05-15 02:07:19.144870551.txt    1.5956091436714737  count: 8735  percentage: 0.056120219983552634  node count: 92  edge count: 113\n",
      "index_count: 8\n",
      "thr: 1.264530753142658\n",
      "graph_5_15/2019-05-15 02:07:19.144870551~2019-05-15 02:23:18.291403804.txt    2.742286253182684  count: 2071  percentage: 0.042134602864583336  node count: 71  edge count: 83\n",
      "index_count: 9\n",
      "thr: 1.1895320961292106\n",
      "graph_5_15/2019-05-15 02:23:18.291403804~2019-05-15 02:39:26.758938680.txt    2.131045477563972  count: 3775  percentage: 0.05502273787313433  node count: 74  edge count: 91\n",
      "index_count: 10\n",
      "thr: 0.7173952717972315\n",
      "graph_5_15/2019-05-15 02:39:26.758938680~2019-05-15 02:54:29.939561154.txt    1.5806725367528622  count: 6555  percentage: 0.04384498073630137  node count: 81  edge count: 95\n",
      "index_count: 11\n",
      "thr: 0.6746893078925994\n",
      "graph_5_15/2019-05-15 02:54:29.939561154~2019-05-15 03:09:30.148005357.txt    1.5421920875482882  count: 6876  percentage: 0.04249901107594937  node count: 96  edge count: 116\n",
      "index_count: 12\n",
      "thr: 0.7383021060158111\n",
      "graph_5_15/2019-05-15 03:09:30.148005357~2019-05-15 03:25:02.394441209.txt    1.5708282645693838  count: 8559  percentage: 0.04887952302631579  node count: 103  edge count: 127\n",
      "index_count: 13\n",
      "thr: 1.0119772052715117\n",
      "graph_5_15/2019-05-15 03:25:02.394441209~2019-05-15 03:41:44.920119418.txt    1.6100001905488608  count: 7537  percentage: 0.08460174209770115  node count: 70  edge count: 87\n",
      "index_count: 14\n",
      "thr: 0.7334827666025154\n",
      "graph_5_15/2019-05-15 03:41:44.920119418~2019-05-15 03:58:07.697665053.txt    1.6051118486231226  count: 8111  percentage: 0.04686922152366864  node count: 111  edge count: 143\n",
      "index_count: 15\n",
      "thr: 0.8355321929236119\n",
      "graph_5_15/2019-05-15 03:58:07.697665053~2019-05-15 04:14:56.274252703.txt    1.6344123625554632  count: 6772  percentage: 0.05652377136752137  node count: 98  edge count: 120\n",
      "index_count: 16\n",
      "thr: 0.9351695996386983\n",
      "graph_5_15/2019-05-15 04:14:56.274252703~2019-05-15 04:31:01.490574676.txt    1.6779006786438768  count: 5216  percentage: 0.06883445945945946  node count: 69  edge count: 80\n",
      "index_count: 17\n",
      "thr: 1.2698619100389905\n",
      "graph_5_15/2019-05-15 04:31:01.490574676~2019-05-15 04:46:31.301354716.txt    3.3779221979790015  count: 1223  percentage: 0.027775254360465115  node count: 66  edge count: 77\n",
      "index_count: 18\n",
      "thr: 1.464011081147808\n",
      "graph_5_15/2019-05-15 04:46:31.301354716~2019-05-15 05:01:36.395374506.txt    3.391016850651614  count: 1006  percentage: 0.04271399456521739  node count: 55  edge count: 62\n",
      "index_count: 19\n",
      "thr: 0.9377978270905049\n",
      "graph_5_15/2019-05-15 05:01:36.395374506~2019-05-15 05:17:01.503229576.txt    1.7911737632646068  count: 4298  percentage: 0.061724494485294115  node count: 62  edge count: 75\n",
      "index_count: 20\n",
      "thr: 1.5110729745617295\n",
      "graph_5_15/2019-05-15 05:17:01.503229576~2019-05-15 05:32:11.337521289.txt    3.3699246190304546  count: 1054  percentage: 0.04678622159090909  node count: 58  edge count: 62\n",
      "index_count: 21\n",
      "thr: 1.315539754392288\n",
      "graph_5_15/2019-05-15 05:32:11.337521289~2019-05-15 05:48:01.503688497.txt    3.0189676661278315  count: 1656  percentage: 0.03515625  node count: 56  edge count: 68\n",
      "index_count: 22\n",
      "thr: 1.3742783994780179\n",
      "graph_5_15/2019-05-15 05:48:01.503688497~2019-05-15 06:05:01.495772298.txt    3.3945004316811143  count: 1316  percentage: 0.03671875  node count: 53  edge count: 63\n",
      "index_count: 23\n",
      "thr: 1.2087496651602332\n",
      "graph_5_15/2019-05-15 06:05:01.495772298~2019-05-15 06:20:51.005863855.txt    2.8706274025460594  count: 2340  percentage: 0.03264508928571429  node count: 83  edge count: 99\n",
      "index_count: 24\n",
      "thr: 1.3899343808197495\n",
      "graph_5_15/2019-05-15 06:20:51.005863855~2019-05-15 06:36:01.491983616.txt    3.40602054418476  count: 1021  percentage: 0.0343817349137931  node count: 56  edge count: 61\n",
      "index_count: 25\n",
      "thr: 0.9456039031249527\n",
      "graph_5_15/2019-05-15 06:36:01.491983616~2019-05-15 06:53:31.493116975.txt    1.7650068623587876  count: 5605  percentage: 0.06081814236111111  node count: 79  edge count: 97\n",
      "index_count: 26\n",
      "thr: 1.2029623171028687\n",
      "graph_5_15/2019-05-15 06:53:31.493116975~2019-05-15 07:09:55.168118324.txt    2.3858293842924527  count: 2904  percentage: 0.0515625  node count: 973  edge count: 990\n",
      "index_count: 27\n",
      "thr: 1.7395459502641701\n",
      "graph_5_15/2019-05-15 07:09:55.168118324~2019-05-15 07:27:01.254806380.txt    3.4751019576670594  count: 965  percentage: 0.06731305803571429  node count: 49  edge count: 52\n",
      "index_count: 28\n",
      "thr: 0.609675059589387\n",
      "graph_5_15/2019-05-15 07:27:01.254806380~2019-05-15 07:42:05.122895776.txt    1.6946649654729673  count: 4424  percentage: 0.030640514184397165  node count: 99  edge count: 120\n",
      "index_count: 29\n",
      "thr: 2.2164684935528625\n",
      "graph_5_15/2019-05-15 07:42:05.122895776~2019-05-15 07:57:29.435273604.txt    4.995771610401163  count: 14418  percentage: 0.058182141012396695  node count: 244  edge count: 258\n",
      "index_count: 30\n",
      "thr: 0.946372280860642\n",
      "graph_5_15/2019-05-15 07:57:29.435273604~2019-05-15 08:12:40.385079790.txt    1.609851000453449  count: 7691  percentage: 0.07363472732843138  node count: 86  edge count: 106\n",
      "index_count: 31\n",
      "thr: 0.7192825206789272\n",
      "graph_5_15/2019-05-15 08:12:40.385079790~2019-05-15 08:28:58.370499520.txt    1.5603202913243803  count: 8972  percentage: 0.04611430921052632  node count: 100  edge count: 123\n",
      "index_count: 32\n",
      "thr: 0.7761943832447578\n",
      "graph_5_15/2019-05-15 08:28:58.370499520~2019-05-15 08:46:17.912177800.txt    1.694217777727035  count: 6678  percentage: 0.04903371710526316  node count: 72  edge count: 86\n",
      "index_count: 33\n",
      "thr: 0.5423606687590079\n",
      "graph_5_15/2019-05-15 08:46:17.912177800~2019-05-15 09:01:36.712206897.txt    1.4121995180839304  count: 15009  percentage: 0.03369477370689655  node count: 279  edge count: 315\n",
      "index_count: 34\n",
      "thr: 0.6459993269345781\n",
      "graph_5_15/2019-05-15 09:01:36.712206897~2019-05-15 09:18:20.052280739.txt    1.4621478608629674  count: 16778  percentage: 0.04380953375668449  node count: 127  edge count: 174\n",
      "index_count: 35\n",
      "thr: 0.9842682188347851\n",
      "graph_5_15/2019-05-15 09:18:20.052280739~2019-05-15 09:33:20.409598023.txt    1.6243533589826866  count: 19155  percentage: 0.0687722598805147  node count: 625  edge count: 666\n",
      "index_count: 36\n",
      "thr: 1.498797047759807\n",
      "graph_5_15/2019-05-15 09:33:20.409598023~2019-05-15 09:48:20.851554754.txt    4.364060399333021  count: 1615  percentage: 0.026731329449152543  node count: 423  edge count: 431\n",
      "index_count: 37\n",
      "thr: 0.6520955775090705\n",
      "graph_5_15/2019-05-15 09:48:20.851554754~2019-05-15 10:04:07.712341272.txt    1.460194213210488  count: 14780  percentage: 0.0427029400887574  node count: 123  edge count: 159\n",
      "index_count: 38\n",
      "thr: 0.5990641803831184\n",
      "graph_5_15/2019-05-15 10:04:07.712341272~2019-05-15 10:19:12.055930735.txt    1.4338252582160087  count: 15297  percentage: 0.039208599901574805  node count: 125  edge count: 163\n",
      "index_count: 39\n",
      "thr: 0.9432847586092786\n",
      "graph_5_15/2019-05-15 10:19:12.055930735~2019-05-15 10:34:12.998931412.txt    1.541143698453596  count: 10866  percentage: 0.07689368206521739  node count: 93  edge count: 110\n",
      "index_count: 40\n",
      "thr: 1.1309158553079033\n",
      "graph_5_15/2019-05-15 10:34:12.998931412~2019-05-15 10:52:01.493441398.txt    1.6739405719900293  count: 7325  percentage: 0.08515857514880952  node count: 73  edge count: 93\n",
      "index_count: 41\n",
      "thr: 0.7861359460286281\n",
      "graph_5_15/2019-05-15 10:52:01.493441398~2019-05-15 11:07:01.494486145.txt    1.5852867794105243  count: 7671  percentage: 0.05428413722826087  node count: 81  edge count: 104\n",
      "index_count: 42\n",
      "thr: 0.9061492282745617\n",
      "graph_5_15/2019-05-15 11:07:01.494486145~2019-05-15 11:22:08.001455967.txt    1.5863335492282078  count: 11020  percentage: 0.06811214398734178  node count: 99  edge count: 121\n",
      "index_count: 43\n",
      "thr: 1.1255899659306197\n",
      "graph_5_15/2019-05-15 11:22:08.001455967~2019-05-15 11:38:31.497341568.txt    1.7639403174547983  count: 6517  percentage: 0.08265269886363637  node count: 77  edge count: 91\n",
      "index_count: 44\n",
      "thr: 0.6102656601292508\n",
      "graph_5_15/2019-05-15 11:38:31.497341568~2019-05-15 11:54:52.383589579.txt    1.5072991672841258  count: 11829  percentage: 0.03427821309347181  node count: 120  edge count: 149\n",
      "index_count: 45\n",
      "thr: 0.30913972186723493\n",
      "graph_5_15/2019-05-15 11:54:52.383589579~2019-05-15 13:27:01.496190252.txt    0.9623431960741679  count: 2421  percentage: 0.02149325284090909  node count: 86  edge count: 99\n",
      "index_count: 46\n",
      "thr: 2.411638259895355\n",
      "graph_5_15/2019-05-15 13:27:01.496190252~2019-05-15 13:42:24.177751369.txt    6.386387658889473  count: 24793  percentage: 0.0433905269937276  node count: 1333  edge count: 1540\n",
      "index_count: 47\n",
      "thr: 2.652318781320865\n",
      "graph_5_15/2019-05-15 13:42:24.177751369~2019-05-15 13:58:15.520482252.txt    6.862367397224581  count: 5920  percentage: 0.04282407407407408  node count: 357  edge count: 397\n",
      "index_count: 48\n",
      "thr: 14.029144853231074\n",
      "graph_5_15/2019-05-15 13:58:15.520482252~2019-05-15 14:13:37.257086895.txt    14.148306795008041  count: 425  percentage: 0.0013519187703583061  node count: 7  edge count: 6\n",
      "index_count: 49\n",
      "thr: 0.9797427558561775\n",
      "graph_5_15/2019-05-15 14:13:37.257086895~2019-05-15 14:29:18.996669142.txt    1.5395009175556558  count: 17534  percentage: 0.07818742865296803  node count: 190  edge count: 221\n",
      "index_count: 50\n",
      "thr: 0.9502154327587674\n",
      "graph_5_15/2019-05-15 14:29:18.996669142~2019-05-15 14:44:51.773840192.txt    1.3813258079552964  count: 8962  percentage: 0.09410702284946236  node count: 104  edge count: 118\n",
      "index_count: 51\n",
      "thr: 8.650822215351099\n",
      "graph_5_15/2019-05-15 14:44:51.773840192~2019-05-15 15:00:26.765466538.txt    10.409427697991992  count: 62455  percentage: 0.20674986758474576  node count: 373  edge count: 516\n",
      "index_count: 52\n",
      "thr: 2.08801870225091\n",
      "graph_5_15/2019-05-15 15:00:26.765466538~2019-05-15 15:17:03.203703087.txt    5.189259758479685  count: 2502  percentage: 0.04442471590909091  node count: 983  edge count: 994\n",
      "index_count: 53\n",
      "thr: 0.629645954661206\n",
      "graph_5_15/2019-05-15 15:17:03.203703087~2019-05-15 15:34:25.452570637.txt    1.513034374523323  count: 8332  percentage: 0.03632463727678571  node count: 100  edge count: 126\n",
      "index_count: 54\n",
      "thr: 0.8219892817058292\n",
      "graph_5_15/2019-05-15 15:34:25.452570637~2019-05-15 15:49:43.447021039.txt    1.5547658439124539  count: 5869  percentage: 0.05458519345238095  node count: 67  edge count: 81\n",
      "index_count: 55\n",
      "thr: 0.9393856324468536\n",
      "graph_5_15/2019-05-15 15:49:43.447021039~2019-05-15 16:05:41.064452218.txt    1.5549125277475189  count: 6042  percentage: 0.06860919331395349  node count: 141  edge count: 160\n",
      "index_count: 56\n",
      "thr: 1.005179990832926\n",
      "graph_5_15/2019-05-15 16:05:41.064452218~2019-05-15 16:22:39.979479840.txt    1.5807668860789126  count: 3557  percentage: 0.08078215843023256  node count: 71  edge count: 82\n",
      "index_count: 57\n",
      "thr: 0.7389825075628903\n",
      "graph_5_15/2019-05-15 16:22:39.979479840~2019-05-15 16:38:00.022566187.txt    1.370640541774721  count: 8971  percentage: 0.0600050834760274  node count: 103  edge count: 122\n",
      "index_count: 58\n",
      "thr: 0.8162428346252695\n",
      "graph_5_15/2019-05-15 16:38:00.022566187~2019-05-15 16:54:31.494483643.txt    1.4056996694808506  count: 9506  percentage: 0.06402209051724138  node count: 117  edge count: 140\n",
      "index_count: 59\n",
      "thr: 0.5886073151019293\n",
      "graph_5_15/2019-05-15 16:54:31.494483643~2019-05-15 17:10:01.626108726.txt    1.613738929001603  count: 6059  percentage: 0.02665311796171171  node count: 91  edge count: 111\n",
      "index_count: 60\n",
      "thr: 0.976028006075611\n",
      "graph_5_15/2019-05-15 17:10:01.626108726~2019-05-15 17:25:14.590228152.txt    1.4692890242403474  count: 6737  percentage: 0.08434745592948718  node count: 83  edge count: 94\n",
      "index_count: 61\n",
      "thr: 0.6409010243039486\n",
      "graph_5_15/2019-05-15 17:25:14.590228152~2019-05-15 17:43:54.631759423.txt    1.43038162297233  count: 9640  percentage: 0.042027064732142856  node count: 106  edge count: 127\n",
      "index_count: 62\n",
      "thr: 1.0243213633770638\n",
      "graph_5_15/2019-05-15 17:43:54.631759423~2019-05-15 18:00:21.533587327.txt    1.3934015529421142  count: 6342  percentage: 0.10497219279661017  node count: 73  edge count: 84\n",
      "index_count: 63\n",
      "thr: 0.4819214519514304\n",
      "graph_5_15/2019-05-15 18:00:21.533587327~2019-05-15 18:16:33.957928738.txt    1.4972899528086356  count: 8344  percentage: 0.022385817307692308  node count: 131  edge count: 155\n",
      "index_count: 64\n",
      "thr: 0.5541192274676833\n",
      "graph_5_15/2019-05-15 18:16:33.957928738~2019-05-15 18:32:44.229252473.txt    1.4031913283576616  count: 7524  percentage: 0.032949131165919285  node count: 96  edge count: 120\n",
      "index_count: 65\n",
      "thr: 0.9776277000751008\n",
      "graph_5_15/2019-05-15 18:32:44.229252473~2019-05-15 18:50:02.896672585.txt    1.6292109273128002  count: 2513  percentage: 0.0701171875  node count: 62  edge count: 73\n",
      "index_count: 66\n",
      "thr: 0.883250009796107\n",
      "graph_5_15/2019-05-15 18:50:02.896672585~2019-05-15 19:05:15.589701783.txt    1.4667075061028223  count: 4924  percentage: 0.06869419642857143  node count: 95  edge count: 108\n",
      "index_count: 67\n",
      "thr: 0.760020683797228\n",
      "graph_5_15/2019-05-15 19:05:15.589701783~2019-05-15 19:21:31.509532475.txt    1.4283046045187848  count: 7225  percentage: 0.054274338942307696  node count: 102  edge count: 126\n",
      "index_count: 68\n",
      "thr: 0.48669669003634636\n",
      "graph_5_15/2019-05-15 19:21:31.509532475~2019-05-15 19:37:24.849404892.txt    1.5070157356620502  count: 3214  percentage: 0.020119691506410256  node count: 109  edge count: 128\n",
      "index_count: 69\n",
      "thr: 0.6378478936486812\n",
      "graph_5_15/2019-05-15 19:37:24.849404892~2019-05-15 19:56:19.975334466.txt    1.4185405958491861  count: 8463  percentage: 0.04282201262953368  node count: 101  edge count: 124\n",
      "index_count: 70\n",
      "thr: 0.8058879167821786\n",
      "graph_5_15/2019-05-15 19:56:19.975334466~2019-05-15 20:12:58.479720072.txt    1.5015698827117094  count: 10882  percentage: 0.05838985233516483  node count: 134  edge count: 163\n",
      "index_count: 71\n",
      "thr: 0.6983149487212592\n",
      "graph_5_15/2019-05-15 20:12:58.479720072~2019-05-15 20:28:31.496181001.txt    1.490653616943013  count: 6055  percentage: 0.04316121122262774  node count: 86  edge count: 97\n",
      "index_count: 72\n",
      "thr: 0.7154882601883878\n",
      "graph_5_15/2019-05-15 20:28:31.496181001~2019-05-15 20:45:02.944896082.txt    1.3883842164810838  count: 5985  percentage: 0.0517232439159292  node count: 105  edge count: 127\n",
      "index_count: 73\n",
      "thr: 0.5861157603381891\n",
      "graph_5_15/2019-05-15 20:45:02.944896082~2019-05-15 21:00:14.411230352.txt    1.3607313687481235  count: 12311  percentage: 0.04007486979166667  node count: 122  edge count: 151\n",
      "index_count: 74\n",
      "thr: 0.5665237005040151\n",
      "graph_5_15/2019-05-15 21:00:14.411230352~2019-05-15 21:16:04.951215086.txt    1.3800272909607947  count: 7399  percentage: 0.03524676067073171  node count: 117  edge count: 141\n",
      "index_count: 75\n",
      "thr: 0.9584258250194831\n",
      "graph_5_15/2019-05-15 21:16:04.951215086~2019-05-15 21:31:25.960086974.txt    1.4019255865050453  count: 6816  percentage: 0.09118150684931507  node count: 79  edge count: 87\n",
      "index_count: 76\n",
      "thr: 1.037956580416214\n",
      "graph_5_15/2019-05-15 21:31:25.960086974~2019-05-15 21:47:41.306583947.txt    1.4122726699403714  count: 7748  percentage: 0.10656910211267606  node count: 74  edge count: 91\n",
      "index_count: 77\n",
      "thr: 0.9489652467581344\n",
      "graph_5_15/2019-05-15 21:47:41.306583947~2019-05-15 22:03:31.522168702.txt    1.3827309447630167  count: 4388  percentage: 0.09315557065217392  node count: 59  edge count: 71\n",
      "index_count: 78\n",
      "thr: 0.7061772020466529\n",
      "graph_5_15/2019-05-15 22:03:31.522168702~2019-05-15 22:19:16.263929035.txt    1.4475003123553527  count: 6178  percentage: 0.04865486391129032  node count: 115  edge count: 140\n",
      "index_count: 79\n",
      "thr: 0.6339764783294438\n",
      "graph_5_15/2019-05-15 22:19:16.263929035~2019-05-15 22:37:52.734006062.txt    1.6569852086973986  count: 3173  percentage: 0.02979454627403846  node count: 110  edge count: 126\n",
      "index_count: 80\n",
      "thr: 1.002640558722961\n",
      "graph_5_15/2019-05-15 22:37:52.734006062~2019-05-15 22:55:31.494815444.txt    1.4453104002415311  count: 6747  percentage: 0.09549082880434782  node count: 72  edge count: 82\n",
      "index_count: 81\n",
      "thr: 0.7307601165797034\n",
      "graph_5_15/2019-05-15 22:55:31.494815444~2019-05-15 23:11:23.284826570.txt    1.4183387407642443  count: 7268  percentage: 0.055450439453125  node count: 98  edge count: 115\n",
      "index_count: 82\n",
      "thr: 0.6783281391761737\n",
      "graph_5_15/2019-05-15 23:11:23.284826570~2019-05-15 23:29:31.512587396.txt    1.4689171011817412  count: 7588  percentage: 0.04518387957317073  node count: 113  edge count: 143\n",
      "index_count: 83\n",
      "thr: 1.066601269459553\n",
      "graph_5_15/2019-05-15 23:29:31.512587396~2019-05-15 23:46:09.097590467.txt    1.5502792010521196  count: 1895  percentage: 0.08411754261363637  node count: 56  edge count: 63\n"
     ]
    }
   ],
   "source": [
    "# 5-15 \n",
    "\n",
    "# node_IDF=torch.load(\"node_IDF_5_15\")\n",
    "# node_IDF=torch.load(\"node_IDF_5_9\")\n",
    "y_data_5_15=[]\n",
    "df_list_5_15=[]\n",
    "# node_set_list=[]\n",
    "history_list_5_15=[]\n",
    "tw_que=[]\n",
    "his_tw={}\n",
    "current_tw={}\n",
    "loss_list_5_15=[]\n",
    "\n",
    "\n",
    "\n",
    "file_path_list=[]\n",
    "file_path=\"graph_5_15/\"\n",
    "file_l=os.listdir(\"graph_5_15/\")\n",
    "for i in file_l:\n",
    "    file_path_list.append(file_path+i)\n",
    "\n",
    "index_count=0\n",
    "for f_path in sorted(file_path_list):\n",
    "    f=open(f_path)\n",
    "    edge_loss_list=[]\n",
    "    edge_list=[]\n",
    "    print('index_count:',index_count)\n",
    "    \n",
    "    for line in f:\n",
    "        l=line.strip()\n",
    "        jdata=eval(l)\n",
    "        edge_loss_list.append(jdata['loss'])\n",
    "        edge_list.append([str(jdata['srcmsg']),str(jdata['dstmsg'])])\n",
    "    df_list_5_15.append(pd.DataFrame(edge_loss_list))\n",
    "    count,loss_avg,node_set,edge_set=cal_anomaly_loss(edge_loss_list,edge_list,\"graph_5_15/\")\n",
    "\n",
    "    current_tw['name']=f_path\n",
    "    current_tw['loss']=loss_avg\n",
    "    current_tw['index']=index_count\n",
    "    current_tw['nodeset']=node_set\n",
    "\n",
    "    added_que_flag=False\n",
    "    for hq in history_list_5_15:\n",
    "        for his_tw in hq:\n",
    "\n",
    "            if cal_set_rel(current_tw['nodeset'],his_tw['nodeset'],file_list)!=0 and current_tw['name']!=his_tw['name']:\n",
    "                print(\"history queue:\",his_tw['name'])\n",
    "                hq.append(copy.deepcopy(current_tw))\n",
    "                added_que_flag=True\n",
    "                break\n",
    "            if added_que_flag:\n",
    "                break\n",
    "    if added_que_flag is False:\n",
    "        temp_hq=[copy.deepcopy(current_tw)]\n",
    "        history_list_5_15.append(temp_hq)\n",
    "    index_count+=1\n",
    "    loss_list_5_15.append(loss_avg)\n",
    "    print( f_path,\"  \",loss_avg,\" count:\",count,\" percentage:\",count/len(edge_list),\" node count:\",len(node_set),\" edge count:\",len(edge_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['graph_5_15/2019-05-15 13:58:15.520482252~2019-05-15 14:13:37.257086895.txt']\n",
      "15.148306795008041\n"
     ]
    }
   ],
   "source": [
    "name_list=[]\n",
    "for hl in history_list_5_15:\n",
    "    loss_count=0\n",
    "    for hq in hl:\n",
    "        if loss_count==0:\n",
    "            loss_count=(loss_count+1)*(hq['loss']+1)\n",
    "        else:\n",
    "            loss_count=(loss_count)*(hq['loss']+1)\n",
    "#     name_list=[]\n",
    "    if loss_count>12:\n",
    "        name_list=[]\n",
    "        for i in hl:\n",
    "            name_list.append(i['name']) \n",
    "        print(name_list)\n",
    "        for i in name_list:\n",
    "            pred_label[i]=1\n",
    "        print(loss_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Unused and incomplete function\n",
    "def plot_thr():\n",
    "    np.seterr(invalid='ignore')\n",
    "    step=0.01\n",
    "    thr_list=torch.arange(-5,5,step)\n",
    "\n",
    "    precision_list=[]\n",
    "    recall_list=[]\n",
    "    fscore_list=[]\n",
    "    accuracy_list=[]\n",
    "    auc_val_list=[]\n",
    "    for thr in thr_list:\n",
    "        threshold=thr\n",
    "        y_prediction=[]\n",
    "        for i in y_test_scores:\n",
    "            if i >threshold:\n",
    "                y_prediction.append(1)\n",
    "            else:\n",
    "                y_prediction.append(0)\n",
    "        precision,recall,fscore,accuracy,auc_val=classifier_evaluation(y_test, y_prediction)   \n",
    "        precision_list.append(float(precision))\n",
    "        recall_list.append(float(recall))\n",
    "        fscore_list.append(float(fscore))\n",
    "        accuracy_list.append(float(accuracy))\n",
    "        auc_val_list.append(float(auc_val))\n",
    "\n",
    "    max_fscore=max(fscore_list)\n",
    "    max_fscore_index=fscore_list.index(max_fscore)\n",
    "    print(max_fscore_index)\n",
    "    print(\"max threshold:\",thr_list[max_fscore_index])\n",
    "    print('precision:',precision_list[max_fscore_index])\n",
    "    print('recall:',recall_list[max_fscore_index])\n",
    "    print('fscore:',fscore_list[max_fscore_index])\n",
    "    print('accuracy:',accuracy_list[max_fscore_index])    \n",
    "    print('auc:',auc_val_list[max_fscore_index])\n",
    "    \n",
    "        \n",
    "     # list tensor\n",
    "#     precision_list=torch.tensor(precision_list)   \n",
    "#     recall_list=torch.tensor(recall_list)   \n",
    "#     fscore_list=torch.tensor(fscore_list)   \n",
    "#     accuracy_list=torch.tensor(accuracy_list)   \n",
    "#     auc_val_list=torch.tensor(auc_val_list)   \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    # plt.scatter(attack_x, attack_y, s=20, c='r', label='Attack graph',marker='*')\n",
    "    # plt.scatter(bengin_x, bengin_y, s=20, c='g', label='Bengin graph',marker='1')\n",
    "    # plt.scatter(bengin_x, bengin_y, s=20, c='g', label='Bengin graph',marker='1')\n",
    "\n",
    "    plt.plot(thr_list,precision_list,color='red',label='precision',linewidth=2.0,linestyle='-')\n",
    "    plt.plot(thr_list,recall_list,color='orange',label='recall',linewidth=2.0,linestyle='solid')\n",
    "    plt.plot(thr_list,fscore_list,color='y',label='F-score',linewidth=2.0,linestyle='dashed')\n",
    "    plt.plot(thr_list,accuracy_list,color='g',label='accuracy',linewidth=2.0,linestyle='dashdot')\n",
    "    plt.plot(thr_list,auc_val_list,color='b',label='auc_val',linewidth=2.0,linestyle='dotted')\n",
    "    # '-', '--', '-.', ':', 'None', ' ', '', 'solid', 'dashed', 'dashdot', 'dotted'\n",
    "\n",
    "\n",
    "    # plt.scatter(turnovers, graph_loss, c=color)\n",
    "    plt.xlabel(\"Threshold\", fontdict={'size': 16})\n",
    "    plt.ylabel(\"Rate\", fontdict={'size': 16})\n",
    "    plt.title(\"Different evaluation Indicators by varying threshold value\", fontdict={'size': 12})\n",
    "    plt.legend(loc='best', fontsize=12, markerscale=0.5)\n",
    "    plt.show()\n",
    "\n",
    "# Function to compute classification evaluation metrics\n",
    "def classifier_evaluation(y_test, y_test_pred):\n",
    "    \"\"\"\n",
    "    Calculate evaluation metrics based on ground truth and predicted labels.\n",
    "\n",
    "    Parameters:\n",
    "        y_test (list or array): Ground truth binary labels.\n",
    "        y_test_pred (list or array): Predicted binary labels.\n",
    "\n",
    "    Returns:\n",
    "        tuple: precision, recall, F-score, accuracy, and AUC values.\n",
    "    \"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "    print('tn:',tn)\n",
    "    print('fp:',fp)\n",
    "    print('fn:',fn)\n",
    "    print('tp:',tp)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    precision=tp/(tp+fp)\n",
    "    recall=tp/(tp+fn)\n",
    "    accuracy=(tp+tn)/(tp+tn+fp+fn)\n",
    "    fscore=2*(precision*recall)/(precision+recall)    \n",
    "    auc_val=roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "    print(\"precision:\",precision)\n",
    "    print(\"recall:\",recall)\n",
    "    print(\"fscore:\",fscore)\n",
    "    print(\"accuracy:\",accuracy)\n",
    "    print(\"auc_val:\",auc_val)\n",
    "\n",
    "    return precision,recall,fscore,accuracy,auc_val\n",
    "\n",
    "# Function to apply Min-Max scaling to a dataset\n",
    "def minmax(data):\n",
    "    \"\"\"\n",
    "    Apply Min-Max scaling to normalize data to a range [0, 1].\n",
    "\n",
    "    Parameters:\n",
    "        data (list or array): Input data to be normalized.\n",
    "\n",
    "    Returns:\n",
    "        list: Normalized data.\n",
    "    \"\"\"\n",
    "    min_val=min(data)\n",
    "    max_val=max(data)\n",
    "    ans=[]\n",
    "    for i in data:\n",
    "        ans.append((i-min_val)/(max_val-min_val))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of truth and predicted values from ground truth and predict dictionaries\n",
    "y=[]\n",
    "y_pred=[]\n",
    "for i in labels:\n",
    "    y.append(labels[i])\n",
    "    y_pred.append(pred_label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn: 174\n",
      "fp: 0\n",
      "fn: 1\n",
      "tp: 1\n",
      "precision: 1.0\n",
      "recall: 0.5\n",
      "fscore: 0.6666666666666666\n",
      "accuracy: 0.9943181818181818\n",
      "auc_val: 0.75\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.5, 0.6666666666666666, 0.9943181818181818, 0.75)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_evaluation(y,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count attack edge numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def keyword_hit(line):\n",
    "    attack_nodes=[\n",
    "#             'sshd',\n",
    "            'sshdlog',\n",
    "        'shm',\n",
    "#          'python',\n",
    "#             'firefox',\n",
    "        '189.141.204.211',\n",
    "        '208.203.20.42',\n",
    "       \n",
    "#         '',\n",
    "#         '',\n",
    "#         '',\n",
    "        ]\n",
    "    flag=False\n",
    "    for i in attack_nodes:\n",
    "        if i in line:\n",
    "            flag=True\n",
    "            break\n",
    "    return flag\n",
    "\n",
    "\n",
    "\n",
    "files=[    \n",
    "    'graph_5_15/2019-05-15 13:58:15.520482252~2019-05-15 14:13:37.257086895.txt',\n",
    "    'graph_5_15/2019-05-15 14:44:51.773840192~2019-05-15 15:00:26.765466538.txt',]\n",
    "\n",
    "# Count total edges in these attac time windows\n",
    "attack_edge_count=0\n",
    "for fpath in tqdm(files):\n",
    "    f=open(fpath)\n",
    "    for line in f:\n",
    "        if keyword_hit(line):\n",
    "            attack_edge_count+=1\n",
    "print(attack_edge_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "\n",
    "For the provided attack time windows create graphs for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:05<00:05,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.879262950067025\n",
      "4.766587935442699\n",
      "thr: 14.029144853231074\n",
      "2.3494681087178666\n",
      "4.200902737755488\n",
      "thr: 8.650822215351099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:13<00:00,  6.52s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from graphviz import Digraph\n",
    "import networkx as nx\n",
    "import datetime\n",
    "import community.community_louvain as community_louvain\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "# Some common path abstraction for visualization\n",
    "replace_dic = {\n",
    "        '/run/shm/':'/run/shm/*',\n",
    "        #     '/home/admin/.cache/mozilla/firefox/pe11scpa.default/cache2/entries/':'/home/admin/.cache/mozilla/firefox/pe11scpa.default/cache2/entries/*',\n",
    "        '/home/admin/.cache/mozilla/firefox/':'/home/admin/.cache/mozilla/firefox/*',\n",
    "        '/home/admin/.mozilla/firefox':'/home/admin/.mozilla/firefox*',\n",
    "        '/data/replay_logdb/':'/data/replay_logdb/*',\n",
    "        '/home/admin/.local/share/applications/':'/home/admin/.local/share/applications/*',\n",
    "        '/usr/share/applications/':'/usr/share/applications/*',\n",
    "        '/lib/x86_64-linux-gnu/':'/lib/x86_64-linux-gnu/*',\n",
    "        '/proc/':'/proc/*',\n",
    "        '/stat':'*/stat',\n",
    "        '/etc/bash_completion.d/':'/etc/bash_completion.d/*',\n",
    "        '/usr/bin/python2.7':'/usr/bin/python2.7/*',\n",
    "        '/usr/lib/python2.7':'/usr/lib/python2.7/*',\n",
    "        '/data/data/org.mozilla.fennec_firefox_dev/cache/':'/data/data/org.mozilla.fennec_firefox_dev/cache/*',\n",
    "        'UNNAMED':'UNNAMED*',\n",
    "        '/etc/fonts/':'/etc/fonts/*',\n",
    "}\n",
    "\n",
    "\n",
    "def replace_path_name(path_name):\n",
    "    for i in replace_dic:\n",
    "        if i in path_name:\n",
    "            return replace_dic[i]\n",
    "    return path_name\n",
    "\n",
    "\n",
    "# Users should manually put the detected anomalous time windows here\n",
    "attack_list = [\n",
    "        'graph_5_15/2019-05-15 13:58:15.520482252~2019-05-15 14:13:37.257086895.txt',\n",
    "        'graph_5_15/2019-05-15 14:44:51.773840192~2019-05-15 15:00:26.765466538.txt',\n",
    "]\n",
    "\n",
    "original_edges_count = 0\n",
    "graphs = []\n",
    "gg = nx.DiGraph()\n",
    "count = 0\n",
    "for path in tqdm(attack_list):\n",
    "    if \".txt\" in path:\n",
    "        line_count = 0\n",
    "        node_set = set()\n",
    "        tempg = nx.DiGraph()\n",
    "        f = open(path, \"r\")\n",
    "        edge_list = []\n",
    "        for line in f:\n",
    "            count += 1\n",
    "            l = line.strip()\n",
    "            jdata = eval(l)\n",
    "            edge_list.append(jdata)\n",
    "\n",
    "        edge_list = sorted(edge_list, key=lambda x: x['loss'], reverse=True)\n",
    "        original_edges_count += len(edge_list)\n",
    "\n",
    "        loss_list = []\n",
    "        for i in edge_list:\n",
    "            loss_list.append(i['loss'])\n",
    "        loss_mean = mean(loss_list)\n",
    "        loss_std = std(loss_list)\n",
    "        print(loss_mean)\n",
    "        print(loss_std)\n",
    "        thr = loss_mean + 1.5 * loss_std\n",
    "        print(\"thr:\", thr)\n",
    "        for e in edge_list:\n",
    "            if e['loss'] > thr:\n",
    "                tempg.add_edge(str(hashgen(replace_path_name(e['srcmsg']))),\n",
    "                               str(hashgen(replace_path_name(e['dstmsg']))))\n",
    "                gg.add_edge(str(hashgen(replace_path_name(e['srcmsg']))), str(hashgen(replace_path_name(e['dstmsg']))),\n",
    "                            loss=e['loss'], srcmsg=e['srcmsg'], dstmsg=e['dstmsg'], edge_type=e['edge_type'],\n",
    "                            time=e['time'])\n",
    "\n",
    "\n",
    "partition = community_louvain.best_partition(gg.to_undirected())\n",
    "\n",
    "# Generate the candidate subgraphs based on community discovery results\n",
    "communities = {}\n",
    "max_partition = 0\n",
    "for i in partition:\n",
    "    if partition[i] > max_partition:\n",
    "        max_partition = partition[i]\n",
    "for i in range(max_partition + 1):\n",
    "    communities[i] = nx.DiGraph()\n",
    "for e in gg.edges:\n",
    "    communities[partition[e[0]]].add_edge(e[0], e[1])\n",
    "    communities[partition[e[1]]].add_edge(e[0], e[1])\n",
    "\n",
    "\n",
    "# Define the attack nodes. They are **only be used to plot the colors of attack nodes and edges**.\n",
    "# They won't change the detection results.\n",
    "# Didn't add too much nodes for coloring. Most of the results are compared with the ground truth documentations manually\n",
    "def attack_edge_flag(msg):\n",
    "    attack_nodes = [\n",
    "        '208.203.20.42',\n",
    "        '189.141.204.211',\n",
    "        '/var/log/sshdlog',\n",
    "        '/usr/sbin/sshd',\n",
    "        '/usr/local/lib/firefox-54.0.1/firefox',\n",
    "    ]\n",
    "    flag = False\n",
    "    for i in attack_nodes:\n",
    "        if i in str(msg):\n",
    "            flag = True\n",
    "    return flag\n",
    "\n",
    "\n",
    "# Plot and render candidate subgraph\n",
    "os.system(f\"mkdir -p ./graph_visual/\")\n",
    "graph_index = 0\n",
    "for c in communities:\n",
    "    dot = Digraph(name=\"MyPicture\", comment=\"the test\", format=\"pdf\")\n",
    "    dot.graph_attr['rankdir'] = 'LR'\n",
    "\n",
    "    for e in communities[c].edges:\n",
    "        try:\n",
    "            temp_edge = gg.edges[e]\n",
    "            srcnode = e['srcnode']\n",
    "            dstnode = e['dstnode']\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if True:\n",
    "            # source node\n",
    "            if \"'subject': '\" in temp_edge['srcmsg']:\n",
    "                src_shape = 'box'\n",
    "            elif \"'file': '\" in temp_edge['srcmsg']:\n",
    "                src_shape = 'oval'\n",
    "            elif \"'netflow': '\" in temp_edge['srcmsg']:\n",
    "                src_shape = 'diamond'\n",
    "            if attack_edge_flag(temp_edge['srcmsg']):\n",
    "                src_node_color = 'red'\n",
    "            else:\n",
    "                src_node_color = 'blue'\n",
    "            dot.node(name=str(hashgen(replace_path_name(temp_edge['srcmsg']))), label=str(\n",
    "                replace_path_name(temp_edge['srcmsg']) + str(\n",
    "                    partition[str(hashgen(replace_path_name(temp_edge['srcmsg'])))])), color=src_node_color,\n",
    "                     shape=src_shape)\n",
    "\n",
    "            # destination node\n",
    "            if \"'subject': '\" in temp_edge['dstmsg']:\n",
    "                dst_shape = 'box'\n",
    "            elif \"'file': '\" in temp_edge['dstmsg']:\n",
    "                dst_shape = 'oval'\n",
    "            elif \"'netflow': '\" in temp_edge['dstmsg']:\n",
    "                dst_shape = 'diamond'\n",
    "            if attack_edge_flag(temp_edge['dstmsg']):\n",
    "                dst_node_color = 'red'\n",
    "            else:\n",
    "                dst_node_color = 'blue'\n",
    "            dot.node(name=str(hashgen(replace_path_name(temp_edge['dstmsg']))), label=str(\n",
    "                replace_path_name(temp_edge['dstmsg']) + str(\n",
    "                    partition[str(hashgen(replace_path_name(temp_edge['dstmsg'])))])), color=dst_node_color,\n",
    "                     shape=dst_shape)\n",
    "\n",
    "            if attack_edge_flag(temp_edge['srcmsg']) and attack_edge_flag(temp_edge['dstmsg']):\n",
    "                edge_color = 'red'\n",
    "            else:\n",
    "                edge_color = 'blue'\n",
    "            dot.edge(str(hashgen(replace_path_name(temp_edge['srcmsg']))),\n",
    "                     str(hashgen(replace_path_name(temp_edge['dstmsg']))), label=temp_edge['edge_type'],\n",
    "                     color=edge_color)\n",
    "\n",
    "    dot.render(f'./graph_visual/subgraph_' + str(graph_index), view=False)\n",
    "    graph_index += 1\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "225.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

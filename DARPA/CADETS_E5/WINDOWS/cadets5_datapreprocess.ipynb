{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shahidul/anaconda3/envs/kairos/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import os\n",
    "import json\n",
    "import multiprocessing as mp\n",
    "import re\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import *\n",
    "import threading\n",
    "import networkx as nx\n",
    "import math\n",
    "\n",
    "filePath=\"../../data/cadets_e5/\"\n",
    "\n",
    "import hashlib\n",
    "def stringtomd5(originstr):\n",
    "    originstr = originstr.encode(\"utf-8\")\n",
    "    signaturemd5 = hashlib.sha256()\n",
    "    signaturemd5.update(originstr)\n",
    "    return signaturemd5.hexdigest() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = [\n",
    " 'ta1-cadets-1-e5-official-2.bin.100.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.100.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.100.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.101.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.101.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.101.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.102.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.102.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.102.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.103.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.103.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.103.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.104.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.104.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.104.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.105.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.105.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.105.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.106.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.106.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.106.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.107.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.107.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.107.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.108.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.108.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.108.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.109.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.109.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.109.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.10.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.10.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.10.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.110.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.110.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.110.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.111.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.111.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.111.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.112.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.112.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.112.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.113.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.113.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.113.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.114.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.114.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.114.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.115.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.115.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.115.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.116.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.116.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.116.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.117.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.117.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.117.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.118.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.118.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.118.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.119.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.119.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.119.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.11.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.11.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.11.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.120.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.120.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.120.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.121.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.121.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.12.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.12.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.12.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.13.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.13.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.13.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.14.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.14.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.14.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.15.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.15.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.15.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.16.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.16.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.16.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.17.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.17.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.17.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.18.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.18.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.18.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.19.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.19.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.19.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.1.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.1.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.1.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.20.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.20.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.20.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.21.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.21.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.21.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.22.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.22.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.22.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.23.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.23.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.23.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.24.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.24.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.24.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.25.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.25.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.25.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.26.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.26.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.26.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.27.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.27.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.27.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.28.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.28.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.28.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.29.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.29.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.29.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.2.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.2.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.2.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.30.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.30.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.30.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.31.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.31.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.31.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.32.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.32.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.32.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.33.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.33.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.33.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.34.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.34.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.34.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.35.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.35.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.35.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.36.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.36.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.36.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.37.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.37.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.37.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.38.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.38.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.38.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.39.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.39.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.39.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.3.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.3.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.3.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.40.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.40.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.40.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.41.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.41.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.41.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.42.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.42.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.42.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.43.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.43.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.43.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.44.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.44.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.44.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.45.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.45.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.45.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.46.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.46.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.46.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.47.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.47.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.47.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.48.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.48.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.48.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.49.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.49.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.49.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.4.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.4.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.4.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.50.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.50.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.50.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.51.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.51.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.51.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.52.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.52.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.52.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.53.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.53.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.53.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.54.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.54.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.54.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.55.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.55.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.55.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.56.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.56.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.56.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.57.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.57.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.57.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.58.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.58.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.58.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.59.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.59.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.59.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.5.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.5.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.5.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.60.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.60.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.60.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.61.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.61.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.61.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.62.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.62.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.62.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.63.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.63.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.63.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.64.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.64.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.64.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.65.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.65.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.65.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.66.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.66.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.66.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.67.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.67.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.67.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.68.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.68.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.68.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.69.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.69.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.69.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.6.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.6.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.6.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.70.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.70.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.70.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.71.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.71.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.71.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.72.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.72.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.72.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.73.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.73.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.73.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.74.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.74.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.74.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.75.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.75.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.75.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.76.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.76.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.76.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.77.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.77.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.77.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.78.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.78.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.78.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.79.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.79.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.79.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.7.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.7.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.7.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.80.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.80.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.80.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.81.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.81.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.81.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.82.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.82.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.82.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.83.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.83.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.83.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.84.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.84.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.84.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.85.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.85.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.85.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.86.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.86.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.86.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.87.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.87.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.87.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.88.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.88.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.88.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.89.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.89.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.89.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.8.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.8.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.8.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.90.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.90.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.90.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.91.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.91.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.91.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.92.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.92.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.92.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.93.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.93.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.93.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.94.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.94.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.94.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.95.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.95.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.95.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.96.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.96.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.96.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.97.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.97.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.97.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.98.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.98.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.98.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.99.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.99.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.99.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.9.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.9.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.9.json.2',\n",
    " 'ta1-cadets-1-e5-official-2.bin.json',\n",
    " 'ta1-cadets-1-e5-official-2.bin.json.1',\n",
    " 'ta1-cadets-1-e5-official-2.bin.json.2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "import time\n",
    "import pytz\n",
    "from time import mktime\n",
    "from datetime import datetime\n",
    "import time\n",
    "def ns_time_to_datetime(ns):\n",
    "    \"\"\"\n",
    "    :param ns: int nano timestamp\n",
    "    :return: datetime   format: 2013-10-10 23:40:00.000000000\n",
    "    \"\"\"\n",
    "    dt = datetime.fromtimestamp(int(ns) // 1000000000)\n",
    "    s = dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    s += '.' + str(int(int(ns) % 1000000000)).zfill(9)\n",
    "    return s\n",
    "\n",
    "def ns_time_to_datetime_US(ns):\n",
    "    \"\"\"\n",
    "    :param ns: int nano timestamp\n",
    "    :return: datetime   format: 2013-10-10 23:40:00.000000000\n",
    "    \"\"\"\n",
    "    tz = pytz.timezone('US/Eastern')\n",
    "    dt = pytz.datetime.datetime.fromtimestamp(int(ns) // 1000000000, tz)\n",
    "    s = dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    s += '.' + str(int(int(ns) % 1000000000)).zfill(9)\n",
    "    return s\n",
    "\n",
    "def time_to_datetime_US(s):\n",
    "    \"\"\"\n",
    "    :param ns: int nano timestamp\n",
    "    :return: datetime   format: 2013-10-10 23:40:00\n",
    "    \"\"\"\n",
    "    tz = pytz.timezone('US/Eastern')\n",
    "    dt = pytz.datetime.datetime.fromtimestamp(int(s), tz)\n",
    "    s = dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    return s\n",
    "\n",
    "def datetime_to_ns_time(date):\n",
    "    \"\"\"\n",
    "    :param date: str   format: %Y-%m-%d %H:%M:%S   e.g. 2013-10-10 23:40:00\n",
    "    :return: nano timestamp\n",
    "    \"\"\"\n",
    "    timeArray = time.strptime(date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    timeStamp = int(time.mktime(timeArray))\n",
    "    timeStamp = timeStamp * 1000000000\n",
    "    return timeStamp\n",
    "\n",
    "def datetime_to_ns_time_US(date):\n",
    "    \"\"\"\n",
    "    :param date: str   format: %Y-%m-%d %H:%M:%S   e.g. 2013-10-10 23:40:00\n",
    "    :return: nano timestamp\n",
    "    \"\"\"\n",
    "    tz = pytz.timezone('US/Eastern')\n",
    "    timeArray = time.strptime(date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    dt = datetime.fromtimestamp(mktime(timeArray))\n",
    "    timestamp = tz.localize(dt)\n",
    "    timestamp = timestamp.timestamp()\n",
    "    timeStamp = timestamp * 1000000000\n",
    "    return int(timeStamp)\n",
    "\n",
    "def datetime_to_timestamp_US(date):\n",
    "    \"\"\"\n",
    "    :param date: str   format: %Y-%m-%d %H:%M:%S   e.g. 2013-10-10 23:40:00\n",
    "    :return: nano timestamp\n",
    "    \"\"\"\n",
    "    tz = pytz.timezone('US/Eastern')\n",
    "    timeArray = time.strptime(date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    dt = datetime.fromtimestamp(mktime(timeArray))\n",
    "    timestamp = tz.localize(dt)\n",
    "    timestamp = timestamp.timestamp()\n",
    "    timeStamp = timestamp\n",
    "    return int(timeStamp)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T03:12:41.410691Z",
     "start_time": "2024-11-03T03:12:41.381406Z"
    }
   },
   "source": [
    "# Database setting (Make sure the database and tables are created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "from psycopg2 import extras as ex\n",
    "connect = psycopg2.connect(database = 'tc_e5_cadets_dataset_db',\n",
    "                           host = 'localhost',\n",
    "                           user = 'postgres',\n",
    "                           password = 'postgres',\n",
    "                           port = '5434'\n",
    "                          )\n",
    "\n",
    "cur = connect.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "include_edge_type=[\n",
    "    'EVENT_CLOSE',\n",
    "    'EVENT_OPEN',\n",
    "    'EVENT_READ',\n",
    "    'EVENT_WRITE',\n",
    "     'EVENT_EXECUTE',\n",
    "    'EVENT_RECVFROM',\n",
    "    'EVENT_RECVMSG',\n",
    "    'EVENT_SENDMSG',\n",
    "    'EVENT_SENDTO',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Netflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xc0 in position 17: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnicodeDecodeError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m tqdm(filelist):\n\u001B[1;32m      5\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(filePath \u001B[38;5;241m+\u001B[39m file, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m----> 6\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m f:\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m#                 pass\u001B[39;00m\n\u001B[1;32m      8\u001B[0m                 \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mavro.cdm20.NetFlowObject\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m line:\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m#                     print(line)\u001B[39;00m\n\u001B[1;32m     10\u001B[0m                     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/envs/kairos/lib/python3.9/codecs.py:322\u001B[0m, in \u001B[0;36mBufferedIncrementalDecoder.decode\u001B[0;34m(self, input, final)\u001B[0m\n\u001B[1;32m    319\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecode\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m, final\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    320\u001B[0m     \u001B[38;5;66;03m# decode input (taking the buffer into account)\u001B[39;00m\n\u001B[1;32m    321\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuffer \u001B[38;5;241m+\u001B[39m \u001B[38;5;28minput\u001B[39m\n\u001B[0;32m--> 322\u001B[0m     (result, consumed) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_buffer_decode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfinal\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    323\u001B[0m     \u001B[38;5;66;03m# keep undecoded input until the next call\u001B[39;00m\n\u001B[1;32m    324\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuffer \u001B[38;5;241m=\u001B[39m data[consumed:]\n",
      "\u001B[0;31mUnicodeDecodeError\u001B[0m: 'utf-8' codec can't decode byte 0xc0 in position 17: invalid start byte"
     ]
    }
   ],
   "source": [
    "netobjset=set()\n",
    "netobj2hash={}# \n",
    "datalist=[]\n",
    "for file in tqdm(filelist):\n",
    "        with open(filePath + file, \"r\") as f:\n",
    "            for line in f:\n",
    "#                 pass\n",
    "                if \"avro.cdm20.NetFlowObject\" in line:\n",
    "#                     print(line)\n",
    "                    try:\n",
    "                        res=re.findall('NetFlowObject\":{\"uuid\":\"(.*?)\"(.*?)\"localAddress\":{\"string\":\"(.*?)\"},\"localPort\":{\"int\":(.*?)},\"remoteAddress\":{\"string\":\"(.*?)\"},\"remotePort\":{\"int\":(.*?)}',line)[0]\n",
    "\n",
    "                        nodeid=res[0]\n",
    "                        srcaddr=res[2]\n",
    "                        srcport=res[3]\n",
    "                        dstaddr=res[4]\n",
    "                        dstport=res[5]\n",
    "\n",
    "                        nodeproperty=srcaddr+\",\"+srcport+\",\"+dstaddr+\",\"+dstport \n",
    "#                         nodeproperty=dstaddr+\",\"+dstport # \n",
    "                        hashstr=stringtomd5(nodeproperty)\n",
    "                        netobj2hash[nodeid]=[hashstr,nodeproperty]\n",
    "                        netobj2hash[hashstr]=nodeid\n",
    "                        netobjset.add(hashstr)\n",
    "                    except:\n",
    "                        pass\n",
    "#                     print(match)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist=[]\n",
    "for i in netobj2hash.keys():\n",
    "    if len(i)!=64:\n",
    "        datalist.append([i]+[netobj2hash[i][0]]+netobj2hash[i][1].split(\",\"))\n",
    "\n",
    "#write to database\n",
    "\n",
    "\n",
    "sql = '''insert into netflow_node_table\n",
    "                     values %s\n",
    "        '''\n",
    "ex.execute_values(cur,sql, datalist,page_size=10000)\n",
    "connect.commit() \n",
    "\n",
    "del netobj2hash\n",
    "del datalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting UUIDs of Process and File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_uuid2path={}# \n",
    "file_uuid2path={}# \n",
    "\n",
    "for file in tqdm(filelist):\n",
    "        with open(filePath + file, \"r\") as f:\n",
    "#             for line in tqdm(f): \n",
    "            for line in (f):\n",
    "                if \"schema.avro.cdm20.Subject\" in line:                \n",
    "                    pattern='{\"com.bbn.tc.schema.avro.cdm20.Subject\":{\"uuid\":\"(.*?)\"'\n",
    "                    match_ans=re.findall(pattern,line)[0]           \n",
    "                    subject_uuid2path[match_ans]='none'\n",
    "                elif \"schema.avro.cdm20.FileObject\" in line:   \n",
    "                    pattern='{\"com.bbn.tc.schema.avro.cdm20.FileObject\":{\"uuid\":\"(.*?)\"'\n",
    "                    match_ans=re.findall(pattern,line)[0]           \n",
    "                    file_uuid2path[match_ans]='none'\n",
    "#                     print(line)\n",
    "#                     subject_uuid2path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scusess_count=0\n",
    "fail_count=0\n",
    "\n",
    "for file in tqdm(filelist):\n",
    "    with open(filePath + file, \"r\") as f:\n",
    "#             for line in tqdm(f): \n",
    "        for line in (f):\n",
    "            if \"schema.avro.cdm20.Event\" in line:\n",
    "#                     print(line)\n",
    "                relation_type=re.findall('\"type\":\"(.*?)\"',line)[0]\n",
    "                if relation_type in include_edge_type:\n",
    "                     # 0: subject uuid  1:object uuid  2 object path name   -1: subject name\n",
    "                    try: \n",
    "                        pattern='\"subject\":{\"com.bbn.tc.schema.avro.cdm20.UUID\":\"(.*?)\"},(.*?)\"exec\":\"(.*?)\",'\n",
    "                        match_ans=re.findall(pattern,line)\n",
    "                        if match_ans[0][0] in subject_uuid2path:\n",
    "                            subject_uuid2path[match_ans[0][0]]=match_ans[0][-1]\n",
    "                    except:\n",
    "                        fail_count+=1\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(subject_uuid2path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist=[]\n",
    "for i in subject_uuid2path.keys():\n",
    "    if subject_uuid2path[i]!='none':\n",
    "        datalist.append([i]+[stringtomd5(subject_uuid2path[i]),subject_uuid2path[i]])\n",
    "        \n",
    "\n",
    "\n",
    "sql = '''insert into subject_node_table\n",
    "                     values %s\n",
    "        '''\n",
    "ex.execute_values(cur,sql, datalist,page_size=10000)\n",
    "connect.commit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scusess_count=0\n",
    "fail_count=0\n",
    "\n",
    "for file in tqdm(filelist):\n",
    "    with open(filePath + file, \"r\") as f:\n",
    "#             for line in tqdm(f): \n",
    "        for line in (f):\n",
    "            if \"schema.avro.cdm20.Event\" in line:\n",
    "#                     print(line)\n",
    "                relation_type=re.findall('\"type\":\"(.*?)\"',line)[0]\n",
    "                if relation_type in include_edge_type:                            \n",
    "                    try:    \n",
    "                        object_uuid=re.findall('\"predicateObject\":{\"com.bbn.tc.schema.avro.cdm20.UUID\":\"(.*?)\"},',line)[0]\n",
    "                        if object_uuid in file_uuid2path:\n",
    "                            object_path=re.findall('\"predicateObjectPath\":{\"string\":\"(.*?)\"}',line)                            \n",
    "                            if len(object_path)==0:                                \n",
    "                                file_uuid2path[object_uuid]='null' \n",
    "                            else:\n",
    "                                file_uuid2path[object_uuid]=object_path[0]\n",
    "                    except:\n",
    "                        fail_count+=1\n",
    "\n",
    "#                                 print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datalist=[]\n",
    "for i in file_uuid2path.keys():\n",
    "    if file_uuid2path[i]!='none':\n",
    "        datalist.append([i]+[stringtomd5(file_uuid2path[i]),file_uuid2path[i]])\n",
    "datalist_new=[]\n",
    "for i in datalist:\n",
    "    if i[-1]!='null':\n",
    "        datalist_new.append(i)\n",
    "\n",
    "\n",
    "sql = '''insert into file_node_table\n",
    "                     values %s\n",
    "        '''\n",
    "ex.execute_values(cur,sql, datalist_new,page_size=10000)\n",
    "connect.commit()  \n",
    "datalist_new.clear()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing event data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extracting the node list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate the data of node2id table\n",
    "node_list={}\n",
    "##################################################################################################\n",
    "sql=\"\"\"\n",
    "select * from file_node_table;\n",
    "\"\"\"\n",
    "cur.execute(sql)\n",
    "records = cur.fetchall()\n",
    "\n",
    "for i in records:    \n",
    "    node_list[i[1]]=[\"file\",i[-1]]\n",
    "\n",
    "file_uuid2hash={}\n",
    "for i in records:\n",
    "    file_uuid2hash[i[0]]=i[1]\n",
    "##################################################################################################    \n",
    "sql=\"\"\"\n",
    "select * from subject_node_table;\n",
    "\"\"\"\n",
    "cur.execute(sql)\n",
    "records = cur.fetchall()\n",
    "\n",
    "for i in records:\n",
    "    node_list[i[1]]=[\"subject\",i[-1]]\n",
    "\n",
    "subject_uuid2hash={}\n",
    "for i in records:\n",
    "    subject_uuid2hash[i[0]]=i[1]\n",
    "##################################################################################################\n",
    "sql=\"\"\"\n",
    "select * from netflow_node_table;\n",
    "\"\"\"\n",
    "cur.execute(sql)\n",
    "records = cur.fetchall()\n",
    "\n",
    "for i in records:\n",
    "    \n",
    "    node_list[i[1]]=[\"netflow\",i[-2]+\":\"+i[-1]]\n",
    "\n",
    "net_uuid2hash={}\n",
    "for i in records:\n",
    "    net_uuid2hash[i[0]]=i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list_database=[]\n",
    "node_index=0\n",
    "for i in node_list:\n",
    "    node_list_database.append([i]+node_list[i]+[node_index])\n",
    "    node_index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''insert into node2id\n",
    "                     values %s\n",
    "        '''\n",
    "ex.execute_values(cur,sql, node_list_database,page_size=10000)\n",
    "connect.commit()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the map for nodeid to msg\n",
    "sql=\"select * from node2id ORDER BY index_id;\"\n",
    "cur.execute(sql)\n",
    "rows = cur.fetchall()\n",
    "\n",
    "nodeid2msg={}  # nodeid => msg and node hash => nodeid\n",
    "for i in rows:\n",
    "    nodeid2msg[i[0]]=i[-1]\n",
    "    nodeid2msg[i[-1]]={i[1]:i[2]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeid2msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_edge_type=[\n",
    "    'EVENT_CLOSE',\n",
    "    'EVENT_OPEN',\n",
    "    'EVENT_READ',\n",
    "    'EVENT_WRITE',\n",
    "     'EVENT_EXECUTE',\n",
    "    'EVENT_RECVFROM',\n",
    "    'EVENT_RECVMSG',\n",
    "    'EVENT_SENDMSG',\n",
    "    'EVENT_SENDTO',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_event_in_DB(datalist_new):\n",
    "    sql = '''insert into event_table\n",
    "                         values %s\n",
    "            '''\n",
    "    ex.execute_values(cur,sql, datalist_new,page_size=10000)\n",
    "    connect.commit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist=[]\n",
    "edge_type=set()\n",
    "total_event_count=0\n",
    "reverse=[\"EVENT_READ\",\"EVENT_RECVFROM\",\"EVENT_RECVMSG\"]        \n",
    "for file in tqdm(filelist):\n",
    "        with open(filePath + file, \"r\") as f:\n",
    "            for line in (f):\n",
    "                if '{\"datum\":{\"com.bbn.tc.schema.avro.cdm20.Event\"' in line:\n",
    "                    total_event_count+=1\n",
    "#                     print(line)\n",
    "                    subject_uuid=re.findall('\"subject\":{\"com.bbn.tc.schema.avro.cdm20.UUID\":\"(.*?)\"}',line)\n",
    "                    predicateObject_uuid=re.findall('\"predicateObject\":{\"com.bbn.tc.schema.avro.cdm20.UUID\":\"(.*?)\"}',line)\n",
    "                    if len(subject_uuid) >0 and len(predicateObject_uuid)>0:\n",
    "                        if subject_uuid[0] in subject_uuid2hash\\\n",
    "                        and (predicateObject_uuid[0] in file_uuid2hash or predicateObject_uuid[0] in net_uuid2hash):\n",
    "                            relation_type=re.findall('\"type\":\"(.*?)\"',line)[0]\n",
    "                            time_rec=re.findall('\"timestampNanos\":(.*?),',line)[0]\n",
    "                            time_rec=int(time_rec)\n",
    "                            subjectId=subject_uuid2hash[subject_uuid[0]]\n",
    "                            if predicateObject_uuid[0] in file_uuid2hash:\n",
    "                                objectId=file_uuid2hash[predicateObject_uuid[0]]\n",
    "                            else:\n",
    "                                objectId=net_uuid2hash[predicateObject_uuid[0]]\n",
    "#                                 print(line)\n",
    "                            edge_type.add(relation_type)\n",
    "                            if relation_type in reverse:\n",
    "                                datalist.append([objectId,nodeid2msg[objectId],relation_type,subjectId,nodeid2msg[subjectId],time_rec])\n",
    "                            else:\n",
    "                                datalist.append([subjectId,nodeid2msg[subjectId],relation_type,objectId,nodeid2msg[objectId],time_rec])\n",
    "                            if len(datalist)==50000:\n",
    "                                write_event_in_DB(datalist)\n",
    "                                datalist.clear()\n",
    "                                \n",
    "write_event_in_DB(datalist)\n",
    "datalist.clear()\n",
    "\n",
    "                    \n",
    "print(\"total_event_count:\",total_event_count)     \n",
    "#output: total_event_count: 1193669198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "FH_string=FeatureHasher(n_features=16,input_type=\"string\")\n",
    "FH_dict=FeatureHasher(n_features=16,input_type=\"dict\")\n",
    "\n",
    "\n",
    "def path2higlist(p):\n",
    "    l=[]\n",
    "    spl=p.strip().split('/')\n",
    "    for i in spl:\n",
    "        if len(l)!=0:\n",
    "            l.append(l[-1]+'/'+i)\n",
    "        else:\n",
    "            l.append(i)\n",
    "#     print(l)\n",
    "    return l\n",
    "\n",
    "def ip2higlist(p):\n",
    "    l=[]\n",
    "    spl=p.strip().split('.')\n",
    "    for i in spl:\n",
    "        if len(l)!=0:\n",
    "            l.append(l[-1]+'.'+i)\n",
    "        else:\n",
    "            l.append(i)\n",
    "#     print(l)\n",
    "    return l\n",
    "\n",
    "\n",
    "def subject2higlist(p):\n",
    "    l=[]\n",
    "    spl=p.strip().split('.')\n",
    "    for i in spl:\n",
    "        if len(l)!=0:\n",
    "            l.append(l[-1]+'.'+i)\n",
    "        else:\n",
    "            l.append(i)\n",
    "#     print(l)\n",
    "    return l\n",
    "\n",
    "\n",
    "def list2str(l):\n",
    "    s=''\n",
    "    for i in l:\n",
    "        s+=i\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_msg_vec=[]\n",
    "node_msg_dic_list=[]\n",
    "for i in tqdm(nodeid2msg.keys()):\n",
    "    if type(i)==int:\n",
    "        if 'netflow' in nodeid2msg[i].keys():\n",
    "            higlist=['netflow']\n",
    "            higlist+=ip2higlist(nodeid2msg[i]['netflow'])\n",
    "            \n",
    "        if 'file' in nodeid2msg[i].keys():\n",
    "            higlist=['file']\n",
    "            higlist+=path2higlist(nodeid2msg[i]['file'])\n",
    "            \n",
    "#             print(higlist)\n",
    "        if 'subject' in nodeid2msg[i].keys():\n",
    "            higlist=['subject']\n",
    "            higlist+=subject2higlist(nodeid2msg[i]['subject'])\n",
    "        node_msg_dic_list.append(list2str(higlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node2higvec=[]\n",
    "for i in tqdm(node_msg_dic_list):\n",
    "    vec=FH_string.transform([i]).toarray()\n",
    "    node2higvec.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node2higvec=np.array(node2higvec).reshape([-1,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel2id={1: 'EVENT_CLOSE',\n",
    " 'EVENT_CLOSE': 1,\n",
    " 2: 'EVENT_OPEN',\n",
    " 'EVENT_OPEN': 2,\n",
    " 3: 'EVENT_READ',\n",
    " 'EVENT_READ': 3,\n",
    " 4: 'EVENT_WRITE',\n",
    " 'EVENT_WRITE': 4,\n",
    " 5: 'EVENT_EXECUTE',\n",
    " 'EVENT_EXECUTE': 5,\n",
    " 6: 'EVENT_RECVFROM',\n",
    " 'EVENT_RECVFROM': 6,\n",
    " 7: 'EVENT_RECVMSG',\n",
    " 'EVENT_RECVMSG': 7,\n",
    " 8: 'EVENT_SENDMSG',\n",
    " 'EVENT_SENDMSG': 8,\n",
    " 9: 'EVENT_SENDTO',\n",
    " 'EVENT_SENDTO': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geneate edge type one-hot\n",
    "relvec=torch.nn.functional.one_hot(torch.arange(0, len(rel2id.keys())//2), num_classes=len(rel2id.keys())//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map different relation types to their one-hot encoding\n",
    "rel2vec={}\n",
    "for i in rel2id.keys():\n",
    "    if type(i) is not int:\n",
    "        rel2vec[i]= relvec[rel2id[i]-1]\n",
    "        rel2vec[relvec[rel2id[i]-1]]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the results\n",
    "torch.save(node2higvec,\"node2higvec\")\n",
    "torch.save(rel2vec,\"rel2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node2higvec=torch.load(\"./node2higvec\")\n",
    "rel2vec=torch.load(\"./rel2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"mkdir -p ./train_graph/\")\n",
    "for day in tqdm(range(8,18)):\n",
    "    start_timestamp=datetime_to_ns_time_US('2019-05-'+str(day)+' 00:00:00')\n",
    "    end_timestamp=datetime_to_ns_time_US('2019-05-'+str(day+1)+' 00:00:00')\n",
    "    sql=\"\"\"\n",
    "    select * from event_table\n",
    "    where\n",
    "          timestamp_rec>'%s' and timestamp_rec<'%s'\n",
    "           ORDER BY timestamp_rec;\n",
    "    \"\"\"%(start_timestamp,end_timestamp)\n",
    "    cur.execute(sql)\n",
    "    events = cur.fetchall()\n",
    "    print('2019-05-'+str(day),\" events count:\",str(len(events)))\n",
    "    edge_list=[]\n",
    "    for e in events:\n",
    "        edge_temp=[int(e[1]),int(e[4]),e[2],e[5]]\n",
    "        if e[2] in include_edge_type:# if this edge type is considered, include it into our graphs\n",
    "#         if True:\n",
    "            edge_list.append(edge_temp)\n",
    "    print('2019-05-'+str(day),\" edge list len:\",str(len(edge_list)))\n",
    "\n",
    "    dataset = TemporalData()\n",
    "    src = []\n",
    "    dst = []\n",
    "    msg = []\n",
    "    t = []\n",
    "    for i in edge_list:\n",
    "        src.append(int(i[0]))\n",
    "        dst.append(int(i[1]))\n",
    "    #     msg.append(torch.cat([torch.from_numpy(node2higvec_bn[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec_bn[i[1]])] ))\n",
    "        msg.append(torch.cat([torch.from_numpy(node2higvec[i[0]]), rel2vec[i[2]], torch.from_numpy(node2higvec[i[1]])] ))\n",
    "        t.append(int(i[3]))\n",
    "    if len(edge_list)>0:\n",
    "        dataset.src = torch.tensor(src)\n",
    "        dataset.dst = torch.tensor(dst)\n",
    "        dataset.t = torch.tensor(t)\n",
    "        dataset.msg = torch.vstack(msg)\n",
    "        dataset.src = dataset.src.to(torch.long)\n",
    "        dataset.dst = dataset.dst.to(torch.long)\n",
    "        dataset.msg = dataset.msg.to(torch.float)\n",
    "        dataset.t = dataset.t.to(torch.long)\n",
    "        torch.save(dataset, \"./train_graph/graph_5_\"+str(day)+\".TemporalData.simple\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kairos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "197.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
